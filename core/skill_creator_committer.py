"""
Skill Creator Committer: CREATE/UPDATE ìŠ¤í‚¬ì„ computer-use Pod + skill-creator
(init_skill, package_skill, quick_validate)ë¡œ ìƒì„±í•œ ë’¤ .skill zipì„ íŒŒì‹±í•˜ì—¬
skill_api_clientë¡œ ì—…ë¡œë“œ. base64Â·zip ì‹¤íŒ¨ ì‹œ HTTP í´ë°± ì—†ì´ ì˜ˆì™¸ë¥¼ ì „íŒŒ.
ì‹¤íŒ¨í•´ë„ ì˜ë„ëœ ìˆ˜ì • ë‚´ì—­(skill_content)ì´ ìˆìœ¼ë©´ record_knowledge_historyë¡œ
ë³€ê²½ ì´ë ¥ì— ë‚¨ê¸´ ë’¤ ì˜ˆì™¸ë¥¼ ì „íŒŒ.
"""

import base64
import io
import json
import re
import zipfile
from pathlib import Path
from typing import Dict, List, Optional, Any

from utils.logger import log, handle_error
from core.database import (
    _get_agent_by_id,
    update_agent_and_tenant_skills,
    record_knowledge_history,
)
from core.skill_api_client import (
    check_skill_exists,
    get_skill_file_content,
    get_skill_files,
    update_skill_file,
    upload_skill,
)
from core.learning_committers.skill_committer import _format_skill_document
from core.skill_quick_validate import get_quick_validate_script
from core.mcp_client import get_mcp_tool_by_name_async
from core.llm import create_llm


# MCP tool names (claude-skills, computer-use)
_TOOL_READ_SKILL_DOCUMENT = "read_skill_document"
_TOOL_CREATE_SESSION = "create_session"
_TOOL_DELETE_SESSION = "delete_session"
_TOOL_CREATE_FILE = "create_file"
_TOOL_RUN_SHELL = "run_shell"
_TOOL_DELETE_FILE = "delete_file"


def _tool_name_variants(base: str) -> List[str]:
    """MCP ë„êµ¬ ì´ë¦„ ë³€í˜• (ì„œë²„ ì ‘ë‘ì–´ ë“±)."""
    return [base, f"mcp_computer-use_{base}", f"mcp_cursor-computer-use_{base}"]


def _extract_text(res: Any) -> str:
    """MCP/LLM ê²°ê³¼ì—ì„œ ë¬¸ìì—´ ì¶”ì¶œ. content ë¸”ë¡ ë¦¬ìŠ¤íŠ¸, dict, ê°ì²´ ì§€ì›."""
    if res is None:
        return ""
    if isinstance(res, str):
        return res
    if isinstance(res, list):
        return "".join(
            str(x.get("text", ""))
            for x in res
            if isinstance(x, dict) and "text" in x
        )
    if isinstance(res, dict):
        c = res.get("content")
        if isinstance(c, str):
            return c
        if isinstance(c, list):
            return "".join(
                str(x.get("text", ""))
                for x in c
                if isinstance(x, dict) and "text" in x
            )
        return res.get("text") or res.get("output") or ""
    if hasattr(res, "content"):
        c = getattr(res, "content", None)
        if isinstance(c, str):
            return c
        if isinstance(c, list):
            return "".join(
                str(x.get("text", ""))
                for x in c
                if isinstance(x, dict) and "text" in x
            )
        if hasattr(c, "__iter__") and not isinstance(c, (str, bytes)):
            return "".join(str(x) for x in c)
    return str(res)


def _strip_document_header(text: str) -> str:
    """
    claude-skills read_skill_document ì‘ë‹µì—ì„œ ë˜í¼ë¥¼ ì œê±°.
    í˜•ì‹: "Document: path\\n\\n========...\\n\\n<ì‹¤ì œ ìŠ¤í¬ë¦½íŠ¸>"
    ì´ ë˜í¼ë¥¼ ê·¸ëŒ€ë¡œ .pyì— ì“°ë©´ line 3ì˜ "===..."ê°€ SyntaxErrorë¥¼ ìœ ë°œí•¨.
    """
    if not text or not isinstance(text, str):
        return text or ""
    s = text.lstrip()
    if not s.startswith("Document:"):
        return text
    # "Document: ...\\n\\n=+\\n+" ì œê±°
    m = re.match(r"Document:[^\n]*\n\s*=+\s*\n+", s)
    if m:
        return s[m.end() :].lstrip("\n")
    # í—¤ë” í˜•ì‹ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë©´, ì²« ì½”ë“œ ìœ ì‚¬ ë¼ì¸(#!, """, import, from)ê¹Œì§€ ê±´ë„ˆë›°ê¸°
    for token in ("#!", '"""', "'''", "import ", "from "):
        i = s.find(token)
        if i != -1:
            return s[i:].lstrip()
    return text


def _normalize_and_decode_base64(raw: str) -> bytes:
    """
    MCP run_shell ê²°ê³¼ì—ì„œ ì¶”ì¶œí•œ ë¬¸ìì—´ì„ ì •ê·œí™”í•œ ë’¤ base64 ë””ì½”ë”©.
    - ê³µë°±/ê°œí–‰ ì œê±°, JSON ë“±ì— ê°ì‹¸ì§„ ê²½ìš° base64 ë¸”ë¡ ì¶”ì¶œ, íŒ¨ë”© ë³´ì •.
    - ì‹¤íŒ¨ ì‹œ BinasciiError ë“± ê·¸ëŒ€ë¡œ ì „íŒŒ.
    """
    # [ë””ì½”ë”© ë””ë²„ê·¸] ì…ë ¥
    raw_type = type(raw).__name__
    raw_len = len(raw) if raw else 0
    log(f"   [base64] ì…ë ¥: type={raw_type}, len={raw_len}, ì•150ì={repr((raw or '')[:150])}, ë’¤150ì={repr((raw or '')[-150:])}")

    s = (raw or "").strip()
    if not s:
        log(f"   [base64] strip í›„ ë¹„ì–´ ìˆìŒ")
        raise ValueError("base64 ì…ë ¥ì´ ë¹„ì–´ ìˆìŒ")
    s = re.sub(r"\s+", "", s)
    log(f"   [base64] ê³µë°± ì œê±° í›„ len={len(s)}")

    cand = s
    if not re.fullmatch(r"[A-Za-z0-9+/=]*", s):
        parts = re.findall(r"[A-Za-z0-9+/=]{50,}", s)
        if parts:
            cand = max(parts, key=len)
            log(f"   [base64] ë¹„ base64 ë¬¸ì ìˆìŒ â†’ ë¸”ë¡ ì¶”ì¶œ: {len(parts)}ê°œ ì¤‘ ìµœëŒ€ len(cand)={len(cand)}")
        else:
            parts = re.findall(r"[A-Za-z0-9+/=]+", s)
            cand = max(parts, key=len) if parts else s
            log(f"   [base64] 50ì ì´ìƒ ë¸”ë¡ ì—†ìŒ â†’ [A-Za-z0-9+/=]+ ì¡°ê° {len(parts)}ê°œ ì¤‘ ìµœëŒ€ len(cand)={len(cand)}")
    if not cand:
        log(f"   [base64] base64 ì¶”ì¶œ ë¸”ë¡ ì—†ìŒ, s[:200]={repr(s[:200])}")
        raise ValueError("base64ì— ì‚¬ìš© ê°€ëŠ¥í•œ ë¸”ë¡ì´ ì—†ìŒ")

    pad = (4 - len(cand) % 4) % 4
    cand += "=" * pad
    log(f"   [base64] cand len={len(cand)}, len%4={len(cand) % 4}, pad={pad}, ì•120ì={repr(cand[:120])}, ë’¤120ì={repr(cand[-120:])}")

    try:
        return base64.b64decode(cand)
    except Exception as e1:
        log(f"   [base64] b64decode(cand) ì‹¤íŒ¨: {type(e1).__name__}: {e1}, cand_len={len(cand)}")
        try:
            return base64.b64decode(cand, validate=False)
        except TypeError:
            log(f"   [base64] validate=False ë¯¸ì§€ì›(êµ¬ë²„ì „ íŒŒì´ì¬), ì›ì˜ˆì™¸ ì „íŒŒ")
            raise e1
        except Exception as e2:
            log(f"   [base64] b64decode(validate=False) ë„ ì‹¤íŒ¨: {type(e2).__name__}: {e2}")
            raise e1


def _extract_session_id(res: Any) -> Optional[str]:
    """create_session ê²°ê³¼ì—ì„œ session_id ì¶”ì¶œ.
    MCP computer-useëŠ” {"session_id":"...","pod_name":"..."} ë˜ëŠ”
    content ë‚´ text/JSON ë¬¸ìì—´ë¡œ ë°˜í™˜í•  ìˆ˜ ìˆìŒ.
    """
    if res is None:
        return None
    # 1) ìµœìƒìœ„ dictì— session_id / sessionId
    if isinstance(res, dict):
        sid = res.get("session_id") or res.get("sessionId")
        if sid:
            return str(sid).strip() or None
        # result / data ë˜í•‘
        for key in ("result", "data", "response"):
            sub = res.get(key)
            if isinstance(sub, dict):
                sid = sub.get("session_id") or sub.get("sessionId")
                if sid:
                    return str(sid).strip() or None
    # 2) content ë¬¸ìì—´(JSON) íŒŒì‹±
    text = _extract_text(res)
    if text:
        text = (text or "").strip()
        # ì´ë¯¸ JSON ê°ì²´ í˜•íƒœì˜ ë¬¸ìì—´ì¸ ê²½ìš°
        if text.startswith("{"):
            try:
                data = json.loads(text)
                sid = (data.get("session_id") or data.get("sessionId")) if isinstance(data, dict) else None
                if sid:
                    return str(sid).strip() or None
            except json.JSONDecodeError:
                pass
        # content ë¸”ë¡ì´ ì—¬ëŸ¬ ê°œì—¬ì„œ í•©ì³ì§„ ê²½ìš°, ë§ˆì§€ë§‰ ìœ íš¨ JSONë§Œ ì‹œë„
        for part in text.replace("}\n{", "}\n").split("\n"):
            part = part.strip()
            if part.startswith("{") and "session_id" in part:
                try:
                    data = json.loads(part)
                    sid = (data.get("session_id") or data.get("sessionId")) if isinstance(data, dict) else None
                    if sid:
                        return str(sid).strip() or None
                except json.JSONDecodeError:
                    pass
    # 3) ê°ì²´ì˜ content ì†ì„±ì—ì„œ ë‚˜ì˜¨ dict (ì´ë¯¸ 1ì—ì„œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ê²½ìš°)
    if hasattr(res, "content") and isinstance(getattr(res, "content", None), dict):
        return _extract_session_id(getattr(res, "content"))
    return None


def _log_create_session_debug(cr: Any) -> None:
    """create_session ì‘ë‹µì—ì„œ session_idë¥¼ ëª» ì°¾ì•˜ì„ ë•Œ ë””ë²„ê·¸ ë¡œê·¸."""
    try:
        t = type(cr).__name__
        if isinstance(cr, dict):
            r = {k: (v if k != "content" else ("<len=%s>" % len(v) if isinstance(v, (list, str)) else type(v).__name__)) for k, v in list(cr.items())[:10]}
        else:
            r = repr(cr)[:500]
        log(f"   âš ï¸ create_session ì‘ë‹µ: type={t}, repr={r}")
        txt = _extract_text(cr)
        if txt:
            log(f"   âš ï¸ _extract_text(ì‘ë‹µ) ê¸¸ì´={len(txt)}, ì• 300ì: {repr(txt[:300])}")
    except Exception as e:
        log(f"   âš ï¸ create_session ë””ë²„ê·¸ ë¡œê·¸ ì‹¤íŒ¨: {e}")


async def _invoke_tool(name: str, **kwargs: Any) -> Any:
    """MCP ë„êµ¬ë¥¼ ì´ë¦„ìœ¼ë¡œ ì°¾ì•„ ainvoke. name ë³€í˜•ìœ¼ë¡œ ì¬ì‹œë„."""
    for n in _tool_name_variants(name) + [name]:
        tool = await get_mcp_tool_by_name_async(n)
        if tool is not None:
            try:
                return await tool.ainvoke(kwargs)
            except Exception as e:
                log(f"   âš ï¸ MCP ë„êµ¬ ainvoke ì‹¤íŒ¨ {n}: {e}")
                raise
    raise RuntimeError(f"MCP ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {name}")


async def _read_skill_document(skill_name: str, document_path: str) -> str:
    """claude-skills read_skill_document. skill-creator ìŠ¤í¬ë¦½íŠ¸ ì¡°íšŒ.
    ì‘ë‹µì— 'Document: path' ë° '===...' ë˜í¼ê°€ ìˆìœ¼ë©´ ì œê±°í•´ ìˆœìˆ˜ ìŠ¤í¬ë¦½íŠ¸ë§Œ ë°˜í™˜.
    """
    for n in [_TOOL_READ_SKILL_DOCUMENT, f"mcp_claude-skills_{_TOOL_READ_SKILL_DOCUMENT}"]:
        tool = await get_mcp_tool_by_name_async(n)
        if tool is not None:
            out = await tool.ainvoke({
                "skill_name": skill_name,
                "document_path": document_path,
            })
            raw = _extract_text(out)
            return _strip_document_header(raw)
    raise RuntimeError("read_skill_document MCP ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (claude-skills)")


def _detect_feedback_language(text: str) -> str:
    """
    ë§¤ìš° ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ í”¼ë“œë°±ì˜ ì£¼ ì‚¬ìš© ì–¸ì–´ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.
    - í•œê¸€(ê°€-í£)ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ 'ko'
    - ì•„ë‹ˆë©´ 'en' (ê¸°ë³¸ê°’)
    """
    if not isinstance(text, str):
        return "en"
    for ch in text:
        # í•œê¸€ ì™„ì„±í˜• ë²”ìœ„
        if "\uac00" <= ch <= "\ud7a3":
            return "ko"
    return "en"


# Related skills context: SKILL.md summary chars, file head chars, total cap
_RELATED_SKILL_SUMMARY_CHARS = 700
_RELATED_SKILL_FILE_HEAD_CHARS = 1500
_RELATED_SKILL_CONTEXT_CAP = 20000


def _extract_document_paths_from_find_helpful_result(res: Any) -> Dict[str, List[str]]:
    """
    Extract built-in skill document paths from claude-skills find_helpful_skills output.
    Tries to be resilient across dict/list/text outputs.
    Returns: {skill_name: [doc_path, ...]}
    """
    def _try_json(s: str) -> Any:
        try:
            return json.loads(s)
        except Exception:
            return None

    obj: Any = res
    # unwrap text -> json if possible
    if isinstance(obj, str):
        j = _try_json(obj)
        if j is not None:
            obj = j
    else:
        # sometimes tools return content blocks; attempt to extract text then json
        txt = _extract_text(obj)
        if txt and txt.strip().startswith("{"):
            j = _try_json(txt.strip())
            if j is not None:
                obj = j

    skills: List[Dict[str, Any]] = []
    if isinstance(obj, dict):
        v = obj.get("skills") or obj.get("results") or []
        if isinstance(v, list):
            skills = [x for x in v if isinstance(x, dict)]
    elif isinstance(obj, list):
        skills = [x for x in obj if isinstance(x, dict)]

    out: Dict[str, List[str]] = {}
    for s in skills:
        name = (s.get("name") or s.get("skill_name") or s.get("id") or "").strip()
        if not name:
            continue
        docs = s.get("documents") or s.get("document_paths") or s.get("files") or []
        paths: List[str] = []
        if isinstance(docs, list):
            for d in docs:
                if isinstance(d, str):
                    paths.append(d.strip())
                elif isinstance(d, dict):
                    p = (d.get("path") or d.get("document_path") or d.get("name") or "").strip()
                    if p:
                        paths.append(p)
        # ensure deterministic / remove empties
        paths = [p for p in paths if p]
        if paths:
            out[name] = paths
    return out


async def _find_helpful_skills_documents(
    *,
    tenant_id: Optional[str],
    allowed_skill_names: List[str],
    task_description: str,
) -> Dict[str, List[str]]:
    """
    Use claude-skills find_helpful_skills with list_documents=True to obtain document paths
    for built-in skills. Returns {skill_name: [doc_path, ...]}.
    """
    if not allowed_skill_names:
        return {}
    if not tenant_id:
        return {}
    for tool_name in ("find_helpful_skills", "mcp_claude-skills_find_helpful_skills"):
        tool = await get_mcp_tool_by_name_async(tool_name)
        if tool is None:
            continue
        res = await tool.ainvoke(
            {
                "tenant_id": tenant_id,
                "task_description": task_description,
                "top_k": max(3, len(allowed_skill_names)),
                "list_documents": True,
                "allowed_skill_names": allowed_skill_names,
            }
        )
        return _extract_document_paths_from_find_helpful_result(res)
    log("   âš ï¸ find_helpful_skills MCP ë„êµ¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (claude-skills)")
    return {}


async def _build_related_skills_context(
    *,
    related_skill_ids: Optional[str],
    exclude_skill_id: Optional[str],
    tenant_id: Optional[str],
    task_description: str,
) -> Optional[str]:
    """
    Build a context string from related skills: summary (SKILL.md head) + file paths + each file's head.
    Supports both uploaded skills (HTTP) and built-in skills (claude-skills find_helpful_skills/read_skill_document).
    """
    if not related_skill_ids or not str(related_skill_ids).strip():
        return None
    names = [s.strip() for s in str(related_skill_ids).split(",") if s.strip()]
    if not names:
        return None
    exclude = (exclude_skill_id or "").strip()
    if exclude:
        names = [n for n in names if n != exclude]
    if not names:
        return None
    # ì»¨í…ìŠ¤íŠ¸ë¡œ ë„˜ê¸°ëŠ” ìŠ¤í‚¬ ê°œìˆ˜ëŠ” ìµœëŒ€ 3ê°œ
    names = names[:3]

    # Prefer MCP (find_helpful_skills + read_skill_document) for doc lists/content.
    # Fall back to HTTP get_skill_files/get_skill_file_content when MCP doesn't have the skill.
    docs_map = await _find_helpful_skills_documents(
        tenant_id=tenant_id,
        allowed_skill_names=names,
        task_description=task_description,
    )

    parts: List[str] = []
    total = 0
    cap = _RELATED_SKILL_CONTEXT_CAP

    for skill_name in names:
        if total >= cap:
            break

        # ---- summary + file list ----
        try:
            # MCP-first
            try:
                content = (await _read_skill_document(skill_name, "SKILL.md") or "").strip()
            except Exception:
                info = get_skill_file_content(skill_name, "SKILL.md")
                content = (info.get("content") or "").strip()
            summary = content[:_RELATED_SKILL_SUMMARY_CHARS]
            if len(content) > _RELATED_SKILL_SUMMARY_CHARS:
                summary += "..."
            block = f"\n[ê´€ë ¨ ìŠ¤í‚¬: {skill_name}]\nìš”ì•½:\n{summary}\n"
        except Exception as e:
            log(f"   âš ï¸ ê´€ë ¨ ìŠ¤í‚¬ SKILL.md ì¡°íšŒ ì‹¤íŒ¨ ({skill_name}), ê±´ë„ˆëœ€: {e}")
            continue

        paths: List[str] = []
        # MCP doc list if available
        paths = [p for p in (docs_map.get(skill_name, []) or []) if p and p != "SKILL.md"]
        if not paths:
            # HTTP fallback
            try:
                files = get_skill_files(skill_name) or []
                for fi in files:
                    p = (fi.get("path") or "").strip()
                    if p and p != "SKILL.md":
                        paths.append(p)
            except Exception as e:
                log(f"   âš ï¸ ê´€ë ¨ ìŠ¤í‚¬ íŒŒì¼ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ ({skill_name}): {e}")
        # keep deterministic and short
        paths = list(dict.fromkeys(paths))
        block += f"íŒŒì¼ ëª©ë¡: {paths}\n"
        block += f"ì°¸ì¡° ì‹œ ê²½ë¡œ í˜•ì‹(í•„ìˆ˜): {skill_name}/í´ë”/íŒŒì¼ (ì˜ˆ: {skill_name}/references/workflows.md)\n"

        part_len = len(block)
        if total + part_len > cap:
            block = block[: cap - total]
            part_len = len(block)
        parts.append(block)
        total += part_len

        # ---- file heads ----
        for path in paths:
            if total >= cap:
                break
            try:
                # MCP-first, HTTP fallback
                try:
                    c = (await _read_skill_document(skill_name, path) or "").strip()
                except Exception:
                    fc = get_skill_file_content(skill_name, path)
                    c = (fc.get("content") or "").strip()
                head = c[:_RELATED_SKILL_FILE_HEAD_CHARS]
                if len(c) > _RELATED_SKILL_FILE_HEAD_CHARS:
                    head += "..."
                line = f"\n--- [{path}] ---\n{head}\n"
                line_len = len(line)
                if total + line_len > cap:
                    line = line[: cap - total]
                    line_len = len(line)
                parts.append(line)
                total += line_len
            except Exception as e:
                log(f"   âš ï¸ ê´€ë ¨ ìŠ¤í‚¬ íŒŒì¼ ë‚´ìš© ì¡°íšŒ ì‹¤íŒ¨ ({skill_name}/{path}): {e}")

    if not parts:
        return None
    return "".join(parts).strip()


_SKILL_CREATOR_SYSTEM = """You implement the skill-creator workflow. Given user feedback and (for UPDATE) existing skill content, produce a JSON object that will become SKILL.md and bundled files. Follow skill-creator rules. Aim for the same depth and structure as built-in skills (e.g. skill-creator, doc-coauthoring): concrete procedures, principles, reference paths, and examples.

- name: hyphen-case (e.g. my-investment-skill). For UPDATE use the provided existing name.
- description: 1â€“2 sentences for frontmatter; include WHAT the skill does and WHEN to use it.
- overview: short body overview (used only when body_markdown is omitted).
- steps: list of strings, e.g. ["Step one", "Step two"]. Used only when body_markdown is omitted.
- usage: optional string. Used only when body_markdown is omitted.
- body_markdown: (optional, strongly recommended) Full markdown body for SKILL.md **without frontmatter**. When provided, overview/steps/usage are ignored for the body. Keep under ~500 lines. Include: Overview, When to Use (if needed), Core Principles or Capabilities, step-by-step process (with ### subsections where helpful), explicit references to bundled files, code blocks and tables where useful. If you add additional_files, the body must reference each of them (path + one-line purpose) for progressive disclosure. **Reference path format**: for files in *this* skill use `folder/file` (e.g. `references/guide.md`, `scripts/run.py`); for files in *related* (external) skills always use `skill-name/folder/file` (e.g. `skill-creator/references/workflows.md`). Related-skill references MUST include the skill name prefix.
- additional_files: dict of path -> full content. **CRITICAL**:
  - Include ONLY (a) NEW files with **complete** content, (b) EXISTING files you are **explicitly modifying** with **full** new content.
  - Do NOT include existing files that you are not modifyingâ€”they will be preserved automatically.
  - NEVER use placeholders like "content about X", "# code for X", "# code to X". Always provide full, runnable code or full document text.
  - For NEW files: write complete implementation (entire script or entire reference doc). One-line stubs are forbidden.
  - **references/** (e.g. references/*.md): Write as **professional reference docs**: clear ##/### sections, optional table of contents for long docs, "when to read this file" note, code examples, tables, best practices. Avoid one- or two-sentence stub content.
  - **scripts/** (e.g. scripts/*.py): Write **runnable, complete implementations**: module/function docstrings (purpose, args, returns, usage), error handling, type hints where appropriate. No one-line stubs or TODO-only files.
  - **assets/**: Only include files the agent can actually use or modify (templates, boilerplate). Omit if not needed; if included, ensure they are usable as-is.

For UPDATE: preserve existing structure, sections, and files; integrate feedback as additions or refinements. Do not drop existing steps, overview, or files. Merge feedback into the existing content. When modifying a file in additional_files, apply the same quality bar (references = professional reference; scripts = full runnable code).
When [ê´€ê³„ ë¶„ì„] indicates EXTENDS or COMPLEMENTS: **preserve all existing content**; only add or refine from feedback. Do not remove existing steps or files. For additional_files, include only new files or files you are actually changingâ€”omit the rest.

LANGUAGE RULES (CRITICAL):
- Detect the primary language of the user feedback (Korean vs English).
- **All humanâ€‘readable natural language text** in SKILL.md and any Markdown/reference files
  MUST be written in the **same language as the feedback**.
- When the feedback is in Korean, write all narrative text, headings, explanations,
  overviews, and steps in clear, natural Korean. Do NOT translate them to English.
- Skill identifiers MUST remain stable and English-friendly:
  - `name` field: keep in hyphenated English (e.g. my-investment-skill).
  - File and directory names under additional_files (e.g. scripts/*.py, references/*.md)
    should be in English and snake_case / hyphen-case as appropriate.
- Code inside scripts (Python, etc.) should use English identifiers and comments unless
  the feedback explicitly requests Korean comments.

If there is any conflict between previous instructions and these language rules,
the language rules take precedence for natural-language content.

When [ê´€ë ¨ ìŠ¤í‚¬ ì°¸ê³ ] is provided: use the listed skills and their file paths to add **explicit references** in overview, usage, or markdown body so that reference graphs can show cross-skill edges. **Reference path rule**: references to files *inside the current skill* use `folder/file` (e.g. `references/guide.md`). References to files in *related (external) skills* MUST use `skill-name/folder/file` (e.g. `skill-creator/references/workflows.md`). Never use bare `folder/file` for external skillsâ€”always prefix with the skill name. Do not invent paths; use the skill names and file paths from the context.

Output only valid JSON. No markdown, no explanation. Example: {"name":"x","description":"...","overview":"...","steps":["a","b"],"usage":"","body_markdown":null,"additional_files":{}}"""


async def _generate_skill_artifact_from_feedback(
    feedback_content: str,
    operation: str,
    skill_id: Optional[str],
    existing_skill_md: Optional[str],
    existing_additional_files: Optional[Dict[str, str]],
    relationship_analysis: Optional[str] = None,
    related_skills_context: Optional[str] = None,
) -> Dict:
    """skill-creator ê°€ì´ë“œì— ë”°ë¼ í”¼ë“œë°±ê³¼(ì„ íƒ) ê¸°ì¡´ ìŠ¤í‚¬ ë‚´ìš©ìœ¼ë¡œë¶€í„° skill_artifact JSONì„ ìƒì„±."""
    from langchain_core.messages import SystemMessage, HumanMessage

    # ì…ë ¥ í”¼ë“œë°± ì–¸ì–´ë¥¼ ê°ì§€í•˜ì—¬ skill-creatorì—ê²Œ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬
    lang = _detect_feedback_language(feedback_content)
    if lang == "ko":
        lang_hint = (
            "ì…ë ¥ í”¼ë“œë°±ì˜ ì£¼ìš” ì–¸ì–´ëŠ” **í•œêµ­ì–´**ì…ë‹ˆë‹¤.\n"
            "- SKILL.mdì˜ ì„¤ëª…, ê°œìš”, ë‹¨ê³„(steps), ì‚¬ìš©ë²•(usage)ê³¼ "
            "ì¶”ê°€ ë§ˆí¬ë‹¤ìš´/ë ˆí¼ëŸ°ìŠ¤ íŒŒì¼ì˜ ë³¸ë¬¸ì€ ëª¨ë‘ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”.\n"
            "- ìŠ¤í‚¬ ì´ë¦„(name)ê³¼ íŒŒì¼/ë””ë ‰í„°ë¦¬ ê²½ë¡œ, ì½”ë“œ(ì˜ˆ: scripts/*.py)ëŠ” ì˜ì–´ ì‹ë³„ìë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n"
            "- ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ì‘ì„±í–ˆë”ë¼ë„, ìŠ¤í‚¬ ì´ë¦„ê³¼ ì½”ë“œ êµ¬ì¡° ìì²´ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­/ì •ê·œí™”í•´ë„ ë©ë‹ˆë‹¤. "
            "í•˜ì§€ë§Œ ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë°”ê¾¸ë©´ ì•ˆ ë©ë‹ˆë‹¤."
        )
    else:
        lang_hint = (
            "The primary language of the feedback appears to be **English**.\n"
            "- Write all humanâ€‘readable descriptions, overviews, steps, usage text, and "
            "Markdown/reference file bodies in natural English.\n"
            "- Skill `name` and file/directory paths should remain concise, English identifiers.\n"
            "- Code inside scripts should use English identifiers and comments unless explicitly told otherwise."
        )

    user_parts = [lang_hint, f"\ní”¼ë“œë°±:\n{feedback_content}"]
    if relationship_analysis and str(relationship_analysis).strip():
        user_parts.append(f"\n[ê´€ê³„ ë¶„ì„ (EXTENDS/COMPLEMENTS ì‹œ ê¸°ì¡´ ë‚´ìš© ë³´ì¡´ì— ì°¸ê³ )]\n{relationship_analysis[:6000]}")
    if related_skills_context and str(related_skills_context).strip():
        user_parts.append(f"\n[ê´€ë ¨ ìŠ¤í‚¬ ì°¸ê³  (ì°¸ì¡° ê²½ë¡œÂ·ë§í¬ ìƒì„±ì— í™œìš©)]\n{related_skills_context}")
    if operation == "UPDATE" and skill_id:
        user_parts.append(f"\nê¸°ì¡´ ìŠ¤í‚¬ ì´ë¦„ (ë°˜ë“œì‹œ nameì— ì‚¬ìš©): {skill_id}")
        if existing_skill_md:
            user_parts.append(f"\nê¸°ì¡´ SKILL.md:\n{existing_skill_md[:8000]}")
        if existing_additional_files:
            paths = list(existing_additional_files.keys())
            user_parts.append(f"\nê¸°ì¡´ additional_files ê²½ë¡œ ëª©ë¡ (ìˆ˜ì •í•  ë•Œë§Œ additional_filesì— ë„£ê³ , ì „ì²´ ë‚´ìš©ì„ ì‘ì„±. ìˆ˜ì •í•˜ì§€ ì•Šìœ¼ë©´ ë„£ì§€ ë§ ê²ƒâ€”ìë™ ìœ ì§€ë¨): {paths}")
            # ìˆ˜ì • ì‹œ ì°¸ê³ í•  ìˆ˜ ìˆë„ë¡ íŒŒì¼ë³„ ì•ë¶€ë¶„ ì „ë‹¬ (í† í° ì œí•œ: íŒŒì¼ë‹¹ ~2000ì, ì´ ~20000ì)
            total, cap = 0, 20000
            for p, c in list(existing_additional_files.items()):
                if not c or total >= cap:
                    continue
                head = c[:2000] + ("..." if len(c) > 2000 else "")
                user_parts.append(f"\n--- ê¸°ì¡´ íŒŒì¼ ì°¸ê³  (ìˆ˜ì • ì‹œì—ë§Œ êµì²´) [{p}] ---\n{head}")
                total += len(head)

    llm = create_llm()
    msgs = [SystemMessage(content=_SKILL_CREATOR_SYSTEM), HumanMessage(content="\n".join(user_parts))]
    out = await llm.ainvoke(msgs)
    raw = (getattr(out, "content", None) or "") if out else ""
    raw = (raw or "").strip()
    for prefix in ("```json", "```"):
        if raw.startswith(prefix):
            raw = raw[len(prefix):].lstrip()
        if raw.endswith("```"):
            raw = raw[:-3].rstrip()
    try:
        obj = json.loads(raw)
    except json.JSONDecodeError as e:
        log(f"   [skill-creator LLM] JSON íŒŒì‹± ì‹¤íŒ¨: {e}, raw ì• 400ì: {repr(raw[:400])}")
        raise RuntimeError(f"skill-creator LLM ì¶œë ¥ JSON íŒŒì‹± ì‹¤íŒ¨: {e}") from e
    if not isinstance(obj, dict):
        raise RuntimeError("skill-creator LLM ì¶œë ¥ì´ JSON ê°ì²´ê°€ ì•„ë‹˜")
    if operation == "UPDATE" and skill_id:
        obj["name"] = skill_id
    if not obj.get("name") and operation == "CREATE":
        obj["name"] = "feedback-skill"
    return obj


def _is_placeholder_overwrite(new_val: str, old_val: Optional[str]) -> bool:
    """
    LLMì´ ê¸°ì¡´ íŒŒì¼ì„ í”Œë ˆì´ìŠ¤í™€ë”('content about X', '# code for X' ë“±)ë¡œ ë®ì–´ì“¸ ë•Œ
    Trueë¥¼ ë°˜í™˜. ì´ ê²½ìš° ê¸°ì¡´ ë‚´ìš©ì„ ìœ ì§€í•˜ê³  ìƒˆ ê°’ì„ ë²„ë¦°ë‹¤.
    """
    if not old_val or len(old_val) < 400:
        return False
    if not new_val or len(new_val) < 250:
        return True
    low = new_val.lower()
    if any(ph in low for ph in ("content about", "# code for", "# code to ")):
        if len(new_val) < 900:
            return True
    if len(new_val) < len(old_val) * 0.08:
        return True
    return False


def _record_attempted_skill_history(
    *,
    skill_name: str,
    operation: str,
    skill_content_dict: Dict[str, str],
    previous_content: Optional[Dict[str, str]],
    agent_id: str,
    tenant_id: Optional[str],
    feedback_content: Optional[str],
    error: Exception,
) -> None:
    """ì‹¤íŒ¨ ì‹œì—ë„ ì˜ë„ëœ ìˆ˜ì • ë‚´ì—­(ì „ì²´ íŒŒì¼ dict)ì„ JSONìœ¼ë¡œ ë³€ê²½ ì´ë ¥ì— ë‚¨ê¹ë‹ˆë‹¤."""
    try:
        err_msg = (str(error)[:500]) if error else ""
        new_d = dict(skill_content_dict)
        new_d["SKILL.md"] = (new_d.get("SKILL.md") or "") + (
            f"\n\n<!-- [ì´ë ¥] skill-creator ë°˜ì˜ ì‹¤íŒ¨: {err_msg} -->" if err_msg else ""
        )
        record_knowledge_history(
            knowledge_type="SKILL",
            knowledge_id=skill_name,
            agent_id=agent_id,
            tenant_id=tenant_id,
            operation=operation,
            previous_content=previous_content,
            new_content=new_d,
            feedback_content=feedback_content,
            knowledge_name=skill_name,
        )
        log(f"   ğŸ“ ì‹¤íŒ¨í•œ ì‹œë„ì— ëŒ€í•œ ë³€ê²½ ì´ë ¥ ê¸°ë¡ ì™„ë£Œ: {skill_name}")
    except Exception as e2:
        log(f"   âš ï¸ ì‹¤íŒ¨ ì‹œ ì´ë ¥ ê¸°ë¡ ì‹¤íŒ¨ (ë¬´ì‹œ): {e2}")


async def commit_to_skill_via_skill_creator(
    agent_id: str,
    operation: str,
    skill_id: Optional[str] = None,
    feedback_content: Optional[str] = None,
    merge_mode: Optional[str] = None,
    skill_artifact: Optional[Dict] = None,
    relationship_analysis: Optional[str] = None,
    related_skill_ids: Optional[str] = None,
) -> None:
    """
    computer-use + skill-creatorë¡œ ìŠ¤í‚¬ì„ ìƒì„±/ê°±ì‹ í•œ ë’¤ skill_api_clientë¡œ ì—…ë¡œë“œ.
    skill_artifactê°€ Noneì´ë©´ í”¼ë“œë°±ê³¼(UPDATEì‹œ) ê¸°ì¡´ ìŠ¤í‚¬ì„ ë°”íƒ•ìœ¼ë¡œ skill-creator(LLM)ê°€ ìƒì„±.
    relationship_analysisê°€ ìˆìœ¼ë©´ ìŠ¤í‚¬ ìƒì„± LLM ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬(EXTENDS/COMPLEMENTS ì‹œ ê¸°ì¡´ ë‚´ìš© ë³´ì¡´).
    related_skill_idsê°€ ìˆìœ¼ë©´ í•´ë‹¹ ìŠ¤í‚¬ë“¤ì˜ ìš”ì•½Â·ê²½ë¡œÂ·ì•ë¶€ë¶„ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì „ë‹¬(ìŠ¤í‚¬ ê°„ ì°¸ì¡° ìƒì„±ìš©).
    CREATE/UPDATEë§Œ ì²˜ë¦¬ (DELETEëŠ” í˜¸ì¶œí•˜ì§€ ì•ŠìŒ).
    """
    # ----- skill_artifactê°€ ì—†ìœ¼ë©´ skill-creator(LLM)ê°€ í”¼ë“œë°±ì—ì„œ ìƒì„± -----
    if skill_artifact is None:
        if not feedback_content or not str(feedback_content).strip():
            raise ValueError("feedback_contentê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. skill-creatorê°€ ìŠ¤í‚¬ ë‚´ìš©ì„ ìƒì„±í•˜ë ¤ë©´ í”¼ë“œë°±ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        if operation == "UPDATE" and (not skill_id or not str(skill_id).strip()):
            raise ValueError("UPDATE ì‹œ skill_id(ê¸°ì¡´ ìŠ¤í‚¬ ì´ë¦„)ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        existing_md: Optional[str] = None
        existing_files: Optional[Dict[str, str]] = None
        if operation == "UPDATE" and skill_id:
            try:
                info = get_skill_file_content(skill_id, "SKILL.md")
                existing_md = info.get("content") or ""
            except Exception as e:
                log(f"   âš ï¸ ê¸°ì¡´ SKILL.md ì¡°íšŒ ì‹¤íŒ¨: {e}")
            try:
                existing_files = {}
                for fi in get_skill_files(skill_id) or []:
                    p = fi.get("path", "")
                    if not p or p == "SKILL.md":
                        continue
                    fc = get_skill_file_content(skill_id, p)
                    c = fc.get("content", "")
                    if c is not None:
                        existing_files[p] = c
            except Exception as e:
                log(f"   âš ï¸ ê¸°ì¡´ additional_files ì¡°íšŒ ì‹¤íŒ¨: {e}")
        related_skills_context: Optional[str] = None
        if related_skill_ids and str(related_skill_ids).strip():
            try:
                agent_info_for_related = _get_agent_by_id(agent_id)
                tenant_id_for_related = agent_info_for_related.get("tenant_id") if agent_info_for_related else None
            except Exception:
                tenant_id_for_related = None
            related_skills_context = await _build_related_skills_context(
                related_skill_ids=related_skill_ids,
                exclude_skill_id=skill_id if operation == "UPDATE" else None,
                tenant_id=tenant_id_for_related,
                task_description=(feedback_content or "")[:200] or "related skills context",
            )
            if related_skills_context:
                log(f"   ê´€ë ¨ ìŠ¤í‚¬ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ ({len(related_skills_context)}ì)")
        log("   skill-creator(LLM)ê°€ í”¼ë“œë°±ìœ¼ë¡œ ìŠ¤í‚¬ ë‚´ìš© ìƒì„± ì¤‘...")
        skill_artifact = await _generate_skill_artifact_from_feedback(
            feedback_content=feedback_content,
            operation=operation,
            skill_id=skill_id,
            existing_skill_md=existing_md,
            existing_additional_files=existing_files,
            relationship_analysis=relationship_analysis,
            related_skills_context=related_skills_context,
        )
        log(f"   ìƒì„±ëœ ìŠ¤í‚¬ name={skill_artifact.get('name')}, steps={len(skill_artifact.get('steps') or [])}")

    skill_name = (skill_id or skill_artifact.get("name") or "").strip()
    if not skill_name:
        raise ValueError("skill_nameì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. skill_id ë˜ëŠ” skill_artifact.name í•„ìš”.")

    steps = skill_artifact.get("steps", [])
    description = skill_artifact.get(
        "description",
        f"{skill_name} ì‘ì—…ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•œ ë‹¨ê³„ë³„ ì ˆì°¨ì…ë‹ˆë‹¤.",
    )
    overview = skill_artifact.get("overview")
    usage = skill_artifact.get("usage")
    body_markdown = skill_artifact.get("body_markdown")
    art_files = skill_artifact.get("additional_files") or {}

    agent_info = _get_agent_by_id(agent_id)
    if not agent_info:
        raise ValueError(f"ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {agent_id}")
    tenant_id = agent_info.get("tenant_id")
    if not tenant_id:
        raise ValueError(f"ì—ì´ì „íŠ¸ì˜ tenant_idê°€ ì—†ìŠµë‹ˆë‹¤: {agent_id}")

    # ----- 1) ê¸°ì¡´ ìŠ¤í‚¬ ìˆ˜ì§‘ (UPDATE) -----
    existing_files: Dict[str, str] = {}
    previous_content_dict: Optional[Dict[str, str]] = None
    if operation == "UPDATE":
        if not check_skill_exists(skill_name):
            log(f"   âš ï¸ UPDATE ëŒ€ìƒ ìŠ¤í‚¬ì´ ì—†ì–´ CREATEë¡œ ì²˜ë¦¬: {skill_name}")
            operation = "CREATE"
        else:
            try:
                info = get_skill_file_content(skill_name, "SKILL.md")
                prev = info.get("content", "")
                if prev:
                    existing_files["SKILL.md"] = prev
            except Exception as e:
                log(f"   âš ï¸ ê¸°ì¡´ SKILL.md ì¡°íšŒ ì‹¤íŒ¨: {e}")
            for fi in get_skill_files(skill_name) or []:
                path = fi.get("path", "")
                if not path or path == "SKILL.md":
                    continue
                try:
                    fc = get_skill_file_content(skill_name, path)
                    c = fc.get("content", "")
                    if c is not None:
                        existing_files[path] = c
                except Exception as e:
                    log(f"   âš ï¸ ê¸°ì¡´ íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨ {path}: {e}")
            # ë³€ê²½ ì´ë ¥ìš©: ë®ì–´ì“°ê¸° ì „ ìƒíƒœ ë³´ê´€ (JSONìœ¼ë¡œ ì €ì¥)
            previous_content_dict = dict(existing_files)
            # artifactë¡œ ë®ì–´ì“°ê¸° (í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ê¸°ì¡´ ë³¸ë¬¸ì´ ë‚ ì•„ê°€ëŠ” ê²ƒ ë°©ì§€)
            for k, v in art_files.items():
                if _is_placeholder_overwrite(v, existing_files.get(k)):
                    log(f"   [additional_files] í”Œë ˆì´ìŠ¤í™€ë” ê°ì§€, ê¸°ì¡´ ìœ ì§€: {k}")
                    continue
                existing_files[k] = v
            art_files = existing_files

    # CREATE: artifactë§Œ (body_markdown ìˆìœ¼ë©´ ë³¸ë¬¸ìœ¼ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ overview+steps+usage)
    skill_content = _format_skill_document(
        skill_name,
        steps,
        description=description,
        overview=overview,
        usage=usage,
        body_markdown=body_markdown,
    )

    # ----- 2) skill-creator ìŠ¤í¬ë¦½íŠ¸ ì¡°íšŒ -----
    log("   skill-creator ìŠ¤í¬ë¦½íŠ¸ ì¡°íšŒ (read_skill_document)...")
    init_script = await _read_skill_document("skill-creator", "scripts/init_skill.py")
    package_script = await _read_skill_document("skill-creator", "scripts/package_skill.py")
    quick_validate_script = get_quick_validate_script()

    # ----- 3) computer-use: create_session -----
    log("   computer-use create_session...")
    cr = await _invoke_tool(_TOOL_CREATE_SESSION, ttl=600)
    session_id = _extract_session_id(cr)
    if not session_id:
        _log_create_session_debug(cr)
        raise RuntimeError("create_sessionì—ì„œ session_idë¥¼ ì–»ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    try:
        work = "/tmp/skill_work"
        base = f"/tmp/{skill_name}"
        skill_path = base

        # ----- 4) /tmp/skill_workì— ìŠ¤í¬ë¦½íŠ¸ ìƒì„± -----
        await _invoke_tool(_TOOL_RUN_SHELL, session_id=session_id, command=f"mkdir -p {work}")
        await _invoke_tool(_TOOL_CREATE_FILE, session_id=session_id, file_path=f"{work}/quick_validate.py", content=quick_validate_script)
        await _invoke_tool(_TOOL_CREATE_FILE, session_id=session_id, file_path=f"{work}/package_skill.py", content=package_script)
        await _invoke_tool(_TOOL_CREATE_FILE, session_id=session_id, file_path=f"{work}/init_skill.py", content=init_script)

        if operation == "CREATE":
            # init_skill
            await _invoke_tool(_TOOL_RUN_SHELL, session_id=session_id, command=f"python3 {work}/init_skill.py {skill_name} --path /tmp")
            # SKILL.md ë®ì–´ì“°ê¸°
            await _invoke_tool(_TOOL_CREATE_FILE, session_id=session_id, file_path=f"{base}/SKILL.md", content=skill_content)
            # additional_files
            for path, content in art_files.items():
                await _invoke_tool(_TOOL_RUN_SHELL, session_id=session_id, command=f"mkdir -p {base}/{str(Path(path).parent)}")
                await _invoke_tool(_TOOL_CREATE_FILE, session_id=session_id, file_path=f"{base}/{path}", content=content)
            # init ê¸°ë³¸ ì˜ˆì œ ì œê±° (additional_filesì— ì—†ìœ¼ë©´)
            for ex in [f"{base}/scripts/example.py", f"{base}/references/api_reference.md", f"{base}/assets/example_asset.txt"]:
                try:
                    await _invoke_tool(_TOOL_DELETE_FILE, session_id=session_id, file_path=ex)
                except Exception:
                    pass
        else:
            # UPDATE: ë””ë ‰í„°ë¦¬ ë° íŒŒì¼ ì§ì ‘ ìƒì„±
            await _invoke_tool(_TOOL_RUN_SHELL, session_id=session_id, command=f"mkdir -p {base}/scripts {base}/references {base}/assets")
            await _invoke_tool(_TOOL_CREATE_FILE, session_id=session_id, file_path=f"{base}/SKILL.md", content=skill_content)
            for path, content in art_files.items():
                await _invoke_tool(_TOOL_RUN_SHELL, session_id=session_id, command=f"mkdir -p {base}/{str(Path(path).parent)}")
                await _invoke_tool(_TOOL_CREATE_FILE, session_id=session_id, file_path=f"{base}/{path}", content=content)

        # ----- 5) quick_validate -----
        rv = await _invoke_tool(_TOOL_RUN_SHELL, session_id=session_id, command=f"cd {work} && python3 quick_validate.py {base}")
        out = _extract_text(rv)
        if "Skill is valid" not in out and "valid" not in out.lower():
            raise RuntimeError(f"quick_validate ì‹¤íŒ¨: {out[:500]}")

        # ----- 6) package_skill -----
        pkg_run = await _invoke_tool(_TOOL_RUN_SHELL, session_id=session_id, command=f"cd {work} && python3 package_skill.py {base} /tmp")
        pkg_out = _extract_text(pkg_run)
        pkg = f"/tmp/{skill_name}.skill"

        # .skill íŒŒì¼ ì¡´ì¬ í™•ì¸ (package_skill ì‹¤íŒ¨ ì‹œ ìƒì„±ë˜ì§€ ì•ŠìŒ. ì¡°ê¸° ì‹¤íŒ¨ë¡œ ì›ì¸ íŒŒì•… ìš©ì´)
        check_run = await _invoke_tool(
            _TOOL_RUN_SHELL,
            session_id=session_id,
            command=f'python3 -c \'import os; print("READY" if os.path.isfile("{pkg}") else "MISSING")\'',
        )
        check_txt = (_extract_text(check_run) or "").strip()
        if "READY" not in check_txt:
            log(f"   âš ï¸ .skill ì¡´ì¬ í™•ì¸: check_txt={repr(check_txt)}, package_skill ì¶œë ¥ ì¼ë¶€: {repr(pkg_out[:500])}")
            raise RuntimeError(
                f".skill íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {pkg}. "
                f"package_skillì´ ì‹¤íŒ¨í–ˆê±°ë‚˜ ì¶œë ¥ ê²½ë¡œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. package_skill ì¶œë ¥: {pkg_out[:800]}"
            )

        # ----- 7) .skill íšŒìˆ˜ (base64, í…ìŠ¤íŠ¸ stdoutë¡œ ì¶œë ¥í•´ MCP ìº¡ì²˜ ì•ˆì •í™”) -----
        rb = await _invoke_tool(
            _TOOL_RUN_SHELL,
            session_id=session_id,
            command=f'python3 -c \'import base64; d=open("{pkg}","rb").read(); print(base64.b64encode(d).decode("ascii"), end="")\'',
        )
        # [ë””ì½”ë”© ë””ë²„ê·¸] run_shell ì‘ë‹µ êµ¬ì¡°
        log(f"   [base64] run_shell ì‘ë‹µ: type={type(rb).__name__}")
        if isinstance(rb, dict):
            for k in list(rb.keys())[:12]:
                v = rb[k]
                if isinstance(v, str):
                    log(f"   [base64]   rb[{k!r}] str len={len(v)}, ì•200={repr(v[:200])}, ë’¤100={repr(v[-100:])}")
                elif isinstance(v, list):
                    texts = [x.get("text", x) if isinstance(x, dict) else str(x) for x in v[:5]]
                    lens = [len(t) if isinstance(t, str) else 0 for t in texts]
                    log(f"   [base64]   rb[{k!r}] list len={len(v)}, ìš”ì†Œ0~4 textê¸¸ì´={lens}, í•©={sum(lens)}")
                    if texts and isinstance(texts[0], str) and texts[0]:
                        log(f"   [base64]     [0] ì•120={repr(texts[0][:120])}, ë’¤80={repr(texts[0][-80:])}")
                else:
                    log(f"   [base64]   rb[{k!r}]={type(v).__name__}")
        raw = _extract_text(rb)
        log(f"   [base64] _extract_text(rb) â†’ len={len(raw)}, ì•250={repr(raw[:250])}, ë’¤250={repr(raw[-250:])}")

        # run_shell ì‹¤íŒ¨ ì‹œ stderr(íŠ¸ë ˆì´ìŠ¤ë°±)ê°€ ë°˜í™˜ë  ìˆ˜ ìˆìŒ. base64 ë””ì½”ë”© ì „ ê²€ì‚¬
        if raw and (
            "FileNotFoundError" in raw
            or "No such file or directory" in raw
            or ("STDERR:" in raw and "Traceback" in raw)
        ):
            raise RuntimeError(
                f".skill íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ base64 ì½ê¸° ëª…ë ¹ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {pkg}. "
                f"run_shellì´ stderr(íŠ¸ë ˆì´ìŠ¤ë°±)ë¥¼ ë°˜í™˜í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. package_skill ì¶œë ¥ ê²½ë¡œÂ·ì‹¤í–‰ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”. ì›ë¬¸: {raw[:500]}"
            )
        try:
            zip_bytes = _normalize_and_decode_base64(raw)
        except Exception as e:
            log(f"   âš ï¸ .skill base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
            raise RuntimeError(f".skill base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}") from e

    except Exception as e:
        _record_attempted_skill_history(
            skill_name=skill_name,
            operation=operation,
            skill_content_dict={"SKILL.md": skill_content, **art_files},
            previous_content=previous_content_dict,
            agent_id=agent_id,
            tenant_id=tenant_id,
            feedback_content=feedback_content,
            error=e,
        )
        raise

    finally:
        try:
            await _invoke_tool(_TOOL_DELETE_SESSION, session_id=session_id)
        except Exception as e:
            log(f"   âš ï¸ delete_session ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

    # ----- 8) zip íŒŒì‹±: skill_content + additional_files -----
    # ----- 9) skill_api_clientë¡œ ì—…ë¡œë“œ/ìˆ˜ì • ë° ì´ë ¥ -----
    try:
        prefix = f"{skill_name}/"
        out_content = ""
        out_files: Dict[str, str] = {}
        with zipfile.ZipFile(io.BytesIO(zip_bytes), "r") as zf:
            for n in zf.namelist():
                if n.endswith("/"):
                    continue
                if n == f"{prefix}SKILL.md" or n == f"{skill_name}\\SKILL.md":
                    out_content = zf.read(n).decode("utf-8", errors="replace")
                    continue
                if n.startswith(prefix):
                    rel = n[len(prefix) :]
                elif n.startswith(skill_name + "\\"):
                    rel = n[len(skill_name) + 1 :].replace("\\", "/")
                else:
                    continue
                if rel == "SKILL.md":
                    out_content = zf.read(n).decode("utf-8", errors="replace")
                    continue
                try:
                    out_files[rel] = zf.read(n).decode("utf-8", errors="replace")
                except Exception:
                    pass
        if not out_content:
            raise RuntimeError(".skill ë‚´ SKILL.mdë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ë³€ê²½ ì´ë ¥: ëª¨ë“  íŒŒì¼ì„ JSON êµ¬ì¡°ë¡œ ì €ì¥ (TEXT ì»¬ëŸ¼ì— json.dumps)
        new_content_dict: Dict[str, str] = {"SKILL.md": out_content, **out_files}

        if operation == "CREATE":
            upload_skill(skill_name=skill_name, skill_content=out_content, tenant_id=tenant_id, additional_files=out_files or None)
            update_agent_and_tenant_skills(agent_id, skill_name, "CREATE")
            record_knowledge_history(
                knowledge_type="SKILL",
                knowledge_id=skill_name,
                agent_id=agent_id,
                tenant_id=tenant_id,
                operation="CREATE",
                new_content=new_content_dict,
                feedback_content=feedback_content,
                knowledge_name=skill_name,
            )
            log(f"   âœ… SKILL(skill-creator) CREATE ì™„ë£Œ: {skill_name}")
        else:
            update_skill_file(skill_name, "SKILL.md", content=out_content)
            for p, c in out_files.items():
                try:
                    update_skill_file(skill_name, p, content=c)
                except Exception as e:
                    log(f"   âš ï¸ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ {p}: {e}")
            update_agent_and_tenant_skills(agent_id, skill_name, "UPDATE")
            record_knowledge_history(
                knowledge_type="SKILL",
                knowledge_id=skill_name,
                agent_id=agent_id,
                tenant_id=tenant_id,
                operation="UPDATE",
                previous_content=previous_content_dict,
                new_content=new_content_dict,
                feedback_content=feedback_content,
                knowledge_name=skill_name,
            )
            log(f"   âœ… SKILL(skill-creator) UPDATE ì™„ë£Œ: {skill_name}")
    except Exception as e:
        _record_attempted_skill_history(
            skill_name=skill_name,
            operation=operation,
            skill_content_dict={"SKILL.md": out_content, **out_files},
            previous_content=previous_content_dict,
            agent_id=agent_id,
            tenant_id=tenant_id,
            feedback_content=feedback_content,
            error=e,
        )
        raise
