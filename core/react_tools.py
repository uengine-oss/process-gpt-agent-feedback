"""
ReAct ì—ì´ì „íŠ¸ìš© ë„êµ¬ ì •ì˜
ê¸°ì¡´ í•¨ìˆ˜ë“¤ì„ LangChain Toolë¡œ ë˜í•‘
"""

import json
import re
from typing import Any, Dict, List, Optional
from pydantic import BaseModel, Field
from langchain_core.tools import StructuredTool
from utils.logger import log, handle_error

# Pydantic v2 model_validatorë¥¼ ìœ„í•œ import
try:
    from pydantic import model_validator
except ImportError:
    # Pydantic v1 í˜¸í™˜ì„±
    try:
        from pydantic import root_validator as model_validator
        # v1ì—ì„œëŠ” mode ì¸ìë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ wrapper í•¨ìˆ˜ í•„ìš”
        def _model_validator_wrapper(mode='before'):
            def decorator(func):
                if mode == 'before':
                    return model_validator(pre=True)(func)
                return func
            return decorator
        model_validator = _model_validator_wrapper
    except ImportError:
        model_validator = None

# ê¸°ì¡´ ëª¨ë“ˆ import
from core.knowledge_retriever import (
    retrieve_existing_memories,
    retrieve_existing_dmn_rules,
    retrieve_existing_skills,
    retrieve_all_existing_knowledge,
    SKILL_SEARCH_CONTEXT_CHARS,
)
from core.learning_committers import (
    commit_to_memory,
    commit_to_dmn_rule,
    commit_to_skill
)
from core.conflict_analyzer import analyze_knowledge_conflict
from core.semantic_matcher import get_semantic_matcher


# ============================================================================
# ë„êµ¬ ì…ë ¥ ìŠ¤í‚¤ë§ˆ ì •ì˜
# ============================================================================

class SearchMemoryInput(BaseModel):
    """ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬ ì…ë ¥"""
    query: str = Field(..., description="ê²€ìƒ‰ ì¿¼ë¦¬ (í”¼ë“œë°± ë‚´ìš© ë˜ëŠ” í‚¤ì›Œë“œ)")
    limit: int = Field(default=10, description="ìµœëŒ€ ê²°ê³¼ ìˆ˜")


class SearchDmnRulesInput(BaseModel):
    """DMN ê·œì¹™ ê²€ìƒ‰ ë„êµ¬ ì…ë ¥"""
    search_text: str = Field(default="", description="ê²€ìƒ‰ í‚¤ì›Œë“œ")


class SearchSkillsInput(BaseModel):
    """Skills ê²€ìƒ‰ ë„êµ¬ ì…ë ¥"""
    search_text: str = Field(default="", description="ê²€ìƒ‰ í‚¤ì›Œë“œ ë˜ëŠ” ì‘ì—… ì„¤ëª…")
    top_k: int = Field(default=10, description="ìµœëŒ€ ê²°ê³¼ ìˆ˜")


class AnalyzeConflictInput(BaseModel):
    """ì¶©ëŒ ë¶„ì„ ë„êµ¬ ì…ë ¥"""
    new_knowledge_json: str = Field(..., description="ìƒˆë¡œìš´ ì§€ì‹ì„ JSON ë¬¸ìì—´ë¡œ ì „ë‹¬ (ì˜ˆ: '{\"content\": \"...\"}' ë˜ëŠ” '{\"dmn\": {\"name\": \"...\", \"condition\": \"...\", \"action\": \"...\"}}' ë˜ëŠ” '{\"skill\": {\"name\": \"...\", \"steps\": [...]}}')")
    existing_knowledge_json: str = Field(..., description="ê¸°ì¡´ ì§€ì‹ì„ JSON ë¬¸ìì—´ë¡œ ì „ë‹¬ (ì˜ˆ: '{\"memories\": [...], \"dmn_rules\": [...], \"skills\": [...]}')")
    target_type: str = Field(..., description="ì €ì¥ ëŒ€ìƒ íƒ€ì… (MEMORY | DMN_RULE | SKILL)")


class CommitMemoryInput(BaseModel):
    """ë©”ëª¨ë¦¬ ì €ì¥ ë„êµ¬ ì…ë ¥"""
    content: str = Field(..., description="ì €ì¥í•  ë©”ëª¨ë¦¬ ë‚´ìš©")
    operation: str = Field(default="CREATE", description="ì‘ì—… íƒ€ì… (CREATE | UPDATE | DELETE)")
    memory_id: Optional[str] = Field(default=None, description="UPDATE/DELETE ì‹œ ê¸°ì¡´ ë©”ëª¨ë¦¬ ID")


class CommitDmnRuleInput(BaseModel):
    """DMN ê·œì¹™ ì €ì¥ ë„êµ¬ ì…ë ¥"""
    dmn_artifact_json: str = Field(..., description="DMN ê·œì¹™ ì •ë³´ë¥¼ JSON ë¬¸ìì—´ë¡œ ì „ë‹¬. ë‹¨ì¼ ê·œì¹™: '{\"name\": \"ê·œì¹™ ì´ë¦„\", \"condition\": \"ì¡°ê±´\", \"action\": \"ê²°ê³¼\"}'. ì—¬ëŸ¬ ê·œì¹™: '{\"name\": \"ê·œì¹™ ì´ë¦„\", \"rules\": [{\"condition\": \"ì¡°ê±´1\", \"action\": \"ê²°ê³¼1\"}, {\"condition\": \"ì¡°ê±´2\", \"action\": \"ê²°ê³¼2\"}]}'. ì—¬ëŸ¬ ê·œì¹™ì´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë³‘í•©ë©ë‹ˆë‹¤.")
    operation: str = Field(default="CREATE", description="âš ï¸ ì‘ì—… íƒ€ì… (CREATE | UPDATE | DELETE). ìœ ì‚¬í•œ ê¸°ì¡´ ê·œì¹™ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ UPDATEë¥¼ ì‚¬ìš©í•˜ê³  rule_idë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ì„¸ìš”!")
    rule_id: Optional[str] = Field(default=None, description="âš ï¸ UPDATE/DELETE ì‹œ í•„ìˆ˜! ê¸°ì¡´ ê·œì¹™ ID (search_similar_knowledge ë˜ëŠ” search_dmn_rules ê²°ê³¼ì—ì„œ ì–»ì€ ID)")
    feedback_content: str = Field(default="", description="ì›ë³¸ í”¼ë“œë°± ë‚´ìš© (ì„ íƒì )")
    merge_mode: Optional[str] = Field(default="REPLACE", description="ë³‘í•© ëª¨ë“œ (REPLACE | EXTEND | REFINE). EXTEND: ê¸°ì¡´ ê·œì¹™ ë³´ì¡´ + ìƒˆ ê·œì¹™ ì¶”ê°€. REFINE: ê¸°ì¡´ ê·œì¹™ ì°¸ì¡° í›„ ì¼ë¶€ ìˆ˜ì •. REPLACE: ì™„ì „ ëŒ€ì²´ (ê¸°ë³¸ê°’)")


class AttachSkillsToAgentInput(BaseModel):
    """ê¸°ì¡´ ìŠ¤í‚¬ì„ ì—ì´ì „íŠ¸ì— ì ì¬í•˜ëŠ” ë„êµ¬ ì…ë ¥ (ìŠ¤í‚¬ ìƒì„±/ìˆ˜ì • ì—†ìŒ)"""
    skill_ids: str = Field(
        ...,
        description="ì—ì´ì „íŠ¸ì— ì ì¬í•  ê¸°ì¡´ ìŠ¤í‚¬ ì´ë¦„/IDë¥¼ ì‰¼í‘œ êµ¬ë¶„ (ì˜ˆ: 'skill-a, skill-b'). search_similar_knowledgeì—ì„œ ì°¾ì€ ìŠ¤í‚¬ ID ì‚¬ìš©."
    )


class CommitSkillInput(BaseModel):
    """Skill ì €ì¥ ë„êµ¬ ì…ë ¥

    ReActì€ **ì–´ë–¤ ì§€ì‹ ì €ì¥ì†Œì—(SKILL)**Â·**ê¸°ì¡´ ì§€ì‹ê³¼ì˜ ê´€ê³„(CREATE/UPDATE/DELETE, skill_id)**ë§Œ íŒë‹¨í•©ë‹ˆë‹¤.
    ìŠ¤í‚¬ ë§ˆí¬ë‹¤ìš´Â·stepsÂ·additional_files ë“± **ìŠ¤í‚¬ ë‚´ìš© ìƒì„±ì€ ì „ë¶€ skill-creator ìŠ¤í‚¬**ì´ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    í”¼ë“œë°±(feedback_content)ì€ ë„êµ¬ ì™¸ë¶€ì—ì„œ ìë™ ì „ë‹¬ë©ë‹ˆë‹¤.
    """
    operation: str = Field(
        default="CREATE",
        description="ì‘ì—… íƒ€ì… (CREATE | UPDATE | DELETE). ê´€ë ¨ ìŠ¤í‚¬ì´ ìˆìœ¼ë©´ UPDATE, ì—†ìœ¼ë©´ CREATE."
    )
    skill_id: Optional[str] = Field(
        default=None,
        description="UPDATE/DELETE ì‹œ í•„ìˆ˜. ê¸°ì¡´ ìŠ¤í‚¬ ì´ë¦„(id). CREATE ì‹œì—ëŠ” ë¹„ì›Œë‘ ."
    )
    merge_mode: Optional[str] = Field(
        default="MERGE",
        description="UPDATE ì‹œ ë³‘í•© ëª¨ë“œ (MERGE | REPLACE). MERGE: ê¸°ì¡´ ë³´ì¡´+ë³€ê²½ ë°˜ì˜. REPLACE: ì „ì²´ êµì²´.",
    )
    relationship_analysis: Optional[str] = Field(
        default=None,
        description="search_similar_knowledge ê²°ê³¼(ê´€ê³„ ìœ í˜• ë¶„í¬Â·ìƒì„¸ ë¶„ì„)ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬. EXTENDS/COMPLEMENTS ì‹œ ê¸°ì¡´ ë‚´ìš© ë³´ì¡´ì— í™œìš©. ìˆìœ¼ë©´ ë°˜ë“œì‹œ ì „ë‹¬í•˜ì„¸ìš”.",
    )
    related_skill_ids: Optional[str] = Field(
        default=None,
        description="search_similar_knowledgeì—ì„œ ì°¾ì€ ê´€ë ¨ ìŠ¤í‚¬ ì´ë¦„/IDë¥¼ ì‰¼í‘œ êµ¬ë¶„ ë¬¸ìì—´ë¡œ ì „ë‹¬ (ì˜ˆ: 'skill-a, skill-b'). ìˆìœ¼ë©´ ì „ë‹¬í•˜ë©´ ìŠ¤í‚¬ ê°„ ì°¸ì¡° ìƒì„±ì— í™œìš©ë©ë‹ˆë‹¤.",
    )


# ============================================================================
# ìƒˆë¡œìš´ í†µí•© ë„êµ¬ ìŠ¤í‚¤ë§ˆ (Phase 2: ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜)
# ============================================================================

class SearchSimilarKnowledgeInput(BaseModel):
    """í†µí•© ìœ ì‚¬ ì§€ì‹ ê²€ìƒ‰ ë„êµ¬ ì…ë ¥ (ë‹¨ìˆœí™”)"""
    content: str = Field(..., description="ê²€ìƒ‰í•  ì§€ì‹ ë‚´ìš© (í”¼ë“œë°± ë‚´ìš© ë˜ëŠ” ì €ì¥í•˜ë ¤ëŠ” ì§€ì‹)")
    knowledge_type: str = Field(
        default="ALL",
        description="ê²€ìƒ‰ ëŒ€ìƒ íƒ€ì… (MEMORY | DMN_RULE | SKILL | ALL)"
    )
    threshold: float = Field(
        default=0.7,
        description="ìœ ì‚¬ë„ ì„ê³„ê°’ (0.0-1.0). ì´ ê°’ ì´ìƒì˜ ìœ ì‚¬ë„ë¥¼ ê°€ì§„ ì§€ì‹ë§Œ ë°˜í™˜"
    )


class CheckDuplicateInput(BaseModel):
    """ì¤‘ë³µ í™•ì¸ ë„êµ¬ ì…ë ¥ (ë‹¨ìˆœí™”)"""
    content: str = Field(..., description="ì¤‘ë³µ ì—¬ë¶€ë¥¼ í™•ì¸í•  ìƒˆë¡œìš´ ì§€ì‹ ë‚´ìš©")
    knowledge_type: str = Field(..., description="ì§€ì‹ íƒ€ì… (MEMORY | DMN_RULE | SKILL)")
    candidate_id: Optional[str] = Field(
        default=None,
        description="íŠ¹ì • ê¸°ì¡´ ì§€ì‹ê³¼ ë¹„êµí•  ê²½ìš° í•´ë‹¹ ID. ì—†ìœ¼ë©´ ëª¨ë“  ê¸°ì¡´ ì§€ì‹ê³¼ ë¹„êµ"
    )


class DetermineOperationInput(BaseModel):
    """ì‘ì—… ê²°ì • ë„êµ¬ ì…ë ¥ (ë‹¨ìˆœí™”)"""
    content: str = Field(..., description="ì €ì¥í•˜ë ¤ëŠ” ìƒˆë¡œìš´ ì§€ì‹ ë‚´ìš©")
    knowledge_type: str = Field(..., description="ì§€ì‹ íƒ€ì… (MEMORY | DMN_RULE | SKILL)")
    
    if model_validator:
        @model_validator(mode='before')
        @classmethod
        def parse_kwargs_input(cls, data):
            """kwargs í˜•ì‹ ì…ë ¥ì„ ì²˜ë¦¬í•˜ëŠ” validator"""
            if isinstance(data, dict):
                # content í•„ë“œì— kwargs í˜•ì‹ ë¬¸ìì—´ì´ ë“¤ì–´ìˆëŠ” ê²½ìš° íŒŒì‹±
                if 'content' in data and isinstance(data['content'], str):
                    content_value = data['content']
                    if 'knowledge_type=' in content_value:
                        log(f"ğŸ”§ DetermineOperationInput: kwargs í˜•ì‹ ì…ë ¥ ê°ì§€, íŒŒì‹± ì‹œë„...")
                        log(f"   ì…ë ¥ê°’: {content_value[:200]}...")
                        
                        # content ì¶”ì¶œ
                        content_match = re.search(r'content\s*=\s*["\']([^"\']*)["\']', content_value)
                        if content_match:
                            data['content'] = content_match.group(1)
                            log(f"   ì¶”ì¶œëœ content: {data['content'][:100]}...")
                        else:
                            # content=...knowledge_type= í˜•íƒœì—ì„œ content ë¶€ë¶„ë§Œ ì¶”ì¶œ
                            content_end = content_value.find('knowledge_type=')
                            if content_end > 0:
                                content_part = content_value[:content_end].strip()
                                if content_part.startswith('content='):
                                    data['content'] = content_part[8:].strip().strip("'\"")
                                    log(f"   ì¶”ì¶œëœ content (í›„ì²˜ë¦¬): {data['content'][:100]}...")
                        
                        # knowledge_type ì¶”ì¶œ (ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì— ìˆìœ¼ë©´ ë®ì–´ì“°ì§€ ì•ŠìŒ)
                        if 'knowledge_type' not in data or not data.get('knowledge_type'):
                            type_match = re.search(r'knowledge_type\s*=\s*["\']?([^"\'",\s]+)["\']?', content_value)
                            if type_match:
                                data['knowledge_type'] = type_match.group(1)
                                log(f"   ì¶”ì¶œëœ knowledge_type: {data['knowledge_type']}")
            
            return data


class GetKnowledgeDetailInput(BaseModel):
    """ê¸°ì¡´ ì§€ì‹ ìƒì„¸ ì¡°íšŒ ë„êµ¬ ì…ë ¥"""
    knowledge_type: str = Field(
        default="AUTO",
        description="ì§€ì‹ íƒ€ì… (MEMORY | DMN_RULE | SKILL | AUTO). AUTOë©´ IDë¡œ ëª¨ë“  íƒ€ì…ì—ì„œ ì¡°íšŒë¥¼ ì‹œë„í•©ë‹ˆë‹¤.",
    )
    knowledge_id: str = Field(default="", description="ì¡°íšŒí•  ì§€ì‹ ID/ì´ë¦„ (í•„ìˆ˜). ReAct í…ìŠ¤íŠ¸ ì—ì´ì „íŠ¸ì˜ ê²½ìš° JSONì´ ë¬¸ìì—´ë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆì–´ ë„êµ¬ì—ì„œ ë³µêµ¬í•©ë‹ˆë‹¤.")


# ============================================================================
# ë„êµ¬ í•¨ìˆ˜ ì •ì˜
# ============================================================================

async def _search_memory_tool(agent_id: str, query: str, limit: int = 10) -> str:
    """
    mem0ì—ì„œ ê´€ë ¨ ë©”ëª¨ë¦¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ (í¬ë§·ëœ í…ìŠ¤íŠ¸)
    """
    try:
        memories = await retrieve_existing_memories(agent_id, query, limit)
        
        if not memories:
            return "ê´€ë ¨ ë©”ëª¨ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        result_lines = [f"ì´ {len(memories)}ê°œì˜ ê´€ë ¨ ë©”ëª¨ë¦¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n"]
        for idx, mem in enumerate(memories, start=1):
            memory_text = mem.get("memory", "")
            score = mem.get("score", 0)
            mem_id = mem.get("id", f"memory_{idx}")
            result_lines.append(f"[{idx}] ID: {mem_id}, ê´€ë ¨ë„: {score:.2f}")
            result_lines.append(f"    ë‚´ìš©: {memory_text[:300]}...")
            result_lines.append("")
        
        return "\n".join(result_lines)
    except Exception as e:
        handle_error("search_memory_tool", e)
        return f"ë©”ëª¨ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"


async def _search_dmn_rules_tool(agent_id: str, search_text: str = "") -> str:
    """
    DMN ê·œì¹™ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        search_text: ê²€ìƒ‰ í‚¤ì›Œë“œ
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ (í¬ë§·ëœ í…ìŠ¤íŠ¸)
    """
    try:
        rules = await retrieve_existing_dmn_rules(agent_id, search_text)
        
        if not rules:
            return "ê´€ë ¨ DMN ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤."
        
        result_lines = [f"ì´ {len(rules)}ê°œì˜ DMN ê·œì¹™ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n"]
        for idx, rule in enumerate(rules, start=1):
            rule_id = rule.get("id", "")
            rule_name = rule.get("name", "")
            bpmn = rule.get("bpmn", "")
            result_lines.append(f"[{idx}] ID: {rule_id}, ì´ë¦„: {rule_name}")
            result_lines.append(f"    XML ë‚´ìš©: {bpmn[:200]}...")
            result_lines.append("")
        
        return "\n".join(result_lines)
    except Exception as e:
        handle_error("search_dmn_rules_tool", e)
        return f"DMN ê·œì¹™ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"


async def _search_skills_tool(agent_id: str, search_text: str = "", top_k: int = 10) -> str:
    """
    Skillsë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        search_text: ê²€ìƒ‰ í‚¤ì›Œë“œ ë˜ëŠ” ì‘ì—… ì„¤ëª…
        top_k: ìµœëŒ€ ê²°ê³¼ ìˆ˜
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ (í¬ë§·ëœ í…ìŠ¤íŠ¸)
    """
    try:
        # ì—ì´ì „íŠ¸ ì •ë³´ ì¡°íšŒí•˜ì—¬ tenant_id ê°€ì ¸ì˜¤ê¸°
        from core.database import _get_agent_by_id
        agent_info = _get_agent_by_id(agent_id)
        tenant_id = agent_info.get("tenant_id") if agent_info else None
        agent_skills = agent_info.get("skills") if agent_info else None
        
        skills = await retrieve_existing_skills(agent_id, search_text, top_k, tenant_id=tenant_id, agent_skills=agent_skills)
        
        if not skills:
            return "ê´€ë ¨ Skillsê°€ ì—†ìŠµë‹ˆë‹¤."
        
        result_lines = [f"ì´ {len(skills)}ê°œì˜ Skillsë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n"]
        for idx, skill in enumerate(skills, start=1):
            skill_id = skill.get("id", skill.get("name", f"skill_{idx}"))
            skill_name = skill.get("name", skill.get("skill_name", "Unknown"))
            result_lines.append(f"[{idx}] ID: {skill_id}, ì´ë¦„: {skill_name}")
            if "description" in skill:
                result_lines.append(f"    ì„¤ëª…: {skill['description'][:200]}...")
            result_lines.append("")
        
        return "\n".join(result_lines)
    except Exception as e:
        handle_error("search_skills_tool", e)
        return f"Skills ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"


async def _analyze_conflict_tool(
    new_knowledge: Dict,
    existing_knowledge: Dict,
    target_type: str
) -> str:
    """
    ìƒˆë¡œìš´ ì§€ì‹ê³¼ ê¸°ì¡´ ì§€ì‹ ê°„ì˜ ì¶©ëŒì„ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Args:
        new_knowledge: ìƒˆë¡œìš´ ì§€ì‹ (content, dmn, skill ì¤‘ í•˜ë‚˜)
        existing_knowledge: ê¸°ì¡´ ì§€ì‹ (memories, dmn_rules, skills í¬í•¨)
        target_type: ì €ì¥ ëŒ€ìƒ íƒ€ì… (MEMORY | DMN_RULE | SKILL)
    
    Returns:
        ì¶©ëŒ ë¶„ì„ ê²°ê³¼ (JSON ë¬¸ìì—´)
    """
    try:
        result = await analyze_knowledge_conflict(new_knowledge, existing_knowledge, target_type)
        
        # ê²°ê³¼ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        operation = result.get("operation", "CREATE")
        conflict_level = result.get("conflict_level", "NONE")
        conflict_reason = result.get("conflict_reason", "")
        matched_item = result.get("matched_item")
        action_description = result.get("action_description", "")
        
        result_text = f"""ì¶©ëŒ ë¶„ì„ ê²°ê³¼:
- ì‘ì—…: {operation}
- ì¶©ëŒ ìˆ˜ì¤€: {conflict_level}
- ì´ìœ : {conflict_reason}
- ì‘ì—… ì„¤ëª…: {action_description}"""
        
        if matched_item:
            matched_id = matched_item.get("id", "Unknown")
            matched_content = matched_item.get("content", "")
            result_text += f"\n- ë§¤ì¹­ëœ í•­ëª© ID: {matched_id}"
            if matched_content:
                result_text += f"\n- ë§¤ì¹­ëœ í•­ëª© ë‚´ìš©: {matched_content[:200]}..."
        
        return result_text
    except Exception as e:
        handle_error("analyze_conflict_tool", e)
        return f"ì¶©ëŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"


async def _commit_memory_tool(
    agent_id: str,
    content: str,
    operation: str = "CREATE",
    memory_id: Optional[str] = None
) -> str:
    """
    mem0ì— ë©”ëª¨ë¦¬ë¥¼ ì €ì¥/ìˆ˜ì •/ì‚­ì œí•©ë‹ˆë‹¤.
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        content: ì €ì¥í•  ë‚´ìš©
        operation: CREATE | UPDATE | DELETE
        memory_id: UPDATE/DELETE ì‹œ ê¸°ì¡´ ë©”ëª¨ë¦¬ ID
    
    Returns:
        ì‘ì—… ê²°ê³¼ ë©”ì‹œì§€
    """
    try:
        await commit_to_memory(
            agent_id=agent_id,
            content=content,
            source_type="guideline",
            operation=operation,
            memory_id=memory_id
        )
        
        if operation == "CREATE":
            return f"âœ… ë©”ëª¨ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ì—ì´ì „íŠ¸: {agent_id})"
        elif operation == "UPDATE":
            return f"âœ… ë©”ëª¨ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {memory_id}, ì—ì´ì „íŠ¸: {agent_id})"
        elif operation == "DELETE":
            return f"âœ… ë©”ëª¨ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {memory_id}, ì—ì´ì „íŠ¸: {agent_id})"
        else:
            return f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—…: {operation}"
    except Exception as e:
        handle_error("commit_memory_tool", e)
        return f"âŒ ë©”ëª¨ë¦¬ ì €ì¥ ì‹¤íŒ¨: {str(e)}"


async def _commit_dmn_rule_tool(
    agent_id: str,
    dmn_artifact: Dict,
    operation: str = "CREATE",
    rule_id: Optional[str] = None,
    feedback_content: str = "",
    merge_mode: str = "REPLACE"
) -> str:
    """
    DMN ê·œì¹™ì„ ì €ì¥/ìˆ˜ì •/ì‚­ì œí•©ë‹ˆë‹¤.
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        dmn_artifact: DMN ê·œì¹™ ì •ë³´ (name, condition, action í¬í•¨)
        operation: CREATE | UPDATE | DELETE
        rule_id: UPDATE/DELETE ì‹œ ê¸°ì¡´ ê·œì¹™ ID
        feedback_content: ì›ë³¸ í”¼ë“œë°± ë‚´ìš© (ì„ íƒì )
        merge_mode: REPLACE | EXTEND | REFINE (ê¸°ë³¸ê°’: REPLACE)
    
    Returns:
        ì‘ì—… ê²°ê³¼ ë©”ì‹œì§€
    """
    try:
        # dmn_artifactë¥¼ ì™„ì „íˆ ì •ê·œí™”í•˜ëŠ” í•¨ìˆ˜ (ì¬ê·€ì ìœ¼ë¡œ condition/action ì¶”ì¶œ)
        def normalize_dmn_artifact(obj):
            """dmn_artifactë¥¼ ì •ê·œí™”í•˜ì—¬ condition, action, nameì„ í™•ì‹¤íˆ ì¶”ì¶œ"""
            if not isinstance(obj, dict):
                return obj
            
            # ì´ë¯¸ conditionê³¼ actionì´ ìµœìƒìœ„ì— ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if "condition" in obj and "action" in obj:
                condition = obj.get("condition", "")
                action = obj.get("action", "")
                if condition and action and isinstance(condition, str) and condition.strip() and isinstance(action, str) and action.strip():
                    return {
                        # ì´ë¦„ì´ ì—†ìœ¼ë©´ ë‚˜ì¤‘ ë‹¨ê³„ì—ì„œ ì•ˆì „í•˜ê²Œ ê¸°ë³¸ê°’ì„ ì ìš©
                        "name": obj.get("name"),
                        "condition": condition,
                        "action": action
                    }
            
            # ì¤‘ì²©ëœ dmn_artifact_jsonì—ì„œ ì°¾ê¸°
            if "dmn_artifact_json" in obj:
                nested = normalize_dmn_artifact(obj["dmn_artifact_json"])
                if isinstance(nested, dict) and "condition" in nested and "action" in nested:
                    return nested
            
            # rules ë°°ì—´ì—ì„œ ì°¾ê¸°
            if "rules" in obj and isinstance(obj.get("rules"), list):
                rules = obj["rules"]
                if len(rules) > 0:
                    first_rule = rules[0] if isinstance(rules[0], dict) else {}
                    condition = first_rule.get("condition") or first_rule.get("input", "")
                    action = first_rule.get("action") or first_rule.get("output", "")
                    if condition and action:
                        # ì—¬ëŸ¬ ê·œì¹™ì´ ìˆìœ¼ë©´ ë³‘í•©
                        if len(rules) > 1:
                            conditions = []
                            actions = []
                            for r in rules:
                                if isinstance(r, dict):
                                    c = r.get("condition") or r.get("input", "")
                                    a = r.get("action") or r.get("output", "")
                                    if c:
                                        conditions.append(c)
                                    if a:
                                        actions.append(a)
                            if conditions and actions:
                                merged_condition = " ë˜ëŠ” ".join([f"({c})" for c in conditions if c])
                                merged_action = "; ".join([a for a in actions if a])
                                return {
                                    "name": obj.get("name"),
                                    "condition": merged_condition,
                                    "action": merged_action
                                }
                        if condition and action:
                            return {
                                "name": obj.get("name"),
                                "condition": condition,
                                "action": action
                            }
            
            # ê·¸ ì™¸ì˜ ê²½ìš° ì›ë³¸ ë°˜í™˜ (í•˜ì§€ë§Œ condition/actionì´ ì—†ìœ¼ë©´ ë¬¸ì œ)
            return obj
        
        # dmn_artifact ì •ê·œí™”
        normalized_artifact = normalize_dmn_artifact(dmn_artifact)
        
        # ì •ê·œí™” í›„ì—ë„ conditionê³¼ actionì´ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not isinstance(normalized_artifact, dict) or not normalized_artifact.get("condition") or not normalized_artifact.get("action"):
            log(f"âš ï¸ _commit_dmn_rule_tool: ì •ê·œí™” í›„ì—ë„ condition/actionì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            try:
                log(f"   ì›ë³¸ dmn_artifact: {json.dumps(dmn_artifact, ensure_ascii=False, indent=2)}")
                log(f"   ì •ê·œí™”ëœ artifact: {json.dumps(normalized_artifact, ensure_ascii=False, indent=2)}")
            except Exception:
                log(f"   ì›ë³¸ dmn_artifact: {str(dmn_artifact)[:500]}")
                log(f"   ì •ê·œí™”ëœ artifact: {str(normalized_artifact)[:500]}")
            return f"âŒ DMN ê·œì¹™ ì €ì¥ ì‹¤íŒ¨: conditionê³¼ actionì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì „ë‹¬ëœ ë°ì´í„° êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        
        log(f"âœ… _commit_dmn_rule_tool: ì •ê·œí™” ì™„ë£Œ - condition={normalized_artifact.get('condition', '')[:50]}..., action={normalized_artifact.get('action', '')[:50]}...")
        
        await commit_to_dmn_rule(
            agent_id=agent_id,
            dmn_artifact=normalized_artifact,
            feedback_content=feedback_content,
            operation=operation,
            rule_id=rule_id,
            merge_mode=merge_mode
        )
        
        rule_name = dmn_artifact.get("name", "Unknown")
        if operation == "CREATE":
            return f"âœ… DMN ê·œì¹™ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (ì´ë¦„: {rule_name}, ì—ì´ì „íŠ¸: {agent_id})"
        elif operation == "UPDATE":
            return f"âœ… DMN ê·œì¹™ì´ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {rule_id}, ì´ë¦„: {rule_name}, ì—ì´ì „íŠ¸: {agent_id})"
        elif operation == "DELETE":
            return f"âœ… DMN ê·œì¹™ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {rule_id}, ì—ì´ì „íŠ¸: {agent_id})"
        else:
            return f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—…: {operation}"
    except Exception as e:
        handle_error("commit_dmn_rule_tool", e)
        return f"âŒ DMN ê·œì¹™ ì €ì¥ ì‹¤íŒ¨: {str(e)}"


async def _commit_skill_tool(
    agent_id: str,
    operation: str = "CREATE",
    skill_id: Optional[str] = None,
    merge_mode: str = "MERGE",
    feedback_content: Optional[str] = None,
    relationship_analysis: Optional[str] = None,
    related_skill_ids: Optional[str] = None,
) -> str:
    """
    Skillì„ ì €ì¥/ìˆ˜ì •/ì‚­ì œí•©ë‹ˆë‹¤. ReActì€ ì €ì¥ì†ŒÂ·ê´€ê³„(operation, skill_id)ë§Œ íŒë‹¨í•˜ê³ ,
    ìŠ¤í‚¬ ë‚´ìš©(SKILL.md, steps, additional_files)ì€ skill-creatorê°€ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        if operation == "DELETE":
            if not skill_id or not str(skill_id).strip():
                return "âŒ DELETEì—ëŠ” skill_id(ê¸°ì¡´ ìŠ¤í‚¬ ì´ë¦„)ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        elif operation == "UPDATE":
            if not skill_id or not str(skill_id).strip():
                return "âŒ UPDATEì—ëŠ” skill_id(ê¸°ì¡´ ìŠ¤í‚¬ ì´ë¦„)ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        elif operation == "CREATE":
            if not feedback_content or not str(feedback_content).strip():
                return "âŒ CREATEì—ëŠ” í”¼ë“œë°±ì´ í•„ìš”í•©ë‹ˆë‹¤. (skill-creatorê°€ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ìŠ¤í‚¬ì„ ìƒì„±í•©ë‹ˆë‹¤.)"

        await commit_to_skill(
            agent_id=agent_id,
            skill_artifact=None,
            operation=operation,
            skill_id=skill_id,
            merge_mode=merge_mode,
            feedback_content=feedback_content or "",
            relationship_analysis=relationship_analysis,
            related_skill_ids=related_skill_ids,
        )

        if operation == "CREATE":
            return f"âœ… Skillì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (skill-creatorê°€ ìƒì„±, ì—ì´ì „íŠ¸: {agent_id})"
        if operation == "UPDATE":
            return f"âœ… Skillì´ ì„±ê³µì ìœ¼ë¡œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {skill_id}, ì—ì´ì „íŠ¸: {agent_id})"
        if operation == "DELETE":
            return f"âœ… Skillì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤. (ID: {skill_id}, ì—ì´ì „íŠ¸: {agent_id})"
        return f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—…: {operation}"
    except Exception as e:
        handle_error("commit_skill_tool", e)
        return f"âŒ Skill ì €ì¥ ì‹¤íŒ¨: {str(e)}"


def _parse_skill_ids_input(skill_ids: Any) -> List[str]:
    """skill_ids ì…ë ¥ì„ íŒŒì‹±í•˜ì—¬ ìŠ¤í‚¬ëª… ë¦¬ìŠ¤íŠ¸ ë°˜í™˜. JSON/dict/ë¬¸ìì—´ ëª¨ë‘ ì²˜ë¦¬."""
    raw = skill_ids
    if raw is None:
        return []
    if isinstance(raw, dict):
        raw = raw.get("skill_ids", "") or ""
    if isinstance(raw, str) and raw.strip().startswith("{"):
        try:
            obj = json.loads(raw)
            if isinstance(obj, dict):
                raw = obj.get("skill_ids", "") or ""
            elif isinstance(obj, list):
                raw = ",".join(str(x) for x in obj)
        except (json.JSONDecodeError, TypeError):
            pass
    return [s.strip() for s in str(raw).split(",") if s.strip()]


async def _attach_skills_to_agent_tool(agent_id: str, skill_ids: Any) -> str:
    """
    ê¸°ì¡´ ìŠ¤í‚¬ì„ ì—ì´ì „íŠ¸ì— ì ì¬ë§Œ í•©ë‹ˆë‹¤. ìŠ¤í‚¬ ë‚´ìš©ì€ ìƒì„±/ìˆ˜ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ìœ ì‚¬ë„ê°€ ë†’ì€ ê¸°ì¡´ ìŠ¤í‚¬ë¡œ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        skill_ids: ì‰¼í‘œ êµ¬ë¶„ ìŠ¤í‚¬ ì´ë¦„/ID (ì˜ˆ: 'skill-a, skill-b') ë˜ëŠ” JSON {"skill_ids": "..."}

    Returns:
        ì²˜ë¦¬ ê²°ê³¼ ë©”ì‹œì§€
    """
    try:
        from core.database import (
            _get_agent_by_id,
            update_agent_and_tenant_skills,
            register_knowledge,
            record_knowledge_history,
        )
        from utils.logger import log

        skill_names = _parse_skill_ids_input(skill_ids)
        if not skill_names:
            return "âŒ skill_idsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì‰¼í‘œ êµ¬ë¶„ìœ¼ë¡œ ìŠ¤í‚¬ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”."

        agent_info = _get_agent_by_id(agent_id)
        if not agent_info:
            return f"âŒ ì—ì´ì „íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {agent_id}"
        tenant_id = agent_info.get("tenant_id")

        attached = []
        for skill_name in skill_names[:10]:  # ìµœëŒ€ 10ê°œ
            try:
                update_agent_and_tenant_skills(agent_id, skill_name, "CREATE")
                register_knowledge(
                    agent_id=agent_id,
                    tenant_id=tenant_id,
                    knowledge_type="SKILL",
                    knowledge_id=skill_name,
                    knowledge_name=skill_name,
                    content_summary=f"ê¸°ì¡´ ìŠ¤í‚¬ ì ì¬: {skill_name}",
                )
                record_knowledge_history(
                    knowledge_type="SKILL",
                    knowledge_id=skill_name,
                    agent_id=agent_id,
                    tenant_id=tenant_id,
                    operation="CREATE",
                    new_content={"source": "attach_existing_skill", "skill_name": skill_name},
                    feedback_content=None,
                    knowledge_name=skill_name,
                )
                attached.append(skill_name)
                log(f"âœ… ìŠ¤í‚¬ ì—ì´ì „íŠ¸ ì ì¬ ì™„ë£Œ: {skill_name} (agent_id={agent_id})")
            except Exception as e:
                log(f"âš ï¸ ìŠ¤í‚¬ ì ì¬ ì‹¤íŒ¨ ({skill_name}): {e}")
                # ê³„ì† ì§„í–‰

        if not attached:
            return f"âŒ ìŠ¤í‚¬ ì ì¬ ì‹¤íŒ¨: {', '.join(skill_names)}"
        return f"âœ… ê¸°ì¡´ ìŠ¤í‚¬ {len(attached)}ê°œë¥¼ ì—ì´ì „íŠ¸ì— ì ì¬í–ˆìŠµë‹ˆë‹¤: {', '.join(attached)}"
    except Exception as e:
        handle_error("attach_skills_to_agent_tool", e)
        return f"âŒ ìŠ¤í‚¬ ì ì¬ ì‹¤íŒ¨: {str(e)}"


# ============================================================================
# ìƒˆë¡œìš´ í†µí•© ë„êµ¬ í•¨ìˆ˜ (Phase 2: ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜)
# ============================================================================

async def _search_similar_knowledge_tool(
    agent_id: str,
    content: str,
    knowledge_type: str = "ALL",
    threshold: float = 0.7
) -> str:
    """
    ëª¨ë“  ì €ì¥ì†Œì—ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì§€ì‹ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ë¨¼ì € ì¡°íšŒí•˜ê³ , ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ê³„ì‚° í›„ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        content: ê²€ìƒ‰í•  ì§€ì‹ ë‚´ìš©
        knowledge_type: ê²€ìƒ‰ ëŒ€ìƒ íƒ€ì… (MEMORY | DMN_RULE | SKILL | ALL)
        threshold: ìœ ì‚¬ë„ ì„ê³„ê°’
    
    Returns:
        ìœ ì‚¬ ì§€ì‹ ê²€ìƒ‰ ê²°ê³¼ (í¬ë§·ëœ í…ìŠ¤íŠ¸)
    """
    try:
        from core.database import (
            _get_agent_by_id,
            get_agent_knowledge_list,
            register_knowledge,
            update_knowledge_access_time
        )
        from utils.logger import log
        
        # ì—ì´ì „íŠ¸ ì •ë³´ ì¡°íšŒ
        agent_info = _get_agent_by_id(agent_id)
        tenant_id = agent_info.get("tenant_id") if agent_info else None
        agent_skills = agent_info.get("skills") if agent_info else None
        
        results = []
        matcher = get_semantic_matcher()
        
        # ê²€ìƒ‰ ëŒ€ìƒ ê²°ì •
        search_memory = knowledge_type in ["ALL", "MEMORY"]
        search_dmn = knowledge_type in ["ALL", "DMN_RULE"]
        search_skill = knowledge_type in ["ALL", "SKILL"]
        
        # 1ë‹¨ê³„: í”¼ë“œë°±ê³¼ ì§ì ‘ ìœ ì‚¬í•œ ì§€ì‹ ì°¾ê¸°
        # MEMORY ê²€ìƒ‰
        if search_memory:
            memories = await retrieve_existing_memories(agent_id, content, limit=20)
            if memories:
                similar_memories = await matcher.find_similar_knowledge(
                    content, memories, "MEMORY", threshold
                )
                for item in similar_memories:
                    item["storage_type"] = "MEMORY"
                    results.append(item)
                    
                    # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡ ë° ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
                    try:
                        register_knowledge(
                            agent_id=agent_id,
                            tenant_id=tenant_id,
                            knowledge_type="MEMORY",
                            knowledge_id=item.get("id", ""),
                            knowledge_name=item.get("name", ""),
                            content_summary=item.get("content_summary", ""),
                            content=item.get("full_content", "")
                        )
                        update_knowledge_access_time(agent_id, "MEMORY", item.get("id", ""))
                    except Exception as e:
                        log(f"âš ï¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰): {e}")
        
        # DMN_RULE ê²€ìƒ‰
        if search_dmn:
            dmn_rules = await retrieve_existing_dmn_rules(agent_id, content[:100])
            if dmn_rules:
                similar_dmn = await matcher.find_similar_knowledge(
                    content, dmn_rules, "DMN_RULE", threshold
                )
                for item in similar_dmn:
                    item["storage_type"] = "DMN_RULE"
                    results.append(item)
                    
                    # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡ ë° ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
                    try:
                        register_knowledge(
                            agent_id=agent_id,
                            tenant_id=tenant_id,
                            knowledge_type="DMN_RULE",
                            knowledge_id=item.get("id", ""),
                            knowledge_name=item.get("name", ""),
                            content_summary=item.get("content_summary", "")
                        )
                        update_knowledge_access_time(agent_id, "DMN_RULE", item.get("id", ""))
                    except Exception as e:
                        log(f"âš ï¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰): {e}")
        
        # SKILL ê²€ìƒ‰
        if search_skill:
            skills = await retrieve_existing_skills(
                agent_id, content[:SKILL_SEARCH_CONTEXT_CHARS], top_k=20,
                tenant_id=tenant_id, agent_skills=agent_skills
            )
            if skills:
                similar_skills = await matcher.find_similar_knowledge(
                    content, skills, "SKILL", threshold
                )
                for item in similar_skills:
                    item["storage_type"] = "SKILL"
                    # ìˆ«ì/ì¸ë±ìŠ¤ í˜•íƒœ IDëŠ” ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡í•˜ì§€ ì•ŠìŒ (phantom SKILL:1 ë°©ì§€)
                    skill_id = item.get("id", "")
                    skill_name = item.get("name", "") or item.get("skill_name", "")
                    if isinstance(skill_id, int) or (isinstance(skill_id, str) and skill_id.isdigit()) or (
                        isinstance(skill_id, str) and skill_id.startswith("skill_") and len(skill_id) > 6 and skill_id[6:].isdigit()
                    ):
                        skill_id = skill_name or str(skill_id)
                    if not skill_id:
                        continue
                    item["id"] = skill_id
                    results.append(item)
                    
                    # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ë“±ë¡ ë° ì ‘ê·¼ ì‹œê°„ ì—…ë°ì´íŠ¸
                    try:
                        register_knowledge(
                            agent_id=agent_id,
                            tenant_id=tenant_id,
                            knowledge_type="SKILL",
                            knowledge_id=skill_id,
                            knowledge_name=skill_name or skill_id,
                            content_summary=item.get("content_summary", "")
                        )
                        update_knowledge_access_time(agent_id, "SKILL", skill_id)
                    except Exception as e:
                        log(f"âš ï¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë“±ë¡ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰): {e}")
        
        # 2ë‹¨ê³„: ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ê´€ë ¨ ì§€ì‹ ì¶”ê°€ ì¡°íšŒ (ì„ íƒì )
        # ì°¾ì€ ì§€ì‹ì´ ì ì„ ê²½ìš° ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ìœ ì‚¬í•œ ì§€ì‹ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
        if len(results) < 5:
            try:
                registry_knowledge = get_agent_knowledge_list(
                    agent_id=agent_id,
                    knowledge_type=knowledge_type if knowledge_type != "ALL" else None,
                    limit=50
                )
                
                # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì˜ ì§€ì‹ ì´ë¦„ì´ë‚˜ ìš”ì•½ì—ì„œ í”¼ë“œë°± ë‚´ìš©ê³¼ ìœ ì‚¬í•œ ê²ƒ ì°¾ê¸°
                for reg_item in registry_knowledge:
                    reg_name = reg_item.get("knowledge_name", "")
                    reg_summary = reg_item.get("content_summary", "")
                    
                    # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (ë” ì •êµí•œ ê²€ìƒ‰ì€ í•„ìš”ì‹œ ì¶”ê°€)
                    if reg_name and content.lower() in reg_name.lower():
                        # ì´ë¯¸ ê²°ê³¼ì— ìˆëŠ”ì§€ í™•ì¸
                        existing = any(
                            r.get("storage_type") == reg_item.get("knowledge_type") and
                            r.get("id") == reg_item.get("knowledge_id")
                            for r in results
                        )
                        if not existing:
                            results.append({
                                "id": reg_item.get("knowledge_id", ""),
                                "name": reg_item.get("knowledge_name", ""),
                                "storage_type": reg_item.get("knowledge_type", ""),
                                "similarity_score": 0.6,  # ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ì°¾ì€ ê²½ìš° ê¸°ë³¸ ì ìˆ˜
                                "relationship": "RELATED",
                                "relationship_reason": "ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ ì´ë¦„ ë§¤ì¹­ìœ¼ë¡œ ë°œê²¬",
                                "from_registry": True
                            })
            except Exception as e:
                log(f"âš ï¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¶”ê°€ ì¡°íšŒ ì‹¤íŒ¨ (ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰): {e}")
        
        if not results:
            return f"""ê´€ë ¨ëœ ê¸°ì¡´ ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ ì„ê³„ê°’: {threshold})

ì´ê²ƒì€ ì™„ì „íˆ ìƒˆë¡œìš´ ì§€ì‹ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
ìƒˆ í”¼ë“œë°±ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì €ì¥ì†Œ(MEMORY/DMN_RULE/SKILL)ì— ì €ì¥í• ì§€ íŒë‹¨í•˜ì„¸ìš”."""
        
        # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x.get("similarity_score", 0), reverse=True)
        
        # ê´€ê³„ ìœ í˜•ë³„ ê·¸ë£¹í™”
        relationship_groups = {}
        for item in results:
            rel = item.get("relationship", "UNKNOWN")
            if rel not in relationship_groups:
                relationship_groups[rel] = []
            relationship_groups[rel].append(item)
        
        # ê²°ê³¼ í¬ë§·íŒ… - ì—ì´ì „íŠ¸ê°€ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸ ì •ë³´ ì œê³µ
        output_lines = [f"ì´ {len(results)}ê°œì˜ ê´€ë ¨ ì§€ì‹ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n"]
        
        # ê´€ê³„ ìœ í˜• ìš”ì•½
        output_lines.append("ğŸ“Š ê´€ê³„ ìœ í˜• ë¶„í¬:")
        for rel_type, items in relationship_groups.items():
            output_lines.append(f"   - {rel_type}: {len(items)}ê°œ")
        output_lines.append("")
        
        # ìƒì„¸ ì •ë³´ (SKILLì€ í‘œì‹œìš© IDê°€ ìˆ«ì/ì¸ë±ìŠ¤ í˜•íƒœë©´ name ì‚¬ìš©)
        output_lines.append("ğŸ“‹ ìƒì„¸ ë¶„ì„ ê²°ê³¼:")
        for idx, item in enumerate(results[:10], start=1):  # ìƒìœ„ 10ê°œ
            storage = item.get("storage_type", "UNKNOWN")
            item_id = item.get("id", "Unknown")
            item_name = item.get("name", item_id)
            if storage == "SKILL" and item_id != item_name:
                sid = item_id
                if isinstance(sid, int) or (isinstance(sid, str) and sid.isdigit()) or (
                    isinstance(sid, str) and len(sid) > 6 and sid.startswith("skill_") and sid[6:].isdigit()
                ):
                    item_id = item_name or str(sid)
                    item["id"] = item_id
            score = item.get("similarity_score", 0)
            relationship = item.get("relationship", "UNKNOWN")
            rel_reason = item.get("relationship_reason", "")
            content_summary = item.get("content_summary", "")
            key_diffs = item.get("key_differences", [])
            key_sims = item.get("key_similarities", [])
            full_content = item.get("full_content", "")
            
            output_lines.append(f"\n[{idx}] {item_name}")
            output_lines.append(f"    ğŸ“ ì €ì¥ì†Œ: {storage}")
            output_lines.append(f"    ğŸ”‘ ID: {item_id}")
            output_lines.append(f"    ğŸ”— ê´€ê³„ ìœ í˜•: {relationship}")
            output_lines.append(f"    ğŸ“ ê´€ê³„ ë¶„ì„: {rel_reason}")
            
            if key_sims:
                output_lines.append(f"    âœ… ìœ ì‚¬ì : {', '.join(key_sims[:3])}")
            if key_diffs:
                output_lines.append(f"    âŒ ì°¨ì´ì : {', '.join(key_diffs[:3])}")
            
            if content_summary:
                output_lines.append(f"    ğŸ“„ ê¸°ì¡´ ì§€ì‹ ìš”ì•½: {content_summary[:200]}...")
            
            # ì „ì²´ ë‚´ìš©ë„ ì¼ë¶€ í¬í•¨ (ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ë¹„êµ ê°€ëŠ¥)
            if full_content:
                output_lines.append(f"    ğŸ“œ ê¸°ì¡´ ì§€ì‹ ë‚´ìš©: {full_content[:500]}...")
        
        # SKILL ì¬ì‚¬ìš© ê°€ì´ë“œ: ìœ ì‚¬ë„ ë†’ê³  DUPLICATE/COMPLEMENTSë©´ attach_skills_to_agent ê¶Œì¥
        skill_results = [r for r in results if r.get("storage_type") == "SKILL"]
        high_sim_skills = [
            r for r in skill_results
            if r.get("similarity_score", 0) >= 0.85
            and r.get("relationship", "") in ("DUPLICATE", "COMPLEMENTS", "EXTENDS")
        ]
        if high_sim_skills:
            skill_ids = [r.get("id", "") or r.get("name", "") for r in high_sim_skills[:5] if r.get("id") or r.get("name")]
            if skill_ids:
                output_lines.append("")
                output_lines.append("ğŸ“Œ **SKILL ì¬ì‚¬ìš© ê¶Œì¥:**")
                output_lines.append(f"   ìœ ì‚¬ë„ 0.85 ì´ìƒ + DUPLICATE/COMPLEMENTS/EXTENDS ê´€ê³„ì¸ ìŠ¤í‚¬ {len(skill_ids)}ê°œ ë°œê²¬.")
                output_lines.append("   ê¸°ì¡´ ìŠ¤í‚¬ë¡œ ìš”êµ¬ì‚¬í•­ì„ ì¶©ë¶„íˆ ì¶©ì¡±í•˜ë©´ **attach_skills_to_agent** ì‚¬ìš© ê¶Œì¥ (ìƒˆ ìŠ¤í‚¬ ìƒì„± ëŒ€ì‹ ).")
                output_lines.append(f"   ì˜ˆ: attach_skills_to_agent(skill_ids=\"{', '.join(skill_ids)}\")")

        output_lines.append("")
        output_lines.append("â”" * 50)
        output_lines.append("ğŸ§  ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ì ‘ íŒë‹¨í•˜ì„¸ìš”:")
        output_lines.append("   - ì´ í”¼ë“œë°±ì€ ê¸°ì¡´ ì§€ì‹ê³¼ ì–´ë–¤ ê´€ê³„ì¸ê°€?")
        output_lines.append("   - ê¸°ì¡´ ì§€ì‹ì„ ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì•¼ í•˜ë‚˜? (ìœ ì§€/ìˆ˜ì •/ì‚­ì œ/í™•ì¥/ì ì¬)")
        output_lines.append("   - **SKILL:** ëª©í‘œ/ê²°ê³¼(ì˜ˆ: ì˜ì‚¬ê²°ì • ê¸°ì—¬)ëŠ” ìŠ¤í‚¬ ì ˆì°¨ê°€ ì•„ë‹˜. êµ¬ì²´ì  ì ˆì°¨Â·ì‚°ì¶œë¬¼ì´ ê¸°ì¡´ ìŠ¤í‚¬ë¡œ ì»¤ë²„ë˜ë©´ attach_skills_to_agent ìš°ì„ , ìƒˆ ì ˆì°¨ê°€ í•„ìš”í•  ë•Œë§Œ commit_to_skill.")
        output_lines.append("   - ìƒˆ ì§€ì‹ì„ ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì•¼ í•˜ë‚˜? (ìƒì„±/ë³‘í•©/ë¬´ì‹œ/ê¸°ì¡´ ì ì¬)")
        output_lines.append("   - í•„ìš”í•˜ë‹¤ë©´ get_knowledge_detailë¡œ ê¸°ì¡´ ì§€ì‹ì˜ ì „ì²´ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")

        return "\n".join(output_lines)
        
    except Exception as e:
        handle_error("search_similar_knowledge_tool", e)
        return f"âŒ ìœ ì‚¬ ì§€ì‹ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}"


async def _check_duplicate_tool(
    agent_id: str,
    content: str,
    knowledge_type: str,
    candidate_id: Optional[str] = None
) -> str:
    """
    íŠ¹ì • ì§€ì‹ì´ ì¤‘ë³µì¸ì§€ ìƒì„¸ í™•ì¸í•©ë‹ˆë‹¤.
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        content: ìƒˆë¡œìš´ ì§€ì‹ ë‚´ìš©
        knowledge_type: ì§€ì‹ íƒ€ì…
        candidate_id: ë¹„êµí•  ê¸°ì¡´ ì§€ì‹ ID (ì—†ìœ¼ë©´ ê°€ì¥ ìœ ì‚¬í•œ ê²ƒê³¼ ë¹„êµ)
    
    Returns:
        ì¤‘ë³µ í™•ì¸ ê²°ê³¼ (í¬ë§·ëœ í…ìŠ¤íŠ¸)
    """
    try:
        from core.database import _get_agent_by_id
        
        agent_info = _get_agent_by_id(agent_id)
        tenant_id = agent_info.get("tenant_id") if agent_info else None
        agent_skills = agent_info.get("skills") if agent_info else None
        
        matcher = get_semantic_matcher()
        candidate = None
        
        # í›„ë³´ ì§€ì‹ ì¡°íšŒ
        if candidate_id:
            # íŠ¹ì • IDë¡œ ì¡°íšŒ
            if knowledge_type == "MEMORY":
                memories = await retrieve_existing_memories(agent_id, content, limit=50)
                candidate = next((m for m in memories if m.get("id") == candidate_id), None)
            elif knowledge_type == "DMN_RULE":
                dmn_rules = await retrieve_existing_dmn_rules(agent_id, "")
                candidate = next((r for r in dmn_rules if r.get("id") == candidate_id), None)
            elif knowledge_type == "SKILL":
                skills = await retrieve_existing_skills(
                    agent_id, "", top_k=100, tenant_id=tenant_id, agent_skills=agent_skills
                )
                candidate = next((s for s in skills if s.get("id") == candidate_id or s.get("name") == candidate_id), None)
        else:
            # ê°€ì¥ ìœ ì‚¬í•œ í•­ëª© ì°¾ê¸°
            existing = []
            if knowledge_type == "MEMORY":
                existing = await retrieve_existing_memories(agent_id, content, limit=20)
            elif knowledge_type == "DMN_RULE":
                existing = await retrieve_existing_dmn_rules(agent_id, content[:100])
            elif knowledge_type == "SKILL":
                existing = await retrieve_existing_skills(
                    agent_id, content[:SKILL_SEARCH_CONTEXT_CHARS], top_k=20,
                    tenant_id=tenant_id, agent_skills=agent_skills
                )
            
            if existing:
                similar = await matcher.find_similar_knowledge(content, existing, knowledge_type, 0.5)
                if similar:
                    best = max(similar, key=lambda x: x.get("similarity_score", 0))
                    candidate = best.get("original", existing[0])
        
        if not candidate:
            return f"ë¹„êµí•  ê¸°ì¡´ ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤.\nâœ… ê¶Œì¥ ì‘ì—…: CREATE (ìƒˆë¡œìš´ ì§€ì‹)"
        
        # ì¤‘ë³µ ìƒì„¸ ê²€ì¦
        result = await matcher.verify_duplicate(content, candidate, knowledge_type)
        
        # ê²°ê³¼ í¬ë§·íŒ…
        output_lines = [f"ì¤‘ë³µ ê²€ì¦ ê²°ê³¼:\n"]
        output_lines.append(f"ë¹„êµ ëŒ€ìƒ ID: {result.get('candidate_id', 'Unknown')}")
        output_lines.append(f"ì¤‘ë³µ ì—¬ë¶€: {'ì˜ˆ' if result.get('is_duplicate') else 'ì•„ë‹ˆì˜¤'}")
        output_lines.append(f"ì‹ ë¢°ë„: {result.get('confidence', 0):.2f}")
        output_lines.append(f"ê¶Œì¥ ì‘ì—…: {result.get('recommended_operation', 'CREATE')}")
        output_lines.append(f"íŒë‹¨ ì´ìœ : {result.get('reason', '')}")
        
        same_aspects = result.get("same_aspects", [])
        if same_aspects:
            output_lines.append(f"\në™ì¼í•œ ë¶€ë¶„:")
            for aspect in same_aspects[:5]:
                output_lines.append(f"  - {aspect}")
        
        diff_aspects = result.get("different_aspects", [])
        if diff_aspects:
            output_lines.append(f"\në‹¤ë¥¸ ë¶€ë¶„:")
            for aspect in diff_aspects[:5]:
                output_lines.append(f"  - {aspect}")
        
        return "\n".join(output_lines)
        
    except Exception as e:
        handle_error("check_duplicate_tool", e)
        return f"âŒ ì¤‘ë³µ í™•ì¸ ì‹¤íŒ¨: {str(e)}"


async def _determine_operation_tool(
    agent_id: str,
    content: str,
    knowledge_type: str
) -> str:
    """
    ìƒˆ ì§€ì‹ê³¼ ê¸°ì¡´ ì§€ì‹ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    (ì‘ì—… ê²°ì •ì€ ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ìˆ˜í–‰)
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        content: ìƒˆë¡œìš´ ì§€ì‹ ë‚´ìš©
        knowledge_type: ì§€ì‹ íƒ€ì…
    
    Returns:
        ê´€ê³„ ë¶„ì„ ê²°ê³¼ (ì—ì´ì „íŠ¸ê°€ íŒë‹¨í•  ì •ë³´ ì œê³µ)
    """
    try:
        from core.database import _get_agent_by_id
        
        agent_info = _get_agent_by_id(agent_id)
        tenant_id = agent_info.get("tenant_id") if agent_info else None
        agent_skills = agent_info.get("skills") if agent_info else None
        
        matcher = get_semantic_matcher()
        
        # ê¸°ì¡´ ì§€ì‹ ì¡°íšŒ
        existing = []
        if knowledge_type == "MEMORY":
            existing = await retrieve_existing_memories(agent_id, content, limit=20)
        elif knowledge_type == "DMN_RULE":
            existing = await retrieve_existing_dmn_rules(agent_id, content[:100])
        elif knowledge_type == "SKILL":
            existing = await retrieve_existing_skills(
                agent_id, content[:SKILL_SEARCH_CONTEXT_CHARS], top_k=20,
                tenant_id=tenant_id, agent_skills=agent_skills
            )
        
        if not existing:
            return f"""ğŸ“Š ê´€ê³„ ë¶„ì„ ê²°ê³¼:

ê¸°ì¡´ {knowledge_type} ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤.

ì´ê²ƒì€ ì™„ì „íˆ ìƒˆë¡œìš´ ì§€ì‹ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.
í”¼ë“œë°± ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆ ì§€ì‹ì„ ìƒì„±í• ì§€ ì§ì ‘ íŒë‹¨í•˜ì„¸ìš”."""
        
        # ìœ ì‚¬ ì§€ì‹ ë¶„ì„
        similar_items = await matcher.find_similar_knowledge(content, existing, knowledge_type, 0.5)
        
        # ê´€ê³„ ë¶„ì„ (ê²°ì • ì—†ì´ ì •ë³´ë§Œ)
        analysis = await matcher.analyze_relationship(content, similar_items, knowledge_type)
        
        output_lines = ["ğŸ“Š ê´€ê³„ ë¶„ì„ ê²°ê³¼:\n"]
        
        if not analysis.get("has_related_knowledge"):
            output_lines.append("ê´€ë ¨ëœ ê¸°ì¡´ ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            output_lines.append("ìƒˆë¡œìš´ ì§€ì‹ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")
        else:
            output_lines.append(f"ê´€ë ¨ ì§€ì‹ ìˆ˜: {analysis.get('total_related', 0)}ê°œ\n")
            
            # ê´€ê³„ ìš”ì•½
            rel_summary = analysis.get("relationship_summary", {})
            if rel_summary:
                output_lines.append("ğŸ“ˆ ê´€ê³„ ìœ í˜• ë¶„í¬:")
                for rel_type, count in rel_summary.items():
                    output_lines.append(f"   - {rel_type}: {count}ê°œ")
                output_lines.append("")
            
            # ìƒì„¸ ë¶„ì„
            output_lines.append("ğŸ“‹ ìƒì„¸ ë¶„ì„:")
            output_lines.append(analysis.get("analysis", ""))
            output_lines.append("")
            
            # ê´€ë ¨ ì§€ì‹ ìƒì„¸
            related_items = analysis.get("related_items", [])
            if related_items:
                output_lines.append("ğŸ” ê´€ë ¨ ì§€ì‹ ìƒì„¸:")
                for idx, item in enumerate(related_items[:5], start=1):
                    output_lines.append(f"\n  [{idx}] {item.get('name', item.get('id'))}")
                    output_lines.append(f"      ID: {item.get('id')}")
                    output_lines.append(f"      ê´€ê³„: {item.get('relationship')}")
                    output_lines.append(f"      ì´ìœ : {item.get('relationship_reason', '')}")
                    
                    key_diffs = item.get("key_differences", [])
                    if key_diffs:
                        output_lines.append(f"      ì°¨ì´ì : {', '.join(key_diffs[:3])}")
                    
                    full_content = item.get("full_content", "")
                    if full_content:
                        output_lines.append(f"      ë‚´ìš©: {full_content[:300]}...")
        
        output_lines.append("")
        output_lines.append("â”" * 50)
        output_lines.append("ğŸ§  ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ì ‘ íŒë‹¨í•˜ì„¸ìš”:")
        output_lines.append("   - DUPLICATE â†’ ì €ì¥í•˜ì§€ ì•ŠìŒ (IGNORE)")
        output_lines.append("   - EXTENDS â†’ ê¸°ì¡´ ì§€ì‹ì— ìƒˆ ë‚´ìš© ë³‘í•©")
        output_lines.append("   - REFINES â†’ ê¸°ì¡´ ì§€ì‹ì˜ í•´ë‹¹ ë¶€ë¶„ ìˆ˜ì •")
        output_lines.append("   - CONFLICTS â†’ ì–´ëŠ ê²ƒì´ ë§ëŠ”ì§€ íŒë‹¨ í•„ìš”")
        output_lines.append("   - EXCEPTION â†’ ì˜ˆì™¸ ê·œì¹™ìœ¼ë¡œ ì¶”ê°€")
        output_lines.append("   - UNRELATED â†’ ìƒˆë¡œ ìƒì„±")
        
        return "\n".join(output_lines)
        
    except Exception as e:
        handle_error("determine_operation_tool", e)
        return f"âŒ ê´€ê³„ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"


async def _get_knowledge_detail_tool(
    agent_id: str,
    knowledge_type: str,
    knowledge_id: str
) -> str:
    """
    ê¸°ì¡´ ì§€ì‹ì˜ ì „ì²´ ìƒì„¸ ë‚´ìš©ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    ì—ì´ì „íŠ¸ê°€ ê¸°ì¡´ ì§€ì‹ê³¼ ìƒˆ í”¼ë“œë°±ì„ ì§ì ‘ ë¹„êµí•˜ì—¬ ë³‘í•© ë°©ë²•ì„ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID
        knowledge_type: ì§€ì‹ íƒ€ì… (MEMORY | DMN_RULE | SKILL)
        knowledge_id: ì¡°íšŒí•  ì§€ì‹ ID
    
    Returns:
        ì§€ì‹ì˜ ì „ì²´ ìƒì„¸ ë‚´ìš©
    """
    try:
        from core.database import _get_agent_by_id
        
        agent_info = _get_agent_by_id(agent_id)
        tenant_id = agent_info.get("tenant_id") if agent_info else None
        agent_skills = agent_info.get("skills") if agent_info else None
        
        output_lines = [f"ğŸ“„ {knowledge_type} ìƒì„¸ ì¡°íšŒ ê²°ê³¼:\n"]
        
        if knowledge_type == "AUTO":
            # AUTO: ìˆœì°¨ì ìœ¼ë¡œ ì¡°íšŒ ì‹œë„ (ê°€ì¥ í”í•œ SKILL â†’ DMN_RULE â†’ MEMORY)
            for t in ["SKILL", "DMN_RULE", "MEMORY"]:
                try:
                    result = await _get_knowledge_detail_tool(agent_id, t, knowledge_id)
                    # "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ì¸ ê²½ìš°ë§Œ ë‹¤ìŒ íƒ€ì…ìœ¼ë¡œ
                    if "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" in result:
                        continue
                    return result
                except Exception:
                    continue
            return f"âŒ ID/ì´ë¦„ì´ '{knowledge_id}'ì¸ ì§€ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (AUTO ì¡°íšŒ)"

        if knowledge_type == "MEMORY":
            # ë¹ˆ ì¿¼ë¦¬ë¡œ semantic searchí•˜ë©´ OpenAI API ì˜¤ë¥˜ ë°œìƒ
            # ëŒ€ì‹  DBì—ì„œ ì§ì ‘ ì¡°íšŒ
            from core.knowledge_retriever import get_memories_by_agent
            memories = await get_memories_by_agent(agent_id, limit=200)
            target = next((m for m in memories if m.get("id") == knowledge_id), None)
            
            if not target:
                return f"âŒ IDê°€ '{knowledge_id}'ì¸ ë©”ëª¨ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            output_lines.append(f"ğŸ”‘ ID: {target.get('id')}")
            # DB ì§ì ‘ ì¡°íšŒ ì‹œ í•„ë“œëª…ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ (memory vs content)
            content = target.get('memory') or target.get('content') or target.get('data', '')
            output_lines.append(f"ğŸ“ ë‚´ìš©:\n{content}")
            
            metadata = target.get("metadata", {})
            if metadata:
                output_lines.append(f"\nğŸ“‹ ë©”íƒ€ë°ì´í„°:")
                for key, value in metadata.items():
                    output_lines.append(f"   - {key}: {value}")
        
        elif knowledge_type == "DMN_RULE":
            dmn_rules = await retrieve_existing_dmn_rules(agent_id, "")
            target = next((r for r in dmn_rules if r.get("id") == knowledge_id), None)
            
            if not target:
                return f"âŒ IDê°€ '{knowledge_id}'ì¸ DMN ê·œì¹™ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            output_lines.append(f"ğŸ”‘ ID: {target.get('id')}")
            output_lines.append(f"ğŸ“› ì´ë¦„: {target.get('name', '')}")
            output_lines.append(f"\nğŸ“œ DMN XML ì „ì²´ ë‚´ìš©:")
            output_lines.append("```xml")
            output_lines.append(target.get("bpmn", ""))
            output_lines.append("```")
            
            # XMLì—ì„œ ê·œì¹™ ì •ë³´ ì¶”ì¶œ ì‹œë„
            bpmn = target.get("bpmn", "")
            if bpmn:
                import re
                # ê°„ë‹¨í•œ ê·œì¹™ ì¶”ì¶œ (inputEntry, outputEntry)
                rules = re.findall(r'<rule[^>]*>.*?</rule>', bpmn, re.DOTALL)
                if rules:
                    output_lines.append(f"\nğŸ“Š ê·œì¹™ ìˆ˜: {len(rules)}ê°œ")
        
        elif knowledge_type == "SKILL":
            skills = await retrieve_existing_skills(
                agent_id, "", top_k=100,
                tenant_id=tenant_id, agent_skills=agent_skills
            )
            target = next((s for s in skills if s.get("id") == knowledge_id or s.get("name") == knowledge_id), None)
            
            if not target:
                return f"âŒ ID/ì´ë¦„ì´ '{knowledge_id}'ì¸ ìŠ¤í‚¬ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            skill_name = target.get('name', target.get('id'))
            output_lines.append(f"ğŸ”‘ ID/ì´ë¦„: {skill_name}")
            output_lines.append(f"ğŸ“ ì„¤ëª…: {target.get('description', '')}")
            
            content = target.get("content", "")
            if content:
                output_lines.append(f"\nğŸ“œ ìŠ¤í‚¬ ì „ì²´ ë‚´ìš©:")
                output_lines.append("```markdown")
                output_lines.append(content)
                output_lines.append("```")
            
            steps = target.get("steps", [])
            if steps:
                output_lines.append(f"\nğŸ“‹ ë‹¨ê³„ë³„ ì ˆì°¨ ({len(steps)}ë‹¨ê³„):")
                for idx, step in enumerate(steps, start=1):
                    output_lines.append(f"   {idx}. {step}")
            
            # ìŠ¤í‚¬ì˜ ëª¨ë“  íŒŒì¼ ë‚´ìš© ì¡°íšŒ (ì—…ë¡œë“œëœ ìŠ¤í‚¬ì¸ ê²½ìš°)
            try:
                from core.skill_api_client import get_skill_files, check_skill_exists, get_skill_file_content
                if check_skill_exists(skill_name):
                    skill_files = get_skill_files(skill_name)
                    if skill_files:
                        output_lines.append(f"\nğŸ“ ìŠ¤í‚¬ ë””ë ‰í† ë¦¬ íŒŒì¼ ({len(skill_files)}ê°œ):")
                        
                        # ëª¨ë“  í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ë‚´ìš© ì¡°íšŒ
                        text_files_found = 0
                        for file_info in skill_files:
                            file_path = file_info.get("path", "")
                            file_size = file_info.get("size", 0)
                            
                            try:
                                # íŒŒì¼ ë‚´ìš© ì¡°íšŒ (í…ìŠ¤íŠ¸ íŒŒì¼ë§Œ)
                                file_content_info = get_skill_file_content(skill_name, file_path)
                                file_type = file_content_info.get("type", "")
                                file_content = file_content_info.get("content", "")
                                
                                if file_type == "text" and file_content:
                                    text_files_found += 1
                                    # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì½”ë“œë¸”ë¡ ì–¸ì–´ ê²°ì •
                                    file_ext = file_path.split(".")[-1].lower() if "." in file_path else ""
                                    lang_map = {
                                        "py": "python",
                                        "md": "markdown",
                                        "json": "json",
                                        "yaml": "yaml",
                                        "yml": "yaml",
                                        "txt": "text",
                                        "sh": "bash",
                                        "js": "javascript",
                                        "ts": "typescript",
                                        "html": "html",
                                        "css": "css",
                                    }
                                    lang = lang_map.get(file_ext, "text")
                                    
                                    output_lines.append(f"\nğŸ“„ {file_path} ({file_size} bytes):")
                                    output_lines.append(f"```{lang}")
                                    output_lines.append(file_content)
                                    output_lines.append("```")
                                else:
                                    # ë°”ì´ë„ˆë¦¬ íŒŒì¼ì´ê±°ë‚˜ ë‚´ìš©ì´ ì—†ëŠ” ê²½ìš°
                                    output_lines.append(f"\nğŸ“„ {file_path} ({file_size} bytes, {file_type} file)")
                            except Exception as e:
                                # íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨ ì‹œ ê²½ë¡œë§Œ í‘œì‹œ
                                log(f"   âš ï¸ íŒŒì¼ ë‚´ìš© ì¡°íšŒ ì‹¤íŒ¨ ({file_path}): {e}")
                                output_lines.append(f"\nğŸ“„ {file_path} ({file_size} bytes, ì¡°íšŒ ì‹¤íŒ¨)")
                        
                        if text_files_found > 0:
                            output_lines.append(f"\nğŸ’¡ ì´ {text_files_found}ê°œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ ë‚´ìš©ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
                            output_lines.append("ğŸ’¡ íŒŒì¼ì„ ìˆ˜ì •í•˜ë ¤ë©´ commit_skill ë„êµ¬ì˜ additional_files íŒŒë¼ë¯¸í„°ì— íŒŒì¼ ê²½ë¡œì™€ ìˆ˜ì •ëœ ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.")
            except Exception as e:
                log(f"   âš ï¸ ìŠ¤í‚¬ íŒŒì¼ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        else:
            return f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì§€ì‹ íƒ€ì…: {knowledge_type}"
        
        output_lines.append("")
        output_lines.append("â”" * 50)
        if knowledge_type == "SKILL":
            output_lines.append("ğŸ§  ìŠ¤í‚¬ì˜ ëª¨ë“  íŒŒì¼ ë‚´ìš©ì„ ê²€í† í•˜ì—¬ í”¼ë“œë°±ê³¼ ë¹„êµí•˜ì„¸ìš”:")
            output_lines.append("   - í”¼ë“œë°±ì´ ì–´ë–¤ íŒŒì¼ê³¼ ê´€ë ¨ë˜ì–´ ìˆëŠ”ê°€? (SKILL.md, scripts/, references/ ë“±)")
            output_lines.append("   - ì–´ë–¤ íŒŒì¼ì„ ìˆ˜ì •í•´ì•¼ í•˜ëŠ”ê°€?")
            output_lines.append("   - ìƒˆ íŒŒì¼ì„ ì¶”ê°€í•´ì•¼ í•˜ëŠ”ê°€?")
            output_lines.append("   - ë³‘í•©/ìˆ˜ì •ì´ í•„ìš”í•˜ë©´ commit_skill ë„êµ¬ì˜ additional_filesì— íŒŒì¼ ê²½ë¡œì™€ ìˆ˜ì •ëœ ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš”.")
            output_lines.append("   - í”¼ë“œë°±ì´ ê¸°ì¡´ ìŠ¤í‚¬ì— í†µí•© ê°€ëŠ¥í•˜ë©´ CREATEë³´ë‹¤ UPDATEë¥¼ ìš°ì„  ê³ ë ¤í•˜ì„¸ìš”.")
        else:
            output_lines.append("ğŸ§  ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í”¼ë“œë°±ê³¼ ë¹„êµí•˜ì—¬ ì²˜ë¦¬ ë°©ë²•ì„ ê²°ì •í•˜ì„¸ìš”.")
            output_lines.append("   - ë³‘í•©ì´ í•„ìš”í•˜ë©´ ê¸°ì¡´ ë‚´ìš© + ìƒˆ ë‚´ìš©ì„ ì§ì ‘ êµ¬ì„±í•˜ì„¸ìš”.")
            output_lines.append("   - ìˆ˜ì •ì´ í•„ìš”í•˜ë©´ ë³€ê²½ëœ ì „ì²´ ë‚´ìš©ì„ êµ¬ì„±í•˜ì„¸ìš”.")
        
        return "\n".join(output_lines)
        
    except Exception as e:
        handle_error("get_knowledge_detail_tool", e)
        return f"âŒ ì§€ì‹ ìƒì„¸ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"


# ============================================================================
# LangChain Tool ìƒì„±
# ============================================================================

def create_react_tools(agent_id: str, feedback_content: Optional[str] = None) -> List[StructuredTool]:
    """
    ReAct ì—ì´ì „íŠ¸ìš© ë„êµ¬ ëª©ë¡ ìƒì„±
    
    Args:
        agent_id: ì—ì´ì „íŠ¸ ID (ë„êµ¬ì— ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©)
        feedback_content: ì›ë³¸ í”¼ë“œë°± ë‚´ìš© (commit_to_skillì˜ record_knowledge_historyìš©, ì„ íƒ)
    
    Returns:
        LangChain Tool ëª©ë¡
    """
    
    # agent_id, feedback_contentë¥¼ í´ë¡œì €ë¡œ ìº¡ì²˜í•˜ëŠ” ë˜í¼ í•¨ìˆ˜ë“¤ (ì™„ì „ async)
    async def search_memory_wrapper(query: str, limit: int = 10) -> str:
        """ë©”ëª¨ë¦¬ ê²€ìƒ‰ ë„êµ¬ (async)"""
        return await _search_memory_tool(agent_id, query, limit)
    
    async def search_dmn_rules_wrapper(search_text: str = "") -> str:
        """DMN ê·œì¹™ ê²€ìƒ‰ ë„êµ¬ (async)"""
        return await _search_dmn_rules_tool(agent_id, search_text)
    
    async def search_skills_wrapper(search_text: str = "", top_k: int = 10) -> str:
        """Skills ê²€ìƒ‰ ë„êµ¬ (async)"""
        return await _search_skills_tool(agent_id, search_text, top_k)
    
    async def analyze_conflict_wrapper(new_knowledge_json: str, existing_knowledge_json: str, target_type: str) -> str:
        """ì¶©ëŒ ë¶„ì„ ë„êµ¬ (async) - JSON ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        import json
        
        def parse_json_input(input_data):
            """JSON ì…ë ¥ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±"""
            if isinstance(input_data, dict):
                return input_data
            elif isinstance(input_data, str):
                input_data = input_data.strip()
                if not input_data:
                    raise ValueError("ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                
                # ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
                if (input_data.startswith("'") and input_data.endswith("'")) or \
                   (input_data.startswith('"') and input_data.endswith('"')):
                    input_data = input_data[1:-1]
                    input_data = input_data.replace("\\'", "'").replace('\\"', '"')
                
                return json.loads(input_data)
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {type(input_data).__name__}")
        
        try:
            # JSON ë¬¸ìì—´ì„ ë”•ì…”ë„ˆë¦¬ë¡œ íŒŒì‹±
            new_knowledge = parse_json_input(new_knowledge_json)
            existing_knowledge = parse_json_input(existing_knowledge_json)

            return await _analyze_conflict_tool(new_knowledge, existing_knowledge, target_type)
        except (json.JSONDecodeError, ValueError) as e:
            return f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}\nì…ë ¥ëœ new_knowledge_json (ì²« 500ì): {str(new_knowledge_json)[:500]}...\nì…ë ¥ëœ existing_knowledge_json (ì²« 500ì): {str(existing_knowledge_json)[:500]}..."
        except Exception as e:
            return f"âŒ ì¶©ëŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}"
    
    async def get_knowledge_detail_wrapper(knowledge_type: str, knowledge_id: str = "") -> str:
        """ê¸°ì¡´ ì§€ì‹ ìƒì„¸ ì¡°íšŒ ë„êµ¬ (async) - kwargs í˜•ì‹ ì…ë ¥ ì²˜ë¦¬"""
        import re
        import json
        
        actual_knowledge_type = knowledge_type
        actual_knowledge_id = knowledge_id
        
        # ReAct(text) ì—ì´ì „íŠ¸ëŠ” Action Input(JSON)ì„ ë¬¸ìì—´ë¡œ ë„˜ê¸¸ ìˆ˜ ìˆì–´,
        # ì´ ê²½ìš° knowledge_type íŒŒë¼ë¯¸í„°ì— JSON ë¬¸ìì—´ì´ í†µì§¸ë¡œ ë“¤ì–´ì˜¨ë‹¤.
        if isinstance(knowledge_type, str):
            input_str = knowledge_type.strip()

            # 1) JSON ë¬¸ìì—´ë¡œ ë“¤ì–´ì˜¨ ê²½ìš° ë³µêµ¬ ({"skill_id": "..."} / {"knowledge_id": "..."} / {"knowledge_type": "...", ...})
            if input_str.startswith("{") and input_str.endswith("}"):
                try:
                    parsed = json.loads(input_str)
                    if isinstance(parsed, dict):
                        # skill_idë§Œ ì£¼ëŠ” ì‹¤ìˆ˜ë¥¼ í”íˆ í•¨ â†’ SKILLë¡œ ê°„ì£¼
                        if not actual_knowledge_id and parsed.get("skill_id"):
                            actual_knowledge_type = "SKILL"
                            actual_knowledge_id = str(parsed.get("skill_id"))
                        # knowledge_idë§Œ ì¤€ ê²½ìš° â†’ AUTOë¡œ ì¡°íšŒ
                        if not actual_knowledge_id and parsed.get("knowledge_id"):
                            actual_knowledge_type = parsed.get("knowledge_type") or "AUTO"
                            actual_knowledge_id = str(parsed.get("knowledge_id"))
                        # ì •ìƒ ì¼€ì´ìŠ¤
                        if parsed.get("knowledge_type"):
                            actual_knowledge_type = str(parsed.get("knowledge_type"))
                        if parsed.get("knowledge_id"):
                            actual_knowledge_id = str(parsed.get("knowledge_id"))
                except Exception:
                    pass

            # 2) kwargs í˜•ì‹ ë¬¸ìì—´ì¸ ê²½ìš° ë³µêµ¬
            if 'knowledge_type=' in input_str or 'knowledge_id=' in input_str or 'skill_id=' in input_str:
                log(f"ğŸ”§ get_knowledge_detail: kwargs í˜•ì‹ ì…ë ¥ ê°ì§€, íŒŒì‹± ì‹œë„...")
                log(f"   ì…ë ¥ê°’: {input_str}")

                # knowledge_type ì¶”ì¶œ
                type_match = re.search(r'knowledge_type\s*=\s*["\']?([^"\'",\s]+)["\']?', input_str)
                if type_match:
                    actual_knowledge_type = type_match.group(1)
                    log(f"   ì¶”ì¶œëœ knowledge_type: {actual_knowledge_type}")

                # knowledge_id ì¶”ì¶œ
                id_match = re.search(r'knowledge_id\s*=\s*["\']?([^"\'",\s]+)["\']?', input_str)
                if id_match:
                    actual_knowledge_id = id_match.group(1)
                    log(f"   ì¶”ì¶œëœ knowledge_id: {actual_knowledge_id}")

                # skill_id ì¶”ì¶œ â†’ SKILLë¡œ ê°„ì£¼
                sid_match = re.search(r'skill_id\s*=\s*["\']?([^"\'",\s]+)["\']?', input_str)
                if sid_match and not actual_knowledge_id:
                    actual_knowledge_type = "SKILL"
                    actual_knowledge_id = sid_match.group(1)
                    log(f"   ì¶”ì¶œëœ skill_id â†’ knowledge_id: {actual_knowledge_id}")
        
        # knowledge_idê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not actual_knowledge_id:
            return f"âŒ knowledge_idê°€ í•„ìš”í•©ë‹ˆë‹¤. ì…ë ¥ê°’: knowledge_type={actual_knowledge_type}"

        # knowledge_typeì´ ë¹„ì •ìƒ/ëˆ„ë½ì´ë©´ AUTOë¡œ ë³µêµ¬
        if not actual_knowledge_type or (isinstance(actual_knowledge_type, str) and actual_knowledge_type.strip() == ""):
            actual_knowledge_type = "AUTO"
        actual_knowledge_type = str(actual_knowledge_type).upper().strip()
        if actual_knowledge_type not in ["MEMORY", "DMN_RULE", "SKILL", "AUTO"]:
            actual_knowledge_type = "AUTO"

        return await _get_knowledge_detail_tool(agent_id, actual_knowledge_type, actual_knowledge_id)
    
    async def commit_memory_wrapper(content: str, operation: str = "CREATE", memory_id: Optional[str] = None) -> str:
        """ë©”ëª¨ë¦¬ ì €ì¥ ë„êµ¬ (async)"""
        return await _commit_memory_tool(agent_id, content, operation, memory_id)
    
    async def commit_dmn_rule_wrapper(dmn_artifact_json: str, operation: str = "CREATE", rule_id: Optional[str] = None, feedback_content: str = "", merge_mode: Optional[str] = "REPLACE") -> str:
        """DMN ê·œì¹™ ì €ì¥ ë„êµ¬ (async) - JSON ë¬¸ìì—´ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        import json
        import re
        
        # ì—ì´ì „íŠ¸ê°€ kwargs í˜•ì‹ìœ¼ë¡œ ì „ë‹¬í•œ ê²½ìš° íŒŒì‹±
        # ì˜ˆ: dmn_artifact_json='{"name": "..."}', operation="UPDATE", rule_id="...", merge_mode="EXTEND"
        actual_operation = operation
        actual_rule_id = rule_id
        actual_merge_mode = merge_mode
        actual_json = dmn_artifact_json  # ì´ˆê¸°ê°’ ì„¤ì •
        
        log(f"ğŸ” commit_dmn_rule_wrapper ì‹œì‘: operation={operation}, rule_id={rule_id}, merge_mode={merge_mode}")
        log(f"   dmn_artifact_json íƒ€ì…: {type(dmn_artifact_json).__name__}")
        
        # LangChainì´ ë”•ì…”ë„ˆë¦¬ë¥¼ ì§ì ‘ ì „ë‹¬í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²˜ë¦¬
        if isinstance(dmn_artifact_json, dict):
            # ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³  JSON íŒŒì‹± ë‹¨ê³„ ê±´ë„ˆë›°ê¸°
            log(f"â„¹ï¸ dmn_artifact_jsonì´ ì´ë¯¸ ë”•ì…”ë„ˆë¦¬ë¡œ ì „ë‹¬ë¨: {list(dmn_artifact_json.keys())}")
            log(f"   ë”•ì…”ë„ˆë¦¬ ë‚´ìš©: {json.dumps(dmn_artifact_json, ensure_ascii=False)[:500]}")
            
            # âš ï¸ ì¤‘ìš”: ë”•ì…”ë„ˆë¦¬ì—ì„œ operation, rule_id, merge_modeë¥¼ ë¨¼ì € ì¶”ì¶œ (ì¤‘ì²© êµ¬ì¡° ì²˜ë¦¬ ì „ì—)
            # LangChainì´ ë”•ì…”ë„ˆë¦¬ë¥¼ ì „ë‹¬í•  ë•Œ, ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ë“¤ì´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ
            # dmn_artifact_json ë”•ì…”ë„ˆë¦¬ ë‚´ë¶€ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ì¶œí•´ì•¼ í•¨
            if "operation" in dmn_artifact_json:
                extracted_op = dmn_artifact_json.get("operation")
                log(f"   ğŸ” operation í‚¤ ë°œê²¬: {repr(extracted_op)} (íƒ€ì…: {type(extracted_op).__name__})")
                if extracted_op and str(extracted_op).strip():
                    actual_operation = str(extracted_op).strip().upper()  # ëŒ€ë¬¸ìë¡œ ì •ê·œí™”
                    log(f"   âœ… ë”•ì…”ë„ˆë¦¬ì—ì„œ operation ì¶”ì¶œ: {actual_operation} (í•¨ìˆ˜ íŒŒë¼ë¯¸í„°: {operation})")
                else:
                    log(f"   âš ï¸ operation ê°’ì´ ë¹„ì–´ìˆìŒ: {repr(extracted_op)}")
            else:
                log(f"   âš ï¸ operation í‚¤ê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìŒ")
            
            if "rule_id" in dmn_artifact_json:
                extracted_rid = dmn_artifact_json.get("rule_id")
                log(f"   ğŸ” rule_id í‚¤ ë°œê²¬: {repr(extracted_rid)} (íƒ€ì…: {type(extracted_rid).__name__})")
                if extracted_rid and str(extracted_rid).strip():
                    actual_rule_id = str(extracted_rid).strip()
                    log(f"   âœ… ë”•ì…”ë„ˆë¦¬ì—ì„œ rule_id ì¶”ì¶œ: {actual_rule_id} (í•¨ìˆ˜ íŒŒë¼ë¯¸í„°: {rule_id})")
                else:
                    log(f"   âš ï¸ rule_id ê°’ì´ ë¹„ì–´ìˆìŒ: {repr(extracted_rid)}")
            else:
                log(f"   âš ï¸ rule_id í‚¤ê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìŒ")
            
            if "merge_mode" in dmn_artifact_json:
                extracted_mm = dmn_artifact_json.get("merge_mode")
                log(f"   ğŸ” merge_mode í‚¤ ë°œê²¬: {repr(extracted_mm)} (íƒ€ì…: {type(extracted_mm).__name__})")
                if extracted_mm and str(extracted_mm).strip():
                    actual_merge_mode = str(extracted_mm).strip().upper()  # ëŒ€ë¬¸ìë¡œ ì •ê·œí™”
                    log(f"   âœ… ë”•ì…”ë„ˆë¦¬ì—ì„œ merge_mode ì¶”ì¶œ: {actual_merge_mode} (í•¨ìˆ˜ íŒŒë¼ë¯¸í„°: {merge_mode})")
                else:
                    log(f"   âš ï¸ merge_mode ê°’ì´ ë¹„ì–´ìˆìŒ: {repr(extracted_mm)}")
            else:
                log(f"   âš ï¸ merge_mode í‚¤ê°€ ë”•ì…”ë„ˆë¦¬ì— ì—†ìŒ")
            
            log(f"   ğŸ“Š ì¶”ì¶œ ê²°ê³¼: actual_operation={actual_operation}, actual_rule_id={actual_rule_id}, actual_merge_mode={actual_merge_mode}")
            
            # ë”•ì…”ë„ˆë¦¬ ì•ˆì— "dmn_artifact_json" í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸ (ì¤‘ì²©ëœ ê²½ìš°)
            if "dmn_artifact_json" in dmn_artifact_json:
                # ì¤‘ì²©ëœ êµ¬ì¡°: {"dmn_artifact_json": {...}, "operation": "CREATE"}
                nested_artifact = dmn_artifact_json.get("dmn_artifact_json")
                log(f"   ì¤‘ì²©ëœ dmn_artifact_json ë°œê²¬, ì¶”ì¶œ ì¤‘...")
                
                # ì¤‘ì²©ëœ dmn_artifact_jsonì„ ì‚¬ìš©í•˜ë˜, ë©”íƒ€ë°ì´í„°(operation, rule_id, merge_mode)ëŠ” ìœ ì§€
                if isinstance(nested_artifact, dict):
                    # ì¤‘ì²©ëœ êµ¬ì¡°ì— ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ì „ë‹¬ (extract_nested_artifactì—ì„œ ì¶”ì¶œí•  ìˆ˜ ìˆë„ë¡)
                    actual_json = {
                        "dmn_artifact_json": nested_artifact,
                        "operation": actual_operation,  # ì´ë¯¸ ì¶”ì¶œëœ ê°’ ì‚¬ìš©
                        "rule_id": actual_rule_id,      # ì´ë¯¸ ì¶”ì¶œëœ ê°’ ì‚¬ìš©
                        "merge_mode": actual_merge_mode # ì´ë¯¸ ì¶”ì¶œëœ ê°’ ì‚¬ìš©
                    }
                    log(f"   ì¤‘ì²© êµ¬ì¡° + ë©”íƒ€ë°ì´í„°ë¡œ actual_json êµ¬ì„±: operation={actual_operation}, rule_id={actual_rule_id}")
                elif isinstance(nested_artifact, str):
                    actual_json = nested_artifact  # ë¬¸ìì—´ì´ë©´ ë‚˜ì¤‘ì— íŒŒì‹±
                else:
                    actual_json = dmn_artifact_json  # í´ë°±
            else:
                # ì¼ë°˜ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš© (ë©”íƒ€ë°ì´í„°ê°€ ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ)
                actual_json = dmn_artifact_json  # ë”•ì…”ë„ˆë¦¬ë¡œ ìœ ì§€í•˜ì—¬ try ë¸”ë¡ì—ì„œ ì²˜ë¦¬
        elif isinstance(dmn_artifact_json, str):
            input_str = dmn_artifact_json.strip()
            
            # kwargs í˜•ì‹ì¸ì§€ í™•ì¸ (dmn_artifact_json= ë˜ëŠ” operation= í¬í•¨)
            if 'dmn_artifact_json=' in input_str or (', operation=' in input_str and ', rule_id=' in input_str):
                log(f"ğŸ”§ kwargs í˜•ì‹ ì…ë ¥ ê°ì§€, íŒŒì‹± ì‹œë„...")
                
                # operation ì¶”ì¶œ
                op_match = re.search(r'operation\s*=\s*["\']?(\w+)["\']?', input_str)
                if op_match:
                    actual_operation = op_match.group(1)
                    log(f"   ì¶”ì¶œëœ operation: {actual_operation}")
                
                # rule_id ì¶”ì¶œ
                rid_match = re.search(r'rule_id\s*=\s*["\']?([^"\'",\s]+)["\']?', input_str)
                if rid_match:
                    actual_rule_id = rid_match.group(1)
                    log(f"   ì¶”ì¶œëœ rule_id: {actual_rule_id}")
                
                # merge_mode ì¶”ì¶œ
                mm_match = re.search(r'merge_mode\s*=\s*["\']?(\w+)["\']?', input_str)
                if mm_match:
                    actual_merge_mode = mm_match.group(1)
                    log(f"   ì¶”ì¶œëœ merge_mode: {actual_merge_mode}")
                
                # JSON ë¶€ë¶„ ì¶”ì¶œ (ì¤‘ì²© ì¤‘ê´„í˜¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ brace counting)
                # ë¨¼ì € ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸° (ë”°ì˜´í‘œ í¬í•¨ ê°€ëŠ¥)
                json_start = -1
                for i, char in enumerate(input_str):
                    if char == '{':
                        # ì•ì— ë”°ì˜´í‘œê°€ ìˆìœ¼ë©´ ê·¸ê²ƒë¶€í„° ì‹œì‘
                        if i > 0 and input_str[i-1] in "\"'":
                            json_start = i - 1
                        else:
                            json_start = i
                        break
                
                if json_start >= 0:
                    # brace countingìœ¼ë¡œ ë ìœ„ì¹˜ ì°¾ê¸°
                    brace_count = 0
                    json_end = -1
                    in_string = False
                    escape_next = False
                    actual_start = json_start if input_str[json_start] == '{' else json_start + 1
                    
                    for i in range(actual_start, len(input_str)):
                        char = input_str[i]
                        
                        if escape_next:
                            escape_next = False
                            continue
                        
                        if char == '\\':
                            escape_next = True
                            continue
                        
                        if char == '"' and not in_string:
                            in_string = True
                        elif char == '"' and in_string:
                            in_string = False
                        elif not in_string:
                            if char == '{':
                                brace_count += 1
                            elif char == '}':
                                brace_count -= 1
                                if brace_count == 0:
                                    json_end = i + 1
                                    break
                    
                    if json_end > 0:
                        actual_json = input_str[actual_start:json_end]
                        log(f"   ì¶”ì¶œëœ JSON (brace counting): {actual_json[:100]}...")
        
        try:
            # ë©”íƒ€ë°ì´í„° ë° ì¤‘ì²© artifactë¥¼ ì¶”ì¶œí•˜ëŠ” ê³µí†µ í—¬í¼
            def _extract_meta_and_artifact_from_dict(obj: dict):
                nonlocal actual_operation, actual_rule_id, actual_merge_mode

                # âš ï¸ ì¤‘ìš”: ë”•ì…”ë„ˆë¦¬ì—ì„œ operation, rule_id, merge_modeë¥¼ ë¨¼ì € ì¶”ì¶œ
                if "operation" in obj:
                    extracted_op = obj.get("operation")
                    if extracted_op:
                        actual_operation = extracted_op
                        log(f"   actual_jsonì—ì„œ operation ì¶”ì¶œ: {actual_operation}")

                if "rule_id" in obj:
                    extracted_rid = obj.get("rule_id")
                    if extracted_rid:
                        actual_rule_id = extracted_rid
                        log(f"   actual_jsonì—ì„œ rule_id ì¶”ì¶œ: {actual_rule_id}")

                if "merge_mode" in obj:
                    extracted_mm = obj.get("merge_mode")
                    if extracted_mm:
                        actual_merge_mode = extracted_mm
                        log(f"   actual_jsonì—ì„œ merge_mode ì¶”ì¶œ: {actual_merge_mode}")

                dmn_obj = obj

                # ì¬ê·€ì ìœ¼ë¡œ ì¤‘ì²© êµ¬ì¡°ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜
                def extract_nested_artifact(inner_obj, depth=0, max_depth=5):
                    """ì¤‘ì²©ëœ êµ¬ì¡°ì—ì„œ ì‹¤ì œ artifactë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ"""
                    nonlocal actual_operation, actual_rule_id, actual_merge_mode

                    if depth > max_depth:
                        return inner_obj

                    if not isinstance(inner_obj, dict):
                        return inner_obj

                    # operation, rule_id, merge_mode ë“± ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ì¶”ê°€ ì•ˆì „ì¥ì¹˜)
                    if "operation" in inner_obj:
                        extracted_op = inner_obj.get("operation")
                        if extracted_op:
                            actual_operation = extracted_op
                            log(f"   extract_nested_artifactì—ì„œ operation ì¶”ì¶œ (depth={depth}): {actual_operation}")
                    if "rule_id" in inner_obj:
                        extracted_rid = inner_obj.get("rule_id")
                        if extracted_rid:
                            actual_rule_id = extracted_rid
                            log(f"   extract_nested_artifactì—ì„œ rule_id ì¶”ì¶œ (depth={depth}): {actual_rule_id}")
                    if "merge_mode" in inner_obj:
                        extracted_mm = inner_obj.get("merge_mode")
                        if extracted_mm:
                            actual_merge_mode = extracted_mm
                            log(f"   extract_nested_artifactì—ì„œ merge_mode ì¶”ì¶œ (depth={depth}): {actual_merge_mode}")

                    # "dmn_artifact_json" í‚¤ê°€ ìˆìœ¼ë©´ ì¬ê·€ì ìœ¼ë¡œ ì¶”ì¶œ
                    if "dmn_artifact_json" in inner_obj:
                        nested = inner_obj["dmn_artifact_json"]
                        log(f"   ì¤‘ì²©ëœ dmn_artifact_json ë°œê²¬ (depth={depth}), ì¬ê·€ ì¶”ì¶œ ì¤‘...")
                        return extract_nested_artifact(nested, depth + 1, max_depth)

                    # conditionê³¼ actionì´ ì§ì ‘ ìˆëŠ”ì§€ í™•ì¸
                    if "condition" in inner_obj and "action" in inner_obj:
                        return inner_obj

                    # rules ë°°ì—´ì´ ìˆëŠ”ì§€ í™•ì¸
                    if "rules" in inner_obj and isinstance(inner_obj.get("rules"), list):
                        return inner_obj

                    # ê·¸ ì™¸ì—ëŠ” ê·¸ëŒ€ë¡œ ë°˜í™˜
                    return inner_obj

                extracted = extract_nested_artifact(dmn_obj)
                log(f"   ìµœì¢… ì¶”ì¶œëœ dmn_artifact í‚¤: {list(extracted.keys()) if isinstance(extracted, dict) else 'N/A'}")
                log(f"   ìµœì¢… actual_operation={actual_operation}, actual_rule_id={actual_rule_id}, actual_merge_mode={actual_merge_mode}")
                return extracted

            # ì…ë ¥ íƒ€ì…ì— ë”°ë¼ ì²˜ë¦¬
            if isinstance(actual_json, dict):
                dmn_artifact = _extract_meta_and_artifact_from_dict(actual_json)
            elif isinstance(actual_json, str):
                # ë¬¸ìì—´ì¸ ê²½ìš° íŒŒì‹± ì‹œë„
                actual_json = actual_json.strip()
                if not actual_json:
                    return "âŒ dmn_artifact_jsonì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                
                # ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬ (ì˜ˆ: '{"name": "..."}')
                if (actual_json.startswith("'") and actual_json.endswith("'")) or \
                   (actual_json.startswith('"') and actual_json.endswith('"')):
                    # ì™¸ë¶€ ë”°ì˜´í‘œ ì œê±°
                    actual_json = actual_json[1:-1]
                    # ì´ìŠ¤ì¼€ì´í”„ëœ ë”°ì˜´í‘œ ë³µì›
                    actual_json = actual_json.replace("\\'", "'").replace('\\"', '"')
                
                try:
                    # ë¬¸ìì—´ì„ JSONìœ¼ë¡œ íŒŒì‹±í•œ ë’¤, ë”•ì…”ë„ˆë¦¬ ì²˜ë¦¬ ë¡œì§ì„ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©
                    parsed = json.loads(actual_json)
                    if not isinstance(parsed, dict):
                        return f"âŒ dmn_artifact_json íŒŒì‹± ê²°ê³¼ê°€ dictê°€ ì•„ë‹™ë‹ˆë‹¤. type={type(parsed).__name__}"
                    dmn_artifact = _extract_meta_and_artifact_from_dict(parsed)
                except json.JSONDecodeError as e:
                    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë” ìì„¸í•œ ì—ëŸ¬ ì •ë³´
                    return f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}\nì…ë ¥ëœ dmn_artifact_json (ì²« 500ì): {actual_json[:500]}...\nì…ë ¥ íƒ€ì…: {type(actual_json).__name__}"
            else:
                return f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {type(actual_json).__name__}\nì…ë ¥ëœ ê°’: {str(actual_json)[:200]}..."
            
            # conditionê³¼ actionì„ ì°¾ëŠ” í•¨ìˆ˜ (ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰)
            def find_condition_and_action(obj, depth=0, max_depth=5):
                """ì¬ê·€ì ìœ¼ë¡œ conditionê³¼ actionì„ ì°¾ê¸°"""
                if depth > max_depth or not isinstance(obj, dict):
                    return None, None
                
                # ìµœìƒìœ„ ë ˆë²¨ì—ì„œ ì§ì ‘ ì°¾ê¸°
                condition = obj.get("condition")
                action = obj.get("action")
                if condition and action:
                    # ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œì§€ í™•ì¸
                    if isinstance(condition, str) and condition.strip() and isinstance(action, str) and action.strip():
                        return condition, action
                
                # rules ë°°ì—´ì—ì„œ ì°¾ê¸°
                if "rules" in obj and isinstance(obj.get("rules"), list):
                    rules = obj["rules"]
                    if len(rules) > 0:
                        first_rule = rules[0]
                        if isinstance(first_rule, dict):
                            # condition/action í˜•ì‹
                            rule_condition = first_rule.get("condition")
                            rule_action = first_rule.get("action")
                            if rule_condition and rule_action:
                                if isinstance(rule_condition, str) and rule_condition.strip() and isinstance(rule_action, str) and rule_action.strip():
                                    # ì—¬ëŸ¬ ê·œì¹™ì´ ìˆìœ¼ë©´ ë³‘í•©
                                    if len(rules) > 1:
                                        conditions = [r.get("condition", "") for r in rules if isinstance(r, dict) and r.get("condition")]
                                        actions = [r.get("action", "") for r in rules if isinstance(r, dict) and r.get("action")]
                                        if conditions and actions:
                                            merged_condition = " ë˜ëŠ” ".join([f"({c})" for c in conditions if c])
                                            merged_action = "; ".join([a for a in actions if a])
                                            return merged_condition, merged_action
                                    return rule_condition, rule_action
                            
                            # input/output í˜•ì‹
                            rule_input = first_rule.get("input")
                            rule_output = first_rule.get("output")
                            if rule_input and rule_output:
                                if isinstance(rule_input, str) and rule_input.strip() and isinstance(rule_output, str) and rule_output.strip():
                                    if len(rules) > 1:
                                        inputs = [r.get("input", "") for r in rules if isinstance(r, dict) and r.get("input")]
                                        outputs = [r.get("output", "") for r in rules if isinstance(r, dict) and r.get("output")]
                                        if inputs and outputs:
                                            merged_condition = " ë˜ëŠ” ".join([f"({i})" for i in inputs if i])
                                            merged_action = "; ".join([o for o in outputs if o])
                                            return merged_condition, merged_action
                                    return rule_input, rule_output
                
                # ì¤‘ì²©ëœ êµ¬ì¡°ì—ì„œ ì¬ê·€ì ìœ¼ë¡œ ì°¾ê¸°
                for key, value in obj.items():
                    if key in ["dmn_artifact_json", "artifact", "rule", "data"] and isinstance(value, dict):
                        nested_condition, nested_action = find_condition_and_action(value, depth + 1, max_depth)
                        if nested_condition and nested_action:
                            return nested_condition, nested_action
                
                return None, None
            
            # conditionê³¼ action ì°¾ê¸° (ì¬ê·€ì ìœ¼ë¡œ ëª¨ë“  êµ¬ì¡° íƒìƒ‰)
            condition, action = find_condition_and_action(dmn_artifact)
            
            # ë””ë²„ê¹…ì„ ìœ„í•œ ìƒì„¸ ë¡œê·¸
            log(f"ğŸ” DMN artifact ê²€ì¦: condition={repr(condition)}, action={repr(action)}")
            log(f"ğŸ” DMN artifact ì „ì²´: {json.dumps(dmn_artifact, ensure_ascii=False, indent=2)}")
            
            # conditionê³¼ actionì´ ì—†ê±°ë‚˜ ë¹ˆ ë¬¸ìì—´ì¸ì§€ í™•ì¸
            if not condition or (isinstance(condition, str) and not condition.strip()):
                return f"âŒ conditionì´ í•„ìš”í•©ë‹ˆë‹¤ (ë¹„ì–´ìˆê±°ë‚˜ None). ì „ë‹¬ëœ ë°ì´í„°: {json.dumps(dmn_artifact, ensure_ascii=False)[:500]}..."
            
            if not action or (isinstance(action, str) and not action.strip()):
                return f"âŒ actionì´ í•„ìš”í•©ë‹ˆë‹¤ (ë¹„ì–´ìˆê±°ë‚˜ None). ì „ë‹¬ëœ ë°ì´í„°: {json.dumps(dmn_artifact, ensure_ascii=False)[:500]}..."
            
            # conditionê³¼ actionì„ ì°¾ì•˜ìœ¼ë¯€ë¡œ, dmn_artifactë¥¼ ì™„ì „íˆ ì •ê·œí™”ëœ í˜•íƒœë¡œ ì¬êµ¬ì„±
            # ì¤‘ì²© êµ¬ì¡°ë¥¼ ì œê±°í•˜ê³  ìµœìƒìœ„ì— condition, action, nameë§Œ ìˆëŠ” ê¹”ë”í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¦
            # ì´ë¦„ì´ ë¹„ì–´ ìˆìœ¼ë©´ ì—¬ê¸°ì„œëŠ” ì±„ìš°ì§€ ì•Šê³ , commit_to_dmn_rule ë‹¨ê³„ì—ì„œ ì•ˆì „í•œ ê¸°ë³¸ê°’ì„ ì ìš©í•œë‹¤.
            normalized_dmn_artifact = {
                "name": (dmn_artifact.get("name") or "").strip() or None,
                "condition": condition,
                "action": action
            }
            
            log(f"âœ… ìµœì¢… ì¶”ì¶œ ì™„ë£Œ: condition={condition[:50]}..., action={action[:50]}...")
            log(f"âœ… ì •ê·œí™”ëœ dmn_artifact: {json.dumps(normalized_dmn_artifact, ensure_ascii=False)}")
            
            # ì¶”ì¶œëœ operation/rule_id ë¡œê¹… ë° ìµœì¢… ê²€ì¦
            log(f"ğŸ“‹ DMN ê·œì¹™ ì €ì¥ í˜¸ì¶œ: operation={actual_operation}, rule_id={actual_rule_id}, merge_mode={actual_merge_mode}")
            
            # âš ï¸ ì¤‘ìš”: rule_idê°€ ìˆëŠ”ë° operationì´ CREATEì´ë©´ ì—ëŸ¬
            if actual_rule_id and actual_rule_id.strip() and actual_operation == "CREATE":
                log(f"âš ï¸ ê²½ê³ : rule_idê°€ ìˆëŠ”ë° operationì´ CREATEì…ë‹ˆë‹¤. UPDATEë¡œ ë³€ê²½í•©ë‹ˆë‹¤.")
                actual_operation = "UPDATE"
                log(f"   ìˆ˜ì •ëœ operation: {actual_operation}")
            
            # âš ï¸ ì¤‘ìš”: operationì´ UPDATEì¸ë° rule_idê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
            if actual_operation == "UPDATE" and (not actual_rule_id or not actual_rule_id.strip()):
                return f"âŒ DMN ê·œì¹™ ì €ì¥ ì‹¤íŒ¨: UPDATE ì‘ì—…ì—ëŠ” rule_idê°€ í•„ìˆ˜ì…ë‹ˆë‹¤. rule_idë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. (í˜„ì¬: operation={actual_operation}, rule_id={actual_rule_id})"

            # merge_modeì— ë”°ë¼ ë„êµ¬ê°€ ì•ˆì „í•˜ê²Œ ë³‘í•© ì²˜ë¦¬
            # ì •ê·œí™”ëœ dmn_artifactë¥¼ ì „ë‹¬ (ì¤‘ì²© êµ¬ì¡° ì œê±°)
            return await _commit_dmn_rule_tool(agent_id, normalized_dmn_artifact, actual_operation, actual_rule_id, feedback_content, actual_merge_mode)
        except json.JSONDecodeError as e:
            return f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}\nì…ë ¥ëœ dmn_artifact_json: {actual_json[:200] if isinstance(actual_json, str) else str(actual_json)[:200]}..."
        except Exception as e:
            return f"âŒ DMN ê·œì¹™ ì €ì¥ ì‹¤íŒ¨: {str(e)}"
    
    async def commit_skill_wrapper(
        operation: str = "CREATE",
        skill_id: Optional[str] = None,
        merge_mode: str = "MERGE",
        relationship_analysis: Optional[str] = None,
        related_skill_ids: Optional[str] = None,
    ) -> str:
        """Skill ì €ì¥ ë„êµ¬ (async). ìŠ¤í‚¬ ë‚´ìš©(SKILL.md, steps, additional_files)ì€ skill-creatorê°€ ìƒì„±. feedback_contentëŠ” ìë™ ì „ë‹¬."""
        import json as _json
        actual_op = operation
        actual_sid = skill_id
        actual_mm = merge_mode or "MERGE"
        actual_ra = relationship_analysis
        actual_related = related_skill_ids
        # ReActì´ Action Inputì— {"operation":"UPDATE","skill_id":"x",...} ì „ì²´ë¥¼ ë„˜ê¸°ë©´, ì²« íŒŒë¼ë¯¸í„°(operation)ì— ê·¸ëŒ€ë¡œ ë“¤ì–´ì˜¬ ìˆ˜ ìˆìŒ. ì–¸ë©.
        def _unwrap(obj: dict) -> None:
            nonlocal actual_op, actual_sid, actual_mm, actual_ra, actual_related
            if isinstance(obj, dict):
                if obj.get("operation") is not None:
                    actual_op = str(obj.get("operation", "CREATE")).strip().upper()
                if obj.get("skill_id") is not None:
                    actual_sid = obj.get("skill_id") or actual_sid
                if obj.get("merge_mode") is not None:
                    actual_mm = str(obj.get("merge_mode", "MERGE")).strip()
                if obj.get("relationship_analysis") is not None:
                    actual_ra = (obj.get("relationship_analysis") or "").strip() or None
                if obj.get("related_skill_ids") is not None:
                    actual_related = (obj.get("related_skill_ids") or "").strip() or None

        if isinstance(operation, dict):
            _unwrap(operation)
            log(f"ğŸ”§ commit_to_skill: dict ì–¸ë© â†’ operation={actual_op}, skill_id={actual_sid}, merge_mode={actual_mm}")
        elif isinstance(operation, str) and operation.strip().startswith("{"):
            try:
                o = _json.loads(operation)
                if isinstance(o, dict):
                    _unwrap(o)
                    log(f"ğŸ”§ commit_to_skill: JSON ë¬¸ìì—´ ì–¸ë© â†’ operation={actual_op}, skill_id={actual_sid}, merge_mode={actual_mm}")
            except _json.JSONDecodeError:
                pass
        if isinstance(actual_op, str) and actual_op.upper() not in ("CREATE", "UPDATE", "DELETE"):
            s = str(actual_op).strip()
            if s.startswith("{"):
                try:
                    o = _json.loads(s)
                    if isinstance(o, dict):
                        _unwrap(o)
                        log(f"ğŸ”§ commit_to_skill: operation í•„ë“œ JSON ì¬íŒŒì‹± â†’ operation={actual_op}, skill_id={actual_sid}")
                except _json.JSONDecodeError:
                    pass
        try:
            log(f"ğŸ“‹ commit_to_skill: operation={actual_op}, skill_id={actual_sid}, merge_mode={actual_mm}")
            return await _commit_skill_tool(
                agent_id=agent_id,
                operation=actual_op,
                skill_id=actual_sid,
                merge_mode=actual_mm,
                feedback_content=feedback_content or "",
                relationship_analysis=actual_ra,
                related_skill_ids=actual_related,
            )
        except Exception as e:
            return f"âŒ Skill ì €ì¥ ì‹¤íŒ¨: {str(e)}"

    async def attach_skills_to_agent_wrapper(skill_ids: str) -> str:
        """ê¸°ì¡´ ìŠ¤í‚¬ì„ ì—ì´ì „íŠ¸ì— ì ì¬í•©ë‹ˆë‹¤. ìŠ¤í‚¬ ìƒì„±/ìˆ˜ì • ì—†ì´ ì—ì´ì „íŠ¸ì— ì¶”ê°€ë§Œ í•©ë‹ˆë‹¤."""
        return await _attach_skills_to_agent_tool(agent_id=agent_id, skill_ids=skill_ids)

    # ìƒˆë¡œìš´ í†µí•© ë„êµ¬ ë˜í¼ í•¨ìˆ˜ë“¤
    async def search_similar_knowledge_wrapper(content: str, knowledge_type: str = "ALL", threshold: float = 0.7) -> str:
        """ìœ ì‚¬ ì§€ì‹ ê²€ìƒ‰ ë„êµ¬ (async). ì´ˆê¸° ì§€ì‹ ì…‹íŒ… ì‹œ feedback_contentê°€ ìˆìœ¼ë©´ ëª©í‘œ+í˜ë¥´ì†Œë‚˜ë¥¼ ê²€ìƒ‰ì— ì‚¬ìš©."""
        actual_content = content
        if feedback_content and str(feedback_content).strip():
            # ì—ì´ì „íŠ¸ê°€ ëª©í‘œë§Œ ë„£ì—ˆì„ ìˆ˜ ìˆìŒ: contentê°€ feedback_contentë³´ë‹¤ ì§§ê±°ë‚˜, 'í˜ë¥´ì†Œë‚˜'ë¥¼ í¬í•¨í•˜ì§€ ì•Šìœ¼ë©´ ì „ì²´ ë¬¸ë§¥ ì‚¬ìš©
            agent_content = (content or "").strip()
            full_context = str(feedback_content).strip()
            if len(agent_content) < len(full_context) or "í˜ë¥´ì†Œë‚˜" not in agent_content:
                actual_content = full_context
        return await _search_similar_knowledge_tool(agent_id, actual_content, knowledge_type, threshold)
    
    async def check_duplicate_wrapper(content: str, knowledge_type: str, candidate_id: Optional[str] = None) -> str:
        """ì¤‘ë³µ í™•ì¸ ë„êµ¬ (async)"""
        return await _check_duplicate_tool(agent_id, content, knowledge_type, candidate_id)
    
    async def determine_operation_wrapper(content: str, knowledge_type: str = "") -> str:
        """ì‘ì—… ê²°ì • ë„êµ¬ (async) - kwargs í˜•ì‹ ì…ë ¥ ì²˜ë¦¬"""
        import re
        
        actual_content = content
        actual_knowledge_type = knowledge_type
        
        # ì—ì´ì „íŠ¸ê°€ kwargs í˜•ì‹ìœ¼ë¡œ ì „ë‹¬í•œ ê²½ìš° íŒŒì‹±
        # ì˜ˆ: content="some content", knowledge_type="DMN"
        # ë˜ëŠ” content='content=...knowledge_type='DMN''
        if isinstance(content, str):
            input_str = content.strip()
            
            # kwargs í˜•ì‹ì¸ì§€ í™•ì¸ (content= ë˜ëŠ” knowledge_type= í¬í•¨)
            if 'knowledge_type=' in input_str or (not knowledge_type and ('content=' in input_str or 'knowledge_type=' in input_str)):
                log(f"ğŸ”§ determine_operation: kwargs í˜•ì‹ ì…ë ¥ ê°ì§€, íŒŒì‹± ì‹œë„...")
                log(f"   ì…ë ¥ê°’: {input_str}")
                
                # content ì¶”ì¶œ
                # content='...' ë˜ëŠ” content="..." í˜•íƒœ
                content_match = re.search(r'content\s*=\s*["\']([^"\']*)["\']', input_str)
                if content_match:
                    actual_content = content_match.group(1)
                    log(f"   ì¶”ì¶œëœ content: {actual_content[:100]}...")
                else:
                    # content=...knowledge_type= í˜•íƒœì—ì„œ content ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    content_end = input_str.find('knowledge_type=')
                    if content_end > 0:
                        content_part = input_str[:content_end].strip()
                        if content_part.startswith('content='):
                            actual_content = content_part[8:].strip().strip("'\"")
                            log(f"   ì¶”ì¶œëœ content (í›„ì²˜ë¦¬): {actual_content[:100]}...")
                
                # knowledge_type ì¶”ì¶œ
                type_match = re.search(r'knowledge_type\s*=\s*["\']?([^"\'",\s]+)["\']?', input_str)
                if type_match:
                    actual_knowledge_type = type_match.group(1)
                    log(f"   ì¶”ì¶œëœ knowledge_type: {actual_knowledge_type}")
        
        # knowledge_typeì´ ì—†ìœ¼ë©´ ì—ëŸ¬
        if not actual_knowledge_type:
            return f"âŒ knowledge_typeì´ í•„ìš”í•©ë‹ˆë‹¤. ì…ë ¥ê°’: content={actual_content[:100]}..."
        
        # contentê°€ ë¹„ì–´ìˆìœ¼ë©´ ì—ëŸ¬
        if not actual_content:
            return f"âŒ contentê°€ í•„ìš”í•©ë‹ˆë‹¤. ì…ë ¥ê°’: knowledge_type={actual_knowledge_type}"

        return await _determine_operation_tool(agent_id, actual_content, actual_knowledge_type)
    
    tools = [
        StructuredTool.from_function(
            coroutine=search_memory_wrapper,
            name="search_memory",
            description="mem0ì—ì„œ ê´€ë ¨ ë©”ëª¨ë¦¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. í”¼ë“œë°± ë‚´ìš©ê³¼ ìœ ì‚¬í•œ ê¸°ì¡´ ì§€ì‹ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            args_schema=SearchMemoryInput
        ),
        StructuredTool.from_function(
            coroutine=search_dmn_rules_wrapper,
            name="search_dmn_rules",
            description="DMN ê·œì¹™ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. ì¡°ê±´-ê²°ê³¼ í˜•íƒœì˜ ë¹„ì¦ˆë‹ˆìŠ¤ íŒë‹¨ ê·œì¹™ì„ ì°¾ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            args_schema=SearchDmnRulesInput
        ),
        StructuredTool.from_function(
            coroutine=search_skills_wrapper,
            name="search_skills",
            description="Skillsë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤. ë°˜ë³µ ê°€ëŠ¥í•œ ì ˆì°¨ë‚˜ ì‘ì—… ìˆœì„œë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            args_schema=SearchSkillsInput
        ),
        # ìƒˆë¡œìš´ í†µí•© ë„êµ¬ë“¤ (ì˜ë¯¸ì  ìœ ì‚¬ë„ ê¸°ë°˜)
        StructuredTool.from_function(
            coroutine=search_similar_knowledge_wrapper,
            name="search_similar_knowledge",
            description="""ëª¨ë“  ì €ì¥ì†Œì—ì„œ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ê¸°ì¡´ ì§€ì‹ì„ ê²€ìƒ‰í•˜ê³  ê´€ê³„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
í”¼ë“œë°±ì„ ì €ì¥í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ì´ ë„êµ¬ë¥¼ ë¨¼ì € ì‚¬ìš©í•˜ì„¸ìš”.
ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ê´€ê³„ ìœ í˜•(DUPLICATE, EXTENDS, REFINES, CONFLICTS ë“±)ì„ í™•ì¸í•˜ê³ ,
ê¸°ì¡´ ì§€ì‹ê³¼ ìƒˆ í”¼ë“œë°±ì˜ ê´€ê³„ë¥¼ ì§ì ‘ ë¶„ì„í•˜ì—¬ ì²˜ë¦¬ ë°©ë²•ì„ ê²°ì •í•˜ì„¸ìš”.""",
            args_schema=SearchSimilarKnowledgeInput
        ),
        StructuredTool.from_function(
            coroutine=check_duplicate_wrapper,
            name="check_duplicate",
            description="""íŠ¹ì • ì§€ì‹ì´ ê¸°ì¡´ ì§€ì‹ê³¼ ì¤‘ë³µì¸ì§€ ìƒì„¸ í™•ì¸í•©ë‹ˆë‹¤.
search_similar_knowledgeë¡œ ìœ ì‚¬í•œ ì§€ì‹ì„ ì°¾ì€ í›„, ì •í™•í•œ ì¤‘ë³µ ì—¬ë¶€ë¥¼ í™•ì¸í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.""",
            args_schema=CheckDuplicateInput
        ),
        StructuredTool.from_function(
            coroutine=determine_operation_wrapper,
            name="determine_operation",
            description="""ìƒˆ ì§€ì‹ê³¼ ê¸°ì¡´ ì§€ì‹ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ê´€ê³„ ìœ í˜•(DUPLICATE, EXTENDS, REFINES, CONFLICTS ë“±)ê³¼ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
âš ï¸ ì´ ë„êµ¬ëŠ” ì‘ì—…ì„ ê²°ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì œê³µëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ì ‘ íŒë‹¨í•˜ì„¸ìš”.""",
            args_schema=DetermineOperationInput
        ),
        StructuredTool.from_function(
            coroutine=get_knowledge_detail_wrapper,
            name="get_knowledge_detail",
            description="""ê¸°ì¡´ ì§€ì‹ì˜ ì „ì²´ ìƒì„¸ ë‚´ìš©ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
ê¸°ì¡´ ì§€ì‹ê³¼ ìƒˆ í”¼ë“œë°±ì„ ì§ì ‘ ë¹„êµí•˜ì—¬ ë³‘í•©/ìˆ˜ì • ë°©ë²•ì„ ê²°ì •í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
DMN ê·œì¹™ì˜ ê²½ìš° ì „ì²´ XMLì„, SKILLì˜ ê²½ìš° ì „ì²´ stepsë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
ë³‘í•©ì´ í•„ìš”í•˜ë©´ ì´ ë„êµ¬ë¡œ ê¸°ì¡´ ë‚´ìš©ì„ ì¡°íšŒí•œ í›„ ì§ì ‘ í•©ì³ì„œ ì €ì¥í•˜ì„¸ìš”.""",
            args_schema=GetKnowledgeDetailInput
        ),
        StructuredTool.from_function(
            coroutine=commit_memory_wrapper,
            name="commit_to_memory",
            description="mem0ì— ë©”ëª¨ë¦¬ë¥¼ ì €ì¥/ìˆ˜ì •/ì‚­ì œí•©ë‹ˆë‹¤. ì§€ì¹¨, ì„ í˜¸ë„, ë§¥ë½ ì •ë³´ë¥¼ ì €ì¥í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. âš ï¸ ë©”ëª¨ë¦¬ ë‚´ìš©ì€ í•­ìƒ ì…ë ¥ í”¼ë“œë°±ê³¼ ë™ì¼í•œ ì–¸ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš” (ì˜ˆ: í”¼ë“œë°±ì´ í•œêµ­ì–´ì´ë©´ ë©”ëª¨ë¦¬ë„ í•œêµ­ì–´ë¡œ). ë²ˆì—­í•˜ê±°ë‚˜ ì„ì˜ë¡œ ì˜ì–´ë¡œ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”.",
            args_schema=CommitMemoryInput
        ),
        StructuredTool.from_function(
            coroutine=commit_dmn_rule_wrapper,
            name="commit_to_dmn_rule",
            description="""DMN ê·œì¹™ì„ ì €ì¥/ìˆ˜ì •/ì‚­ì œí•©ë‹ˆë‹¤.

âš ï¸ ì¤‘ìš”: ìœ ì‚¬í•œ ê¸°ì¡´ ê·œì¹™ì´ ìˆìœ¼ë©´ ë°˜ë“œì‹œ operation="UPDATE"ì™€ rule_idë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ì„¸ìš”!
- CREATE (ê¸°ë³¸ê°’): ìƒˆ ê·œì¹™ ìƒì„±. ìœ ì‚¬ ê·œì¹™ì´ ì—†ì„ ë•Œë§Œ ì‚¬ìš©
- UPDATE: ê¸°ì¡´ ê·œì¹™ ìˆ˜ì •. ë°˜ë“œì‹œ rule_id í•„ìˆ˜!
- DELETE: ê¸°ì¡´ ê·œì¹™ ì‚­ì œ. ë°˜ë“œì‹œ rule_id í•„ìˆ˜!

merge_mode íŒŒë¼ë¯¸í„° (UPDATE ì‹œ ì¤‘ìš”):
- REPLACE (ê¸°ë³¸ê°’): ì™„ì „ ëŒ€ì²´. ê¸°ì¡´ êµ¬ì¡° ë³€ê²½ ê°€ëŠ¥. ì—ì´ì „íŠ¸ê°€ ì „ë‹¬í•œ ë‚´ìš©ì´ ìµœì¢… ì™„ì„±ë³¸.
- EXTEND: ê¸°ì¡´ ê·œì¹™ ë³´ì¡´ + ìƒˆ ê·œì¹™ ì¶”ê°€. ë„êµ¬ê°€ ìë™ìœ¼ë¡œ ê¸°ì¡´ XML ì¡°íšŒ ë° ë³‘í•©.
- REFINE: ê¸°ì¡´ ê·œì¹™ ì°¸ì¡° í›„ ì¼ë¶€ ìˆ˜ì • (í˜„ì¬ëŠ” REPLACEì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬).

ê´€ê³„ ìœ í˜• â†’ merge_mode ë§¤í•‘:
- EXTENDS ê´€ê³„ â†’ merge_mode="EXTEND" (ê¶Œì¥!)
- REFINES ê´€ê³„ â†’ merge_mode="REFINE"
- SUPERSEDES ê´€ê³„ â†’ merge_mode="REPLACE"

ì˜ˆì‹œ (UPDATE + EXTEND): dmn_artifact_json='{"name": "ê·œì¹™ëª…", "condition": "ì¡°ê±´", "action": "ê²°ê³¼"}', operation="UPDATE", rule_id="ê¸°ì¡´_ê·œì¹™_ID", merge_mode="EXTEND"
ì˜ˆì‹œ (UPDATE + REPLACE): dmn_artifact_json='{"name": "ê·œì¹™ëª…", "condition": "ì¡°ê±´", "action": "ê²°ê³¼"}', operation="UPDATE", rule_id="ê¸°ì¡´_ê·œì¹™_ID", merge_mode="REPLACE"
ì˜ˆì‹œ (CREATE): dmn_artifact_json='{"name": "ê·œì¹™ëª…", "condition": "ì¡°ê±´", "action": "ê²°ê³¼"}'""",
            args_schema=CommitDmnRuleInput
        ),
        StructuredTool.from_function(
            coroutine=commit_skill_wrapper,
            name="commit_to_skill",
            description="Skillì„ ì €ì¥/ìˆ˜ì •/ì‚­ì œí•©ë‹ˆë‹¤. **ReActì€ ì €ì¥ì†Œ(SKILL)Â·ê¸°ì¡´ê³¼ì˜ ê´€ê³„(operation, skill_id)ë§Œ íŒë‹¨í•©ë‹ˆë‹¤.** ìŠ¤í‚¬ ë‚´ìš©(SKILL.md, steps, additional_files)ì€ skill-creatorê°€ ìƒì„±. **ëª©í‘œ/ê²°ê³¼(ì˜ˆ: ì˜ì‚¬ê²°ì • ê¸°ì—¬)ëŠ” ìŠ¤í‚¬ ì ˆì°¨ê°€ ì•„ë‹˜**â€”êµ¬ì²´ì  ì‘ì—… ì ˆì°¨Â·ì‚°ì¶œë¬¼ì´ ê¸°ì¡´ ìŠ¤í‚¬ë¡œ ë¶€ì¡±í•  ë•Œë§Œ CREATE. ê¸°ì¡´ ìŠ¤í‚¬ì„ ì°¸ì¡°í•˜ëŠ” ìƒˆ ìŠ¤í‚¬ì€ operation=CREATE, related_skill_ids=ê¸°ì¡´ìŠ¤í‚¬ì´ë¦„(ì‰¼í‘œ êµ¬ë¶„). ë™ì¼ ë²”ìœ„Â·ë™ì¼ ì ˆì°¨ ìˆ˜ì • ì‹œì—ë§Œ operation=UPDATE, skill_id=ê¸°ì¡´ìŠ¤í‚¬ì´ë¦„. DELETE ì‹œ skill_id í•„ìˆ˜. search_similar_knowledge ê²°ê³¼ëŠ” relationship_analysisì— ì „ë‹¬. ê´€ë ¨ ìŠ¤í‚¬ì€ related_skill_idsì— ì „ë‹¬.",
            args_schema=CommitSkillInput
        ),
        StructuredTool.from_function(
            coroutine=attach_skills_to_agent_wrapper,
            name="attach_skills_to_agent",
            description="""ê¸°ì¡´ ìŠ¤í‚¬ì„ ì—ì´ì „íŠ¸ì— ì ì¬ë§Œ í•©ë‹ˆë‹¤. **ìŠ¤í‚¬ ìƒì„±/ìˆ˜ì • ì—†ì´** ì—ì´ì „íŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.
**ì‚¬ìš© ì‹œì :** search_similar_knowledgeì—ì„œ ìœ ì‚¬/ì—°ê´€ ìŠ¤í‚¬ì„ ì°¾ì•˜ê³ , ê¸°ì¡´ ìŠ¤í‚¬ì´ **ì‘ì—… ì ˆì°¨Â·ì‚°ì¶œë¬¼**(ë°ì´í„° ìˆ˜ì§‘, ë³´ê³ ì„œ, ì‹œê°í™” ë“±)ì„ ì´ë¯¸ ì»¤ë²„í•  ë•Œ. ëª©í‘œì— "ì˜ì‚¬ê²°ì • ê¸°ì—¬" ë“±ì´ ìˆì–´ë„, ê·¸ ì ˆì°¨ë¥¼ ê¸°ì¡´ ìŠ¤í‚¬ì´ ë‹´ë‹¹í•˜ë©´ attachë§Œ í•˜ì„¸ìš”.
- ë‹¨ì¼ ìŠ¤í‚¬ë¡œ ì¶©ë¶„: skill_ids="skill-a"
- ì—¬ëŸ¬ ìŠ¤í‚¬ ì¡°í•© í•„ìš”: skill_ids="skill-a, skill-b, skill-c"
**ì£¼ì˜:** ìƒˆ ìŠ¤í‚¬ ìƒì„±(commit_to_skill CREATE)ì´ ì•„ë‹Œ ê¸°ì¡´ ìŠ¤í‚¬ ì¬ì‚¬ìš©ì…ë‹ˆë‹¤. ì—ì´ì „íŠ¸ëŠ” ë©€í‹° ìŠ¤í‚¬ ì§€ì›.""",
            args_schema=AttachSkillsToAgentInput
        ),
    ]
    
    return tools

