"""
ì˜ë¯¸ì  ì§€ì‹ ìœ ì‚¬ë„ ë¶„ì„ê¸°
ì–¸ì–´/í˜•ì‹ì´ ë‹¬ë¼ë„ ì˜ë¯¸ì ìœ¼ë¡œ ë™ì¼í•œ ì§€ì‹ì„ ì¸ì‹í•˜ëŠ” ëª¨ë“ˆ
"""

import json
from typing import Dict, List, Optional, Tuple
from core.llm import create_llm
from utils.logger import log, handle_error


def clean_json_response(content: str) -> str:
    """LLM ì‘ë‹µì—ì„œ ë°±í‹±ê³¼ json í‚¤ì›Œë“œ ì œê±°"""
    content = content.replace("```json", "").replace("```", "")
    return content.strip()


class SemanticKnowledgeMatcher:
    """ì˜ë¯¸ ê¸°ë°˜ ì§€ì‹ ìœ ì‚¬ë„ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.llm = create_llm(model="gpt-4o", streaming=False, temperature=0)
    
    async def find_similar_knowledge(
        self,
        new_knowledge: str,
        existing_knowledge: List[Dict],
        knowledge_type: str,
        threshold: float = 0.5  # ë‚®ì¶°ì„œ ë” ë§ì€ ê´€ë ¨ ì§€ì‹ì„ ë°˜í™˜
    ) -> List[Dict]:
        """
        ìƒˆ ì§€ì‹ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ê¸°ì¡´ ì§€ì‹ ê²€ìƒ‰
        ì—ì´ì „íŠ¸ê°€ ì§ì ‘ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ì¶©ë¶„í•œ ì •ë³´ ì œê³µ
        
        Args:
            new_knowledge: ìƒˆë¡œìš´ ì§€ì‹ ë‚´ìš© (í…ìŠ¤íŠ¸)
            existing_knowledge: ê¸°ì¡´ ì§€ì‹ ëª©ë¡
            knowledge_type: ì§€ì‹ íƒ€ì… (MEMORY | DMN_RULE | SKILL)
            threshold: ìœ ì‚¬ë„ ì„ê³„ê°’ (0.0-1.0)
        
        Returns:
            ìœ ì‚¬í•œ ì§€ì‹ ëª©ë¡ (ê´€ê³„ ë¶„ì„ í¬í•¨, ì‘ì—… ì¶”ì²œ ì—†ìŒ)
        """
        if not existing_knowledge:
            return []
        
        try:
            # ê¸°ì¡´ ì§€ì‹ í¬ë§·íŒ… (ë” ìƒì„¸í•˜ê²Œ)
            existing_formatted = self._format_existing_knowledge_detailed(existing_knowledge, knowledge_type)
            
            prompt = f"""ë‹¤ìŒ ìƒˆë¡œìš´ ì§€ì‹ê³¼ ê¸°ì¡´ ì§€ì‹ë“¤ì˜ **ê´€ê³„**ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
ì—ì´ì „íŠ¸ê°€ ì§ì ‘ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸í•œ ë¶„ì„ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”.

**ìƒˆë¡œìš´ ì§€ì‹:**
{new_knowledge}

**ê¸°ì¡´ ì§€ì‹ ëª©ë¡:**
{existing_formatted}

**ê´€ê³„ ìœ í˜• ì •ì˜:**
- DUPLICATE: ì™„ì „íˆ ë™ì¼í•œ ë‚´ìš© (ì–¸ì–´/í‘œí˜„ë§Œ ë‹¤ë¦„)
- EXTENDS: ìƒˆ ì§€ì‹ì´ ê¸°ì¡´ ì§€ì‹ì— ì¡°ê±´/ê·œì¹™ì„ ì¶”ê°€ (ê¸°ì¡´ ìœ ì§€ + í™•ì¥)
- REFINES: ìƒˆ ì§€ì‹ì´ ê¸°ì¡´ ì§€ì‹ì˜ ì„¸ë¶€ ê°’ì„ ë³€ê²½
- CONFLICTS: ìƒˆ ì§€ì‹ì´ ê¸°ì¡´ ì§€ì‹ê³¼ ëª¨ìˆœ/ìƒì¶©
- EXCEPTION: ìƒˆ ì§€ì‹ì´ ê¸°ì¡´ ê·œì¹™ì˜ ì˜ˆì™¸ ì¼€ì´ìŠ¤
- SUPERSEDES: ìƒˆ ì§€ì‹ì´ ê¸°ì¡´ ì§€ì‹ì„ ì™„ì „íˆ ëŒ€ì²´
- COMPLEMENTS: ì„œë¡œ ë‹¤ë¥¸ ì¸¡ë©´ì„ ë‹¤ë£¸ (ê´€ë ¨ì€ ìˆìœ¼ë‚˜ ë…ë¦½ì )
- UNRELATED: ê´€ê³„ ì—†ìŒ

**ì‘ë‹µ í˜•ì‹:**
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "similar_items": [
    {{
      "id": "ê¸°ì¡´ ì§€ì‹ ID",
      "name": "ê¸°ì¡´ ì§€ì‹ ì´ë¦„/ì œëª©",
      "similarity_score": 0.0-1.0,
      "relationship": "ìœ„ ê´€ê³„ ìœ í˜• ì¤‘ í•˜ë‚˜",
      "relationship_reason": "ì´ ê´€ê³„ë¡œ íŒë‹¨í•œ êµ¬ì²´ì ì¸ ì´ìœ ",
      "key_differences": ["ê¸°ì¡´ ì§€ì‹ê³¼ ìƒˆ ì§€ì‹ì˜ í•µì‹¬ ì°¨ì´ì  ëª©ë¡"],
      "key_similarities": ["ê¸°ì¡´ ì§€ì‹ê³¼ ìƒˆ ì§€ì‹ì˜ í•µì‹¬ ìœ ì‚¬ì  ëª©ë¡"],
      "content_summary": "ê¸°ì¡´ ì§€ì‹ì˜ í•µì‹¬ ë‚´ìš© ìš”ì•½"
    }}
  ]
}}

ìœ ì‚¬ë„ê°€ {threshold} ì´ìƒì¸ í•­ëª©ë§Œ í¬í•¨í•˜ì„¸ìš”. ê´€ë ¨ì„±ì´ ìˆìœ¼ë©´ ë‚®ì€ ìœ ì‚¬ë„ë„ í¬í•¨í•˜ì„¸ìš”."""

            response = await self.llm.ainvoke(prompt)
            cleaned_content = clean_json_response(response.content)
            
            result = json.loads(cleaned_content)
            similar_items = result.get("similar_items", [])
            
            # ì›ë³¸ ì§€ì‹ ì •ë³´ ì¶”ê°€ (ì—ì´ì „íŠ¸ê°€ ìƒì„¸ ì¡°íšŒ ê°€ëŠ¥í•˜ë„ë¡)
            for item in similar_items:
                item_id = item.get("id")
                for existing in existing_knowledge:
                    existing_id = existing.get("id", existing.get("name", ""))
                    if existing_id == item_id:
                        item["original"] = existing
                        # ì „ì²´ ë‚´ìš©ë„ í¬í•¨ (ì—ì´ì „íŠ¸ê°€ ì§ì ‘ ë¹„êµí•  ìˆ˜ ìˆë„ë¡)
                        item["full_content"] = self._get_knowledge_content(existing, knowledge_type)
                        break
            
            log(f"ğŸ” ìœ ì‚¬ ì§€ì‹ ë¶„ì„ ì™„ë£Œ: {len(similar_items)}ê°œ ë°œê²¬ (ì„ê³„ê°’: {threshold})")
            return similar_items
            
        except json.JSONDecodeError as e:
            log(f"âŒ ìœ ì‚¬ë„ ë¶„ì„ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []
        except Exception as e:
            handle_error("ì˜ë¯¸ì ìœ ì‚¬ë„ë¶„ì„", e)
            return []
    
    def _format_existing_knowledge_detailed(self, knowledge_list: List[Dict], knowledge_type: str) -> str:
        """ê¸°ì¡´ ì§€ì‹ ëª©ë¡ì„ ìƒì„¸ ë¶„ì„ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        formatted = []
        
        for idx, item in enumerate(knowledge_list, start=1):
            item_id = item.get("id", item.get("name", f"item_{idx}"))
            content = self._get_knowledge_content(item, knowledge_type)
            
            formatted.append(f"[{idx}] ID: {item_id}")
            
            if knowledge_type == "DMN_RULE":
                name = item.get("name", "")
                formatted.append(f"    ì´ë¦„: {name}")
                # DMN XMLì˜ ê²½ìš° ë” ë§ì€ ë‚´ìš© í¬í•¨
                formatted.append(f"    ë‚´ìš©: {content[:1000]}...")
            elif knowledge_type == "SKILL":
                name = item.get("name", item.get("skill_name", ""))
                formatted.append(f"    ì´ë¦„: {name}")
                formatted.append(f"    ë‚´ìš©: {content}")
            else:  # MEMORY
                formatted.append(f"    ë‚´ìš©: {content}")
            
            formatted.append("")
        
        return "\n".join(formatted)
    
    async def verify_duplicate(
        self,
        new_knowledge: str,
        candidate: Dict,
        knowledge_type: str
    ) -> Dict:
        """
        íŠ¹ì • ì§€ì‹ì´ ì¤‘ë³µì¸ì§€ ìƒì„¸ ê²€ì¦
        
        Args:
            new_knowledge: ìƒˆë¡œìš´ ì§€ì‹ ë‚´ìš©
            candidate: ì¤‘ë³µ í›„ë³´ ì§€ì‹
            knowledge_type: ì§€ì‹ íƒ€ì…
        
        Returns:
            ê²€ì¦ ê²°ê³¼
        """
        try:
            candidate_content = self._get_knowledge_content(candidate, knowledge_type)
            
            prompt = f"""ë‹¤ìŒ ë‘ ì§€ì‹ì´ ì˜ë¯¸ì ìœ¼ë¡œ ë™ì¼í•œì§€ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”.

**ìƒˆë¡œìš´ ì§€ì‹:**
{new_knowledge}

**ê¸°ì¡´ ì§€ì‹:**
ID: {candidate.get("id", candidate.get("name", "Unknown"))}
ë‚´ìš©: {candidate_content}

**ë¶„ì„ ìš”ì²­:**
1. ë‘ ì§€ì‹ì´ ì˜ë¯¸ì ìœ¼ë¡œ ë™ì¼í•œì§€ íŒë‹¨
2. ë™ì¼í•˜ë‹¤ë©´ ì–´ë–¤ ë¶€ë¶„ì´ ê°™ì€ì§€ ì„¤ëª…
3. ë‹¤ë¥´ë‹¤ë©´ ì–´ë–¤ ì ì´ ë‹¤ë¥¸ì§€ ì„¤ëª…
4. ê¶Œì¥ ì‘ì—… ê²°ì • (UPDATE | CREATE | IGNORE)

**ì‘ë‹µ í˜•ì‹:**
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

{{
  "is_duplicate": true/false,
  "confidence": 0.0-1.0,
  "same_aspects": ["ë™ì¼í•œ ë¶€ë¶„ ëª©ë¡"],
  "different_aspects": ["ë‹¤ë¥¸ ë¶€ë¶„ ëª©ë¡"],
  "recommended_operation": "UPDATE | CREATE | IGNORE",
  "reason": "íŒë‹¨ ì´ìœ "
}}"""

            response = await self.llm.ainvoke(prompt)
            cleaned_content = clean_json_response(response.content)
            
            result = json.loads(cleaned_content)
            result["candidate_id"] = candidate.get("id", candidate.get("name", ""))
            
            log(f"ğŸ” ì¤‘ë³µ ê²€ì¦ ì™„ë£Œ: is_duplicate={result.get('is_duplicate')}, confidence={result.get('confidence')}")
            return result
            
        except json.JSONDecodeError as e:
            log(f"âŒ ì¤‘ë³µ ê²€ì¦ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "is_duplicate": False,
                "confidence": 0.0,
                "recommended_operation": "CREATE",
                "reason": f"ê²€ì¦ ì‹¤íŒ¨: {str(e)}"
            }
        except Exception as e:
            handle_error("ì¤‘ë³µê²€ì¦", e)
            return {
                "is_duplicate": False,
                "confidence": 0.0,
                "recommended_operation": "CREATE",
                "reason": f"ê²€ì¦ ì—ëŸ¬: {str(e)}"
            }
    
    async def analyze_relationship(
        self,
        new_knowledge: str,
        similar_items: List[Dict],
        knowledge_type: str
    ) -> Dict:
        """
        ìœ ì‚¬ ì§€ì‹ê³¼ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì •ë³´ ì œê³µ (ê²°ì •ì€ ì—ì´ì „íŠ¸ê°€ í•¨)
        
        Args:
            new_knowledge: ìƒˆë¡œìš´ ì§€ì‹
            similar_items: ìœ ì‚¬ ì§€ì‹ ëª©ë¡ (find_similar_knowledge ê²°ê³¼)
            knowledge_type: ì§€ì‹ íƒ€ì…
        
        Returns:
            ê´€ê³„ ë¶„ì„ ì •ë³´ (ì‘ì—… ì¶”ì²œ ì—†ìŒ, ì—ì´ì „íŠ¸ê°€ íŒë‹¨)
        """
        if not similar_items:
            return {
                "has_related_knowledge": False,
                "analysis": "ê¸°ì¡´ì— ê´€ë ¨ëœ ì§€ì‹ì´ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ì§€ì‹ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.",
                "related_items": []
            }
        
        # ê´€ê³„ë³„ë¡œ ë¶„ë¥˜
        analysis_result = {
            "has_related_knowledge": True,
            "total_related": len(similar_items),
            "related_items": [],
            "analysis": ""
        }
        
        relationship_groups = {}
        for item in similar_items:
            rel = item.get("relationship", "UNKNOWN")
            if rel not in relationship_groups:
                relationship_groups[rel] = []
            relationship_groups[rel].append(item)
        
        # ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
        analysis_lines = []
        for rel_type, items in relationship_groups.items():
            analysis_lines.append(f"- {rel_type} ê´€ê³„: {len(items)}ê°œ")
            for item in items:
                item_id = item.get("id", "unknown")
                item_name = item.get("name", item_id)
                reason = item.get("relationship_reason", "")
                analysis_lines.append(f"  * {item_name} (ID: {item_id}): {reason}")
        
        analysis_result["analysis"] = "\n".join(analysis_lines)
        analysis_result["relationship_summary"] = {k: len(v) for k, v in relationship_groups.items()}
        
        # ì—ì´ì „íŠ¸ê°€ íŒë‹¨í•  ìˆ˜ ìˆë„ë¡ ìƒì„¸ ì •ë³´ í¬í•¨
        for item in similar_items:
            related_item = {
                "id": item.get("id"),
                "name": item.get("name", item.get("id")),
                "relationship": item.get("relationship"),
                "relationship_reason": item.get("relationship_reason", ""),
                "similarity_score": item.get("similarity_score", 0),
                "key_differences": item.get("key_differences", []),
                "key_similarities": item.get("key_similarities", []),
                "content_summary": item.get("content_summary", ""),
                "full_content": item.get("full_content", "")
            }
            analysis_result["related_items"].append(related_item)
        
        return analysis_result
    
    # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ í•¨ìˆ˜ ìœ ì§€ (deprecated)
    async def determine_operation(
        self,
        new_knowledge: str,
        similar_items: List[Dict],
        knowledge_type: str
    ) -> Dict:
        """
        [DEPRECATED] analyze_relationship ì‚¬ìš© ê¶Œì¥
        í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ì§€ë§Œ, ê²°ì •ì€ ì—ì´ì „íŠ¸ê°€ í•´ì•¼ í•¨
        """
        analysis = await self.analyze_relationship(new_knowledge, similar_items, knowledge_type)
        
        # í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ìµœì†Œí•œì˜ ì‘ë‹µ (ì—ì´ì „íŠ¸ íŒë‹¨ ìœ ë„)
        if not analysis.get("has_related_knowledge"):
            return {
                "suggested_action": "CREATE (ê´€ë ¨ ì§€ì‹ ì—†ìŒ)",
                "analysis": analysis,
                "note": "âš ï¸ ì´ê²ƒì€ ì°¸ê³ ìš© ì •ë³´ì…ë‹ˆë‹¤. ìµœì¢… ê²°ì •ì€ ì—ì´ì „íŠ¸ê°€ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ ì§ì ‘ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤."
            }
        
        return {
            "suggested_action": "ì—ì´ì „íŠ¸ê°€ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ íŒë‹¨ í•„ìš”",
            "analysis": analysis,
            "note": "âš ï¸ ì´ê²ƒì€ ì°¸ê³ ìš© ì •ë³´ì…ë‹ˆë‹¤. ê´€ê³„ ìœ í˜•(EXTENDS, REFINES, CONFLICTS ë“±)ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì²˜ë¦¬ ë°©ë²•ì„ ì§ì ‘ ê²°ì •í•˜ì„¸ìš”."
        }
    
    def _format_existing_knowledge(self, knowledge_list: List[Dict], knowledge_type: str) -> str:
        """ê¸°ì¡´ ì§€ì‹ ëª©ë¡ì„ ë¶„ì„ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        formatted = []
        
        for idx, item in enumerate(knowledge_list, start=1):
            item_id = item.get("id", item.get("name", f"item_{idx}"))
            content = self._get_knowledge_content(item, knowledge_type)
            
            formatted.append(f"[{idx}] ID: {item_id}")
            formatted.append(f"    ë‚´ìš©: {content}")
            formatted.append("")
        
        return "\n".join(formatted)
    
    def _get_knowledge_content(self, item: Dict, knowledge_type: str) -> str:
        """ì§€ì‹ í•­ëª©ì—ì„œ ë‚´ìš© ì¶”ì¶œ"""
        if knowledge_type == "MEMORY":
            return item.get("memory", item.get("content", ""))
        
        elif knowledge_type == "DMN_RULE":
            name = item.get("name", "")
            bpmn = item.get("bpmn", "")
            # DMN XMLì—ì„œ í•µì‹¬ ë‚´ìš© ì¶”ì¶œ ì‹œë„
            if bpmn:
                return f"ê·œì¹™ëª…: {name}, XML: {bpmn[:500]}..."
            return f"ê·œì¹™ëª…: {name}"
        
        elif knowledge_type == "SKILL":
            name = item.get("name", item.get("skill_name", ""))
            description = item.get("description", "")
            content = item.get("content", "")
            steps = item.get("steps", [])
            
            parts = [f"ìŠ¤í‚¬ëª…: {name}"]
            if description:
                parts.append(f"ì„¤ëª…: {description}")
            if steps:
                parts.append(f"ë‹¨ê³„: {', '.join(steps[:5])}")
            if content and not steps:
                parts.append(f"ë‚´ìš©: {content[:500]}...")
            
            return "\n".join(parts)
        
        return str(item)


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_matcher_instance = None


def get_semantic_matcher() -> SemanticKnowledgeMatcher:
    """SemanticKnowledgeMatcher ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _matcher_instance
    if _matcher_instance is None:
        _matcher_instance = SemanticKnowledgeMatcher()
    return _matcher_instance

