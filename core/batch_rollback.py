"""
ë°°ì¹˜ ì‘ì—… ë¡¤ë°± ëª¨ë“ˆ
ë°°ì¹˜ ì‘ì—…ìœ¼ë¡œ ì‚­ì œ/ì´ë™ëœ ì§€ì‹ì„ ë³µêµ¬í•˜ëŠ” ê¸°ëŠ¥
"""

import json
from typing import Dict, List, Optional
from datetime import datetime
from utils.logger import log, handle_error
from core.database import get_db_client
from core.learning_committers.memory_committer import commit_to_memory
from core.learning_committers.dmn_committer import commit_to_dmn_rule
from core.learning_committers.skill_committer import commit_to_skill


async def rollback_batch_job(job_id: str) -> Dict:
    """
    ë°°ì¹˜ ì‘ì—… ë¡¤ë°± ì‹¤í–‰
    
    Args:
        job_id: ë¡¤ë°±í•  ë°°ì¹˜ ì‘ì—… ID
    
    Returns:
        ë¡¤ë°± ê²°ê³¼
    """
    try:
        log(f"ğŸ”„ ë°°ì¹˜ ì‘ì—… ë¡¤ë°± ì‹œì‘: job_id={job_id}")
        
        supabase = get_db_client()
        
        # 1. ë°°ì¹˜ ì‘ì—… ì´ë ¥ í™•ì¸
        job_history = (
            supabase.table("batch_job_history")
            .select("*")
            .eq("job_id", job_id)
            .single()
            .execute()
        )
        
        if not job_history.data:
            raise ValueError(f"ë°°ì¹˜ ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {job_id}")
        
        job_data = job_history.data
        
        # ì´ë¯¸ ë¡¤ë°±ëœ ê²½ìš° í™•ì¸
        if job_data.get("status") == "ROLLED_BACK":
            log(f"âš ï¸ ì´ë¯¸ ë¡¤ë°±ëœ ë°°ì¹˜ ì‘ì—…: {job_id}")
            return {
                "success": False,
                "error": "ì´ë¯¸ ë¡¤ë°±ëœ ë°°ì¹˜ ì‘ì—…ì…ë‹ˆë‹¤",
                "job_id": job_id
            }
        
        # DRY_RUN ëª¨ë“œì¸ ê²½ìš° ë¡¤ë°± ë¶ˆê°€
        if job_data.get("dry_run"):
            log(f"âš ï¸ DRY_RUN ëª¨ë“œ ë°°ì¹˜ ì‘ì—…ì€ ë¡¤ë°±í•  ìˆ˜ ì—†ìŒ: {job_id}")
            return {
                "success": False,
                "error": "DRY_RUN ëª¨ë“œ ë°°ì¹˜ ì‘ì—…ì€ ë¡¤ë°±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤",
                "job_id": job_id
            }
        
        # 2. ë°±ì—… ë°ì´í„° ì¡°íšŒ
        backups = (
            supabase.table("batch_job_backup")
            .select("*")
            .eq("job_id", job_id)
            .execute()
        )
        
        if not backups.data:
            log(f"âš ï¸ ë°±ì—… ë°ì´í„°ê°€ ì—†ìŒ: {job_id}")
            return {
                "success": False,
                "error": "ë°±ì—… ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤",
                "job_id": job_id
            }
        
        # 3. ë¡¤ë°± ì‹¤í–‰
        restored_count = 0
        errors = []
        
        for backup in backups.data:
            try:
                agent_id = backup.get("agent_id")
                storage_type = backup.get("storage_type")
                item_id = backup.get("item_id")
                operation = backup.get("operation")
                original_content = backup.get("original_content", {})
                
                if operation == "DELETE":
                    # ì‚­ì œëœ í•­ëª© ë³µêµ¬
                    await _restore_deleted_item(
                        agent_id=agent_id,
                        storage_type=storage_type,
                        item_id=item_id,
                        original_content=original_content
                    )
                    restored_count += 1
                    log(f"   âœ… {storage_type} ë³µêµ¬: id={item_id}")
                
                elif operation == "MOVE":
                    # ì´ë™ëœ í•­ëª© ë¡¤ë°± (ì›ë³¸ ë³µêµ¬ + ì´ë™ëœ í•­ëª© ì‚­ì œ)
                    moved_to_storage = backup.get("moved_to_storage")
                    moved_to_id = backup.get("moved_to_id")
                    
                    # 1. ì›ë³¸ ë³µêµ¬
                    await _restore_deleted_item(
                        agent_id=agent_id,
                        storage_type=storage_type,
                        item_id=item_id,
                        original_content=original_content
                    )
                    
                    # 2. ì´ë™ëœ í•­ëª© ì‚­ì œ
                    if moved_to_storage and moved_to_id:
                        await _delete_moved_item(
                            agent_id=agent_id,
                            storage_type=moved_to_storage,
                            item_id=moved_to_id
                        )
                    
                    restored_count += 1
                    log(f"   âœ… {storage_type} -> {moved_to_storage} ì´ë™ ë¡¤ë°±: id={item_id}")
                
            except Exception as e:
                error_msg = f"ë¡¤ë°± ì‹¤íŒ¨ ({storage_type}, id={item_id}): {e}"
                errors.append(error_msg)
                log(f"   âš ï¸ {error_msg}")
                handle_error(f"ë°°ì¹˜ë¡¤ë°±_{storage_type}", e)
        
        # 4. ë°°ì¹˜ ì‘ì—… ìƒíƒœ ì—…ë°ì´íŠ¸
        supabase.table("batch_job_history").update({
            "status": "ROLLED_BACK",
            "completed_at": datetime.now().isoformat()
        }).eq("job_id", job_id).execute()
        
        log(f"âœ… ë°°ì¹˜ ì‘ì—… ë¡¤ë°± ì™„ë£Œ: job_id={job_id}, ë³µêµ¬={restored_count}, ì—ëŸ¬={len(errors)}")
        
        return {
            "success": True,
            "job_id": job_id,
            "restored_count": restored_count,
            "errors": errors
        }
        
    except Exception as e:
        error_msg = f"ë°°ì¹˜ ì‘ì—… ë¡¤ë°± ì‹¤íŒ¨: {e}"
        log(f"âŒ {error_msg}")
        handle_error("ë°°ì¹˜ë¡¤ë°±", e)
        return {
            "success": False,
            "error": error_msg,
            "job_id": job_id
        }


async def _restore_deleted_item(
    agent_id: str,
    storage_type: str,
    item_id: str,
    original_content: Dict
) -> None:
    """ì‚­ì œëœ í•­ëª© ë³µêµ¬"""
    if storage_type == "MEMORY":
        content = original_content.get("memory") or original_content.get("content", "")
        await commit_to_memory(
            agent_id=agent_id,
            content=content,
            source_type="batch_rollback",
            operation="CREATE"
        )
    
    elif storage_type == "DMN_RULE":
        # DMN_RULE ë³µêµ¬: conditionê³¼ action ì¶”ì¶œ
        condition = original_content.get("condition", "")
        action = original_content.get("action", "")
        rule_name = original_content.get("name", f"ë³µêµ¬ëœ ê·œì¹™ {item_id[:8]}")
        
        if not condition or not action:
            # XMLì—ì„œ ì¶”ì¶œ ì‹œë„
            bpmn = original_content.get("bpmn", "")
            if bpmn:
                # ê°„ë‹¨í•œ íŒŒì‹± (ê°œì„  ê°€ëŠ¥)
                condition = bpmn[:500]
                action = bpmn[500:1000] if len(bpmn) > 500 else bpmn
        
        await commit_to_dmn_rule(
            agent_id=agent_id,
            dmn_artifact={
                "condition": condition,
                "action": action,
                "name": rule_name
            },
            feedback_content="ë°°ì¹˜ ì‘ì—… ë¡¤ë°±",
            operation="CREATE"
        )
    
    elif storage_type == "SKILL":
        # SKILL ë³µêµ¬
        skill_name = original_content.get("name") or item_id
        description = original_content.get("description", "")
        steps = original_content.get("steps", [])
        
        if not steps:
            # contentì—ì„œ steps ì¶”ì¶œ ì‹œë„
            content = original_content.get("content", "")
            if content:
                steps = [content]
        
        await commit_to_skill(
            agent_id=agent_id,
            skill_artifact={
                "name": skill_name,
                "description": description,
                "steps": steps,
                "overview": original_content.get("overview"),
                "usage": original_content.get("usage")
            },
            operation="CREATE",
            feedback_content="ë°°ì¹˜ ì‘ì—… ë¡¤ë°±"
        )


async def _delete_moved_item(
    agent_id: str,
    storage_type: str,
    item_id: str
) -> None:
    """ì´ë™ëœ í•­ëª© ì‚­ì œ (ë¡¤ë°± ì‹œ)"""
    if storage_type == "MEMORY":
        await commit_to_memory(
            agent_id=agent_id,
            content="",
            source_type="batch_rollback",
            operation="DELETE",
            memory_id=item_id
        )
    
    elif storage_type == "DMN_RULE":
        await commit_to_dmn_rule(
            agent_id=agent_id,
            dmn_artifact={},
            feedback_content="ë°°ì¹˜ ì‘ì—… ë¡¤ë°±",
            operation="DELETE",
            rule_id=item_id
        )
    
    elif storage_type == "SKILL":
        await commit_to_skill(
            agent_id=agent_id,
            skill_artifact={},
            operation="DELETE",
            skill_id=item_id,
            feedback_content="ë°°ì¹˜ ì‘ì—… ë¡¤ë°±"
        )


async def get_batch_job_history(job_id: Optional[str] = None, limit: int = 50) -> List[Dict]:
    """
    ë°°ì¹˜ ì‘ì—… ì´ë ¥ ì¡°íšŒ
    
    Args:
        job_id: íŠ¹ì • ì‘ì—… ID (Noneì´ë©´ ìµœê·¼ ì‘ì—… ëª©ë¡)
        limit: ìµœëŒ€ ê²°ê³¼ ìˆ˜
    
    Returns:
        ë°°ì¹˜ ì‘ì—… ì´ë ¥ ëª©ë¡
    """
    try:
        supabase = get_db_client()
        
        if job_id:
            result = (
                supabase.table("batch_job_history")
                .select("*")
                .eq("job_id", job_id)
                .single()
                .execute()
            )
            return [result.data] if result.data else []
        else:
            result = (
                supabase.table("batch_job_history")
                .select("*")
                .order("started_at", desc=True)
                .limit(limit)
                .execute()
            )
            return result.data or []
    
    except Exception as e:
        handle_error("ë°°ì¹˜ì‘ì—…ì´ë ¥ì¡°íšŒ", e)
        return []

